@article{Al-Labadi2018,
abstract = {The features of a logically sound approach to a theory of statistical reasoning are discussed. A particular approach that satisfies these criteria is reviewed. This is seen to involve selection of a model, model checking, elicitation of a prior, checking the prior for bias, checking for prior-data conflict and estimation and hypothesis assessment inferences based on a measure of evidence. A long-standing anomalous example is resolved by this approach to inference and an application is made to a practical problem of considerable importance, which, among other novel aspects of the analysis, involves the development of a relevant elicitation algorithm. {\textcopyright} 2018 by the authors.},
address = {Department of Mathematics, University of Sharjah, P.O. Box 27272, Sharjah, United Arab Emirates Genetics and Genome Biology, Hospital for Sick Children, Toronto, ON M5G 1X8, Canada Department of Statistical Sciences, University of Toronto, Toronto, ON M5S},
annote = {Cited By :2
Export Date: 12 November 2019},
author = {Al-Labadi, L and Baskurt, Z and Evans, M},
doi = {10.3390/e20040289},
journal = {Entropy},
keywords = {Checking priors Elicitation of priors Measuring st},
number = {4},
title = {{Statistical reasoning: Choosing and checking the ingredients, inferences based on a measure of statistical evidence with some applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045833907{\&}doi=10.3390{\%}2Fe20040289{\&}partnerID=40{\&}md5=850c44342dd46510f170af101c2c955c},
volume = {20},
year = {2018}
}
@article{Al-Labadi2018a,
abstract = {Model checking procedures are considered based on the use of the Dirichlet process and relative belief. This combination is seen to lead to some unique advantages for this problem. Of considerable importance is the selection of the hyperparameters for the Dirichlet process. A particular choice is advocated here for the base distribution that avoids prior-data conflict and double use of the data, while the choice of the concentration parameter is based on elicitation. Several examples are presented in which the proposed approach exhibits excellent performance. The Canadian Journal of Statistics 46: 380–398; 2018 {\textcopyright} 2018 Statistical Society of Canada. {\textcopyright} 2018 Statistical Society of Canada / Soci{\'{e}}t{\'{e}} statistique du Canada},
address = {Department of Mathematics, University of Sharjah, Sharjah, United Arab Emirates Department of Statistical Sciences, University of Toronto, Toronto, Canada},
annote = {Export Date: 12 November 2019},
author = {Al-Labadi, L and Evans, M},
doi = {10.1002/cjs.11457},
journal = {Canadian Journal of Statistics},
keywords = {Dirichlet process Model checking relative belief r},
number = {3},
pages = {380--398},
title = {{Prior-based model checking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052528831{\&}doi=10.1002{\%}2Fcjs.11457{\&}partnerID=40{\&}md5=6652ff3d459d12e31939846187674081},
volume = {46},
year = {2018}
}
@article{Al-Labadi2017,
abstract = {The robustness to the prior of Bayesian inference procedures based on a measure of statistical evidence is considered. These inferences are shown to have optimal properties with respect to robustness. Furthermore, a connection between robustness and prior-data conflict is established. In particular, the inferences are shown to be effectively robust when the choice of prior does not lead to prior-data conflict. When there is prior-data conflict, however, robustness may fail to hold. {\textcopyright} 2017. International Society for Bayesian Analysis.},
address = {Department of Statistical Sciences, University of Toronto, Toronto, ON M5S 3G3, Canada},
annote = {Cited By :2
Export Date: 12 November 2019},
author = {Al-Labadi, L and Evans, M},
doi = {10.1214/16-BA1024},
journal = {Bayesian Analysis},
keywords = {Prior-data conflict Relative belief Robustness LB },
number = {3},
pages = {705--728},
title = {{Optimal robustness results for relative belief inferences and the relationship to prior-data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020295469{\&}doi=10.1214{\%}2F16-BA1024{\&}partnerID=40{\&}md5=8b8e16093663193df93341eff77e1ad8},
volume = {12},
year = {2017}
}
@article{Allocco2010,
abstract = {Background: Paclitaxel-eluting stents decrease angiographic and clinical restenosis following percutaneous coronary intervention compared to bare metal stents. TAXUS Element is a third-generation paclitaxel-eluting stent which incorporates a novel, thinner-strut, platinum-enriched metal alloy platform. The stent is intended to have enhanced radiopacity and improved deliverability compared to other paclitaxel-eluting stents. The safety and efficacy of the TAXUS Element stent are being evaluated in the pivotal PERSEUS clinical trials.Methods/Design: The PERSEUS trials include two parallel studies of the TAXUS Element stent in single, de novo coronary atherosclerotic lesions. The PERSEUS Workhorse study is a prospective, randomized (3:1), single-blind, non-inferiority trial in subjects with lesion length ≤28 mm and vessel diameter ≥2.75 mm to ≤4.0 mm which compares TAXUS Element to the TAXUS Express2 paclitaxel-eluting stent system. The Workhorse study employs a novel Bayesian statistical approach that uses prior information to limit the number of study subjects exposed to the investigational device and thus provide a safer and more efficient analysis of the TAXUS Element stent. PERSEUS Small Vessel is a prospective, single-arm, superiority trial in subjects with lesion length ≤20 mm and vessel diameter ≥2.25 mm to {\textless}2.75 mm that compares TAXUS Element with a matched historical bare metal Express stent control.Discussion: The TAXUS PERSEUS clinical trial program uses a novel statistical approach to evaluate whether design and metal alloy iterations in the TAXUS Element stent platform provide comparable safety and improved procedural performance compared to the previous generation Express stent. PERSEUS trial enrollment is complete and primary endpoint data are expected in 2010. PERSEUS Workhorse and Small Vessel are registered at http://www.clinicaltrials.gov, identification numbers NCT00484315 and NCT00489541. {\textcopyright} 2010 Allocco et al; licensee BioMed Central Ltd.},
address = {D.J. Kereiakes, The Christ Hospital Heart and Vascular Center, The Lindner Center for Research and Education at The Christ Hospital, 2123 Auburn Avenue, Suite 424, Cincinnati, OH, United States},
annote = {L358351871
2010-03-03
2010-03-16},
author = {Allocco, D J and Cannon, L A and Britt, A and Heil, J E and Nersesov, A and Wehrenberg, S and Dawkins, K D and Kereiakes, D J},
doi = {10.1186/1745-6215-11-1},
issn = {1745-6215},
journal = {Trials},
keywords = {NCT00484315 NCT00489541 acetylsalicylic acid antit},
language = {English LB  - Allocco2010},
title = {{A prospective evaluation of the safety and efficacy of the TAXUS Element paclitaxel-eluting coronary stent system for the treatment of de novo coronary artery lesions: Design and statistical methods of the PERSEUS clinical program}},
url = {http://www.trialsjournal.com/content/11/1/1 http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L358351871 http://dx.doi.org/10.1186/1745-6215-11-1},
volume = {11},
year = {2010}
}
@article{Auerbach2015,
abstract = {Although the Food and Drug Administration (FDA) approved oral Truvada for pre-exposure prophylaxis (PrEP) for women at risk of HIV infection in the US in July 2012, and the Centers for Disease Control and Prevention (CDC) issued guidance for clinicians to provide PrEP to women “at substantial risk of HIV acquisition” in May 2014, there remain no clinical trial data on efficacy among US women, and there is a dearth of research on knowledge, attitudes, and likelihood of use of PrEP among them. We conducted a qualitative focus group (FG) study with 144 at-risk women in six US cities between July and September 2013, including locations in the Southern US, where HIV infections among women are most prevalent. FG questions elicited awareness of PrEP, attitudes about administration and uptake, and barriers to and facilitators of use. Women expressed anger at the fact that they had not heard of PrEP prior to the study, but once informed most found it attractive. PrEP was seen as additional, not substitute protection to condoms, and participants suggested several dissemination strategies to meet the diverse needs of women. Key barriers to PrEP uptake included distrust of the medical system, stigma, and cost. Findings suggest that US women view PrEP as an important prevention option, assuming side effects and the cost to the consumer are minimal, the efficacy of the drug is reasonable, and PrEP is delivered by trusted providers in trusted venues.},
author = {Auerbach, Judith D and Kinsky, Suzanne and Brown, Gina and Charles, Vignetta},
doi = {10.1089/apc.2014.0142},
issn = {1087-2914},
journal = {AIDS Patient Care and STDs},
number = {2},
pages = {102--110},
title = {{Knowledge, Attitudes, and Likelihood of Pre-Exposure Prophylaxis (PrEP) Use Among US Women at Risk of Acquiring HIV}},
volume = {29},
year = {2015}
}
@article{Bair2016,
author = {Bair, Eric and Gaynor, Sheila},
doi = {10.1097/j.pain.0000000000000518},
journal = {Pain},
pages = {1266--1278},
title = {{Identification of clusters of individuals relevant to temporomandibular disorders and other chronic pain conditions: the OPPERA study}},
volume = {157(6)},
year = {2016}
}
@article{Banbeta2019,
abstract = {Including historical data may increase the power of the analysis of a current clinical trial and reduce the sample size of the study. Recently, several Bayesian methods for incorporating historical data have been proposed. One of the methods consists of specifying a so-called power prior whereby the historical likelihood is downweighted with a weight parameter. When the weight parameter is also estimated from the data, the modified power prior (MPP) is needed. This method has been used primarily when a single historical trial is available. We have adapted the MPP for incorporating multiple historical control arms into a current clinical trial, each with a separate weight parameter. Three priors for the weights are considered: (1) independent, (2) dependent, and (3) robustified dependent. The latter is developed to account for the possibility of a conflict between the historical data and the current data. We analyze two real-life data sets and perform simulation studies to compare the performance of competing Bayesian methods that allow to incorporate historical control patients in the analysis of a current trial. The dependent power prior borrows more information from comparable historical studies and thereby can improve the statistical power. Robustifying the dependent power prior seems to protect against prior-data conflict.},
address = {A. Banbeta, I-Biostat, UHasselt, Hasselt, Belgium},
annote = {L624610817
2018-11-01},
author = {Banbeta, A and van Rosmalen, J and Dejardin, D and Lesaffre, E},
doi = {10.1002/sim.8019},
issn = {1097-0258 0277-6715},
journal = {Statistics in Medicine},
keywords = {adult article controlled clinical trial controlled},
language = {English LB  - Banbeta2019},
number = {7},
pages = {1147--1169},
title = {{Modified power prior with multiple historical trials for binary endpoints}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L624610817 http://dx.doi.org/10.1002/sim.8019},
volume = {38},
year = {2019}
}
@misc{Bangma2019a,
author = {Bangma, Jacqueline T. and Kwiatkowski, Evan and Psioda, Matt and Santos, Hudson P. and Hooper, Stephen R. and Douglass, Laurie and Joseph, Robert M. and Frazier, Jean A. and Kuban, Karl C.K. and O'Shea, Thomas M. and Fry, Rebecca C.},
booktitle = {Pediatric Research},
doi = {10.1038/s41390-019-0564-8},
issn = {15300447},
pmid = {31521061},
title = {{Understanding positive child health}},
year = {2019}
}
@article{Bangma2019,
abstract = {Background: To identify modifiable antecedents during pre-pregnancy and pregnancy windows associated with a positive child health at 10 years of age. Methods: Data on 889 children enrolled in the Extremely Low Gestational Age Newborn (ELGAN) study in 2002–2004 were analyzed for associations between potentially modifiable maternal antecedents during pre-pregnancy and pregnancy time windows and a previously described positive child health index (PCHI) score at 10 years of age. Stratification by race was also investigated for associations with investigated antecedents. Results: Factors associated with higher PCHI (more positive health) included greater gestational age, birth weight, multiple gestation, and medical interventions, including assisted reproduction and cervical cerclage. Factors associated with lower PCHI included correlates of lower socioeconomic status, pre-pregnancy chronic medical disorders in the mother such as pre-pregnancy body mass index (BMI), and maternal asthma. When stratified by race, variation in significant results was observed. Conclusions: Among children born extremely preterm, medical interventions and higher socioeconomic status were associated with improved PCHI, while chronic illness and high BMI in the mother is associated with lower PCHI at 10 years of age. Knowledge of such antecedent factors could inform efforts to develop interventions that promote positive child health outcomes in future pregnancies.},
author = {Bangma, Jacqueline T. and Kwiatkowski, Evan and Psioda, Matt and Santos, Hudson P. and Hooper, Stephen R. and Douglass, Laurie and Joseph, Robert M. and Frazier, Jean A. and Kuban, Karl C.K. and O'Shea, Thomas M. and Fry, Rebecca C.},
doi = {10.1038/s41390-019-0404-x},
issn = {15300447},
journal = {Pediatric Research},
pmid = {31005057},
title = {{Early life antecedents of positive child health among 10-year-old children born extremely preterm}},
year = {2019}
}
@article{Bangma2018,
abstract = {Objective: To assess the development of a Positive Child Health Index (PCHI) based on 11 adverse outcomes and evaluate the association of PCHI with quality of life (QoL) scores in a preterm cohort. Study design: A total of 889 children enrolled in the Extremely Low Gestational Age Newborn (ELGAN) study in 2002-2004 were followed up at 10 years of age. A parent/caregiver completed questionnaires for child QoL, asthma, visual or hearing impairment, gross motor function impairment, epilepsy, attention deficit/hyperactivity disorder, anxiety, and depression. The child was assessed for cognitive impairment, autism, and obesity. PCHI scores were computed and linear regression models were used to evaluate the relationship between QoL categories (psychosocial, physical, emotional, social, school, and total) and the PCHI (dichotomized and coded as a multilevel categorical predictor) and to assess sex differences. Results: Among ELGAN children, higher PCHI scores were associated with higher reported QoL scores for all QoL categories. Children with no disorders and a PCHI of 100{\%} had Pediatric Quality of Life Inventory total scores that were 11 points higher than children with 1 or more adverse outcomes (PCHI of {\textless}100{\%}). Boys had lower QoL scores for the total, psychosocial, social, and school categories. Conclusions: Positive child health assessed using a quantitative PCHI was associated with QoL across the ELGAN cohort at school age. In the current study, the PCHI encompassed 11 outcomes assessed in ELGANs. Future research could include an enhanced panel of child health outcomes to support the use of PCHI as an indicator of positive child health.},
author = {Bangma, Jacqueline T. and Kwiatkowski, Evan and Psioda, Matthew and Santos, Hudson P. and Hooper, Stephen R. and Douglass, Laurie and Joseph, Robert M. and Frazier, Jean A. and Kuban, Karl C.K. and O'Shea, Thomas M. and Fry, Rebecca C.},
doi = {10.1016/j.jpeds.2018.06.037},
issn = {10976833},
journal = {Journal of Pediatrics},
keywords = {extremely low gestational age newborns,quality of life},
pmid = {30078720},
title = {{Assessing Positive Child Health among Individuals Born Extremely Preterm}},
year = {2018}
}
@article{Barrado2019,
abstract = {The sample size of a prospective clinical study aimed at validation of a diagnostic biomarker-based test may be prohibitively large. We present a Bayesian framework that allows incorporating available development-study information about the performance of the test. As a result, the framework allows reducing the sample size required in the validation study, which may render the latter study feasible. The validation is based on the Bayesian testing of a hypothesis regarding possible values of AUC. Toward this end, first, available information is translated into a prior distribution. Next, this prior distribution is used in a Bayesian design to evaluate the performance of the diagnostic-test. We perform a simulation study to compare the power of the proposed Bayesian design to the approach ignoring development-study information. For each scenario, 1000 studies of sample size 100, 400, and 800 are simulated. Overall, the proposed Bayesian design leads to a substantially higher power than the flat-prior design. In some of the considered simulation settings, the Bayesian design requires as little as 50{\%} of the flat-prior traditional design's sample size to reach approximately the same power. Moreover, a simulation-based application strategy is proposed and presented with respect to a case-study involving the development of a biomarker-based diagnostic-test for Alzheimer's disease.},
address = {L.G. Barrado, Hasselt University, I-Biostat, Agoralaan, Diepenbeek, Belgium},
annote = {L627645470
2019-05-17
2019-08-08},
author = {Barrado, L G and Coart, E and Burzykowski, T},
doi = {10.1080/19466315.2019.1574489},
issn = {1946-6315},
journal = {Statistics in Biopharmaceutical Research},
keywords = {ELISA kit biological marker Alzheimer disease area},
language = {English LB  - Barrado2019},
number = {3},
pages = {311--323},
title = {{A Bayesian Framework Allowing Incorporation of Retrospective Information in Prospective Diagnostic Biomarker-Validation Designs}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L627645470 http://dx.doi.org/10.1080/19466315.2019.1574489},
volume = {11},
year = {2019}
}
@article{Berchialla2019,
abstract = {The Simon's two-stage design is the most commonly applied among multi-stage designs in phase IIA clinical trials. It combines the sample sizes at the two stages in order to minimize either the expected or the maximum sample size. When the uncertainty about pre-trial beliefs on the expected or desired response rate is high, a Bayesian alternative should be considered since it allows to deal with the entire distribution of the parameter of interest in a more natural way. In this setting, a crucial issue is how to construct a distribution from the available summaries to use as a clinical prior in a Bayesian design. In this work, we explore the Bayesian counterparts of the Simon's two-stage design based on the predictive version of the single threshold design. This design requires specifying two prior distributions: the analysis prior, which is used to compute the posterior probabilities, and the design prior, which is employed to obtain the prior predictive distribution. While the usual approach is to build beta priors for carrying out a conjugate analysis, we derived both the analysis and the design distributions through linear combinations of B-splines. The motivating example is the planning of the phase IIA two-stage trial on anti-HER2 DNA vaccine in breast cancer, where initial beliefs formed from elicited experts' opinions and historical data showed a high level of uncertainty. In a sample size determination problem, the impact of different priors is evaluated.},
address = {P. Berchialla, Department of Clinical and Biological Sciences, University of Torino, Torino, Italy},
annote = {L625034793
2018-11-23
2019-04-02},
author = {Berchialla, P and Zohar, S and Baldi, I},
doi = {10.1002/pst.1914},
issn = {1539-1612 1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {DNA vaccine epidermal growth factor receptor 2 art},
language = {English LB  - Berchialla2019},
number = {2},
pages = {198--211},
title = {{Bayesian sample size determination for phase IIA clinical trials using historical data and semi-parametric prior's elicitation}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L625034793 http://dx.doi.org/10.1002/pst.1914},
volume = {18},
year = {2019}
}
@article{Berry2015,
abstract = {Background: Pirfenidone, an oral antifibrotic agent that also displays anti-inflammatory properties, has been investigated in 3 similar, multinational, placebo-controlled phase 3 studies (ASCEND study PIPF-016 and CAPACITY studies PIPF-004 and PIPF-006) in patients with idiopathic pulmonary fibrosis (IPF). In the present analysis, we investigated whether the efficacy of pirfenidone in slowing the progression of IPF results in longer survival. Bayesian statistics were used to assess the impact of pirfenidone on 1-year all-cause-mortality and treatment-emergent IPF-related mortality from each individual study and from a synthesis of the data from the 3 studies. Methods: The results of the earlier CAPACITY studies were known at the time a pooled 1-year mortality analysis was prespecified for ASCEND. In the Bayesian approach to inference, when analyzing the mortality results of ASCEND, the earlier studies are taken to be prior information regarding the hypothesis that pirfenidone reduces mortality. To address multiplicity and the possibility that historical results may not apply in the next study, we first discounted the information in CAPACITY by 50{\%} in drawing overall conclusions about the ASCEND population. We extended this analysis to address the extent to which the CAPACITY studies could be discounted and still conclude superiority of pirfenidone to placebo. We required a posterior probability of superiority of 97.5{\%} for pirfenidone to conclude a significant mortality benefit (which is analogous to requiring a two-sided p-value less than 0.05). Results: The 1-year mortality results were consistent across the 3 studies (Table 1). For hypothesis generation, using only 50{\%} of the mortality information from CAPACITY gave a prior probability {\textgreater}90{\%} that pirfenidone was superior to placebo in reducing all-cause mortality, which is more than sufficient for the purpose of hypothesis generation. Updating this prior information using the data from ASCEND gave a posterior probability of 98.4{\%} that pirfenidone is superior to placebo in decreasing 1-year all-cause mortality. Discounting the CAPACITY studies by as much as 71{\%} gave a posterior probability of ≥97.5{\%}. Similarly, for treatment-emergent IPF-related mortality, discounting the CAPACITY studies by as much as 62{\%} gave a posterior probability of superiority of ≥97.5{\%}. Conclusions: Pirfenidone has significant benefits on all-cause and treatment-emergent IPF-related mortality at 1 year even when the prior information from the CAPACITY studies is greatly discounted. (Figure Presented).},
address = {D. Berry, Berry Consultants, Austin, TX, United States},
annote = {L72052291
2015-11-05},
author = {Berry, D and Albera, C and Bradford, W Z and Costabel, U and {Du Bois}, R and Glaspole, I and {Glassberg Csete}, M K and Lancaster, L and Lederer, D J and Lin, Z and Nathan, S D and Swigris, J J and Valeyre, D and Noble, P W},
issn = {1073-449X},
journal = {American Journal of Respiratory and Critical Care Medicine},
keywords = {pirfenidone placebo antifibrotic agent mortality p},
language = {English LB  - Berry2015},
title = {{Pirfenidone impact on mortality in IPF patients: Bayesian analysis}},
url = {http://www.atsjournals.org/doi/pdf/10.1164/ajrccm-conference.2015.191.1{\_}MeetingAbstracts.A4417 http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L72052291},
volume = {191},
year = {2015}
}
@article{Berry2017,
abstract = {7021Background: Clinical trials of experimental drugs require controls. Concurrently randomized controls are the gold standard for judging drug effect. Historical controls are not ideal but are much more efficient and economical. Historical controls derived from a single clinical trial have the biases of that trial. Using many trials with comparable end points and eligibility minimizes such bias. Medidata's archive contains {\textgreater}3000 trials with clinical data rights for deidentified aggregated analyses. We used this resource to develop a synthetic control arm (SCA) for a particular phase I/II single-arm trial in AML. We demonstrate the utility of this approach by addressing a different but equally important issue: establishing early end points as predictors of long term clinical outcomes. Methods: We built an SCA from 7 relapsed/refractory AML trials completed in last 5 yrs. They had similar eligibility criteria as a particular phase I/II trial for an investigational agent. We selected subjects for the SCA who had baseline covariates matching the subjects in the tri.al. Data cleaning and standardization ensured consistency of data fields. The primary outcomes were CR (complete remission) and CRi (CR without hematologic recovery) at 56 days, and overall survival (OS) subsequent to 56 days. Non-CR/non-CRi deaths before 56 days were set to OS=0. We used a landmark analysis to correlate CR and CRi with OS, calculating the hazard ratio (HR) of OS of CR and CRi vs its comparison group. Results: The SCA included 340 subjects (median age 63 yrs, 55{\%} male, 77{\%} White Non-Hispanic, 28{\%} ECOG 0). Results are in this table. Conclusions: The Medidata trial archive is a resource for creating SCAs. The example SCA we created identified well-defined subjects for whom a CR or CRi is associated with longer OS. Investigations of SCAs for other drugs could aid in addressing the types of subjects and drug categories for which CR or CR/CRi predict longer OS. Such information can help build more efficient and more informative adaptive clinical trials. NMedian OS (wks)Com-parisonHRp valueCR3564CRi0.22{\textless}0.001CRi5123Other0.44{\textless}0.001CR/CRi8630Other0.28{\textless}0.001Other25411–––},
author = {Berry, Donald A and Elashoff, Michael and Blotner, Steven and Davi, Ruthie and Beineke, Philip and Chandler, Mark and Lee, David S and Chen, Lin Chi and Sarkar, Somnath},
doi = {10.1200/JCO.2017.35.15{\_}suppl.7021},
journal = {Journal of Clinical Oncology},
number = {15{\_}suppl LB  - Berry2017},
pages = {7021},
title = {{Creating a synthetic control arm from previous clinical trials: Application to establishing early end points as indicators of overall survival in acute myeloid leukemia (AML)}},
url = {https://ascopubs.org/doi/abs/10.1200/JCO.2017.35.15{\_}suppl.7021},
volume = {35},
year = {2017}
}
@article{Bertsche2019,
abstract = {After exploratory drug development, companies face the decision whether to initiate confirmatory trials based on limited efficacy information. This proof-of-concept decision is typically performed after a Phase II trial studying a novel treatment versus either placebo or an active comparator. The article aims to optimize the design of such a proof-of-concept trial with respect to decision making. We incorporate historical information and develop pre-specified decision criteria accounting for the uncertainty of the observed treatment effect. We optimize these criteria based on sensitivity and specificity, given the historical information. Specifically, time-to-event data are considered in a randomized 2-arm trial with additional prior information on the control treatment. The proof-of-concept criterion uses treatment effect size, rather than significance. Criteria are defined on the posterior distribution of the hazard ratio given the Phase II data and the historical control information. Event times are exponentially modeled within groups, allowing for group-specific conjugate prior-to-posterior calculation. While a non-informative prior is placed on the investigational treatment, the control prior is constructed via the meta-analytic-predictive approach. The design parameters including sample size and allocation ratio are then optimized, maximizing the probability of taking the right decision. The approach is illustrated with an example in lung cancer.},
address = {1 Biost. and Data Sciences, Boehringer Ingelheim Pharma GmbH {\&} Co. KG, Biberach/Riss, Germany. 2 Institute of Statistics, Ulm University, Ulm, Germany.},
annote = {1477-0334
Bertsche, Anja
ORCID: https://orcid.org/0000-0002-6933-6894
Fleischer, Frank
Beyersmann, Jan
Nehmiz, Gerhard
ORCID: https://orcid.org/0000-0002-9009-4316
Journal Article
England
Stat Methods Med Res. 2019 Apr;28(4):1272-1289. doi: 10.1177/0962280217747310. Epub 2017 Dec 28.},
author = {Bertsche, A and Fleischer, F and Beyersmann, J and Nehmiz, G},
doi = {10.1177/0962280217747310},
edition = {2017/12/30},
issn = {0962-2802},
journal = {Statistical Methods in Medical Research},
keywords = {Bayes Go-NoGo decision Proof-of-concept meta-analy},
language = {eng LB  - Bertsche2019},
number = {4},
pages = {1272--1289},
title = {{Bayesian Phase II optimization for time-to-event data based on historical information}},
volume = {28},
year = {2019}
}
@article{Bickel2015,
abstract = {Two major approaches have developed within Bayesian statistics to address uncertainty in the prior distribution and in the rest of the model. First, methods of model checking, including those assessing prior-data conflict, determine whether the posterior resulting from the model is adequate for purposes of inference and estimation or other decision-making. A potential drawback of this approach is that it provides little guidance for inference in the event that the model is found to be inadequate, that is, in conflict with the data. Second, the robust Bayes approach determines the sensitivity of inferences and decisions to the prior distribution and other model assumptions. This approach includes rules for making decisions on the basis of a set of posterior distributions corresponding to the set of reasonable model assumptions. Drawbacks of the second approach include the inability to criticize the set of models and the lack of guidance for specifying such a set. Those two approaches to model uncertainty are combined into a two-stage procedure in order to overcome each of their limitations. The first stage checks each model within a large class of models to assess which models are in conflict with the data and which are adequate for purposes of data analysis. The resulting set of adequate models is then used in the second stage either for summarizing a combined posterior such as a maximum-entropy posterior or for inference according to decision rules of the robust Bayes approach and of imprecise probability more generally. This proposed framework is illustrated by the application of a class of hierarchical models to a simple data set. {\textcopyright} 2015 Elsevier Inc. All rights reserved.},
address = {Ottawa Institute of Systems Biology, Department of Biochemistry, Microbiology, and Immunology, University of Ottawa, 451 Smyth Road, Ottawa, ON K1H 8M5, Canada},
annote = {Cited By :4
Export Date: 12 November 2019},
author = {Bickel, D R},
doi = {10.1016/j.ijar.2015.07.012},
journal = {International Journal of Approximate Reasoning},
keywords = {Imprecise probability Model assessment Model check},
pages = {53--72},
title = {{Inference after checking multiple Bayesian models for data conflict and applications to mitigating the influence of rejected priors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941647637{\&}doi=10.1016{\%}2Fj.ijar.2015.07.012{\&}partnerID=40{\&}md5=668fb678ce3ecd2b8e83e66812071d66},
volume = {66},
year = {2015}
}
@article{Bickel2018,
abstract = {Learning from model diagnostics that a prior distribution must be replaced by one that conflicts less with the data raises the question of which prior should instead be used for inference and decision. The same problem arises when a decision maker learns that one or more reliable experts express unexpected beliefs. In both cases, coherence of the solution would be guaranteed by applying Bayes's theorem to a distribution of prior distributions that effectively assigns the initial prior distribution a probability arbitrarily close to 1. The new distribution for inference would then be the distribution of priors conditional on the insight that the prior distribution lies in a closed convex set that does not contain the initial prior. A readily available distribution of priors needed for such conditioning is the law of the empirical distribution of sufficiently large number of independent parameter values drawn from the initial prior. According to the Gibbs conditioning principle from the theory of large deviations, the resulting new prior distribution minimizes the entropy relative to the initial prior. While minimizing relative entropy accommodates the necessity of going beyond the initial prior without departing from it any more than the insight demands, the large-deviation derivation also ensures the advantages of Bayesian coherence. This approach is generalized to uncertain insights by allowing the closed convex set of priors to be random. {\textcopyright} 2018 Informa UK Limited, trading as Taylor {\&} Francis Group.},
address = {Department of Biochemistry, Microbiology, and Immunology, Department of Mathematics and Statistics, Ottawa Institute of Systems Biology, University of Ottawa, Ottawa, ON, Canada},
annote = {Export Date: 12 November 2019},
author = {Bickel, D R},
doi = {10.1080/02331888.2018.1427752},
journal = {Statistics},
keywords = {Bayesian model averaging model assessment model ch},
number = {3},
pages = {552--570},
title = {{Bayesian revision of a prior given prior-data conflict, expert opinion, or a similar insight: a large-deviation approach}},
url = {internal-pdf://101.96.7.229/fjenqq5x.bmp LB  - Bickel2018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041169865{\&}doi=10.1080{\%}2F02331888.2018.1427752{\&}partnerID=40{\&}md5=125004d0a01c6ad9eac8b615c6990327},
volume = {52},
year = {2018}
}
@article{Bilal2018a,
annote = {doi: 10.1080/09546634.2017.1422591},
author = {Bilal, Jawad and Berlinberg, Adam and Bhattacharjee, Sandipan and Trost, Jaren and Riaz, Irbaz Bin and Kurtzman, Drew J B},
doi = {10.1080/09546634.2017.1422591},
issn = {0954-6634},
journal = {Journal of Dermatological Treatment},
pages = {1--10},
title = {{A systematic review and meta-analysis of the efficacy and safety of the interleukin (IL)-12/23 and IL-17 inhibitors ustekinumab, secukinumab, ixekizumab, brodalumab, guselkumab and tildrakizumab for the treatment of moderate to severe plaque psoriasis}},
year = {2018}
}
@article{Bilal2018,
author = {Bilal, Jawad and Berlinberg, Adam and Bhattacharjee, Sandipan and Trost, Jaren and Riaz, Irbaz Bin and Kurtzman, Drew J B},
doi = {10.1080/09546634.2017.1422591},
issn = {0954-6634},
journal = {Journal of Dermatological Treatment},
pages = {1--10},
title = {{A systematic review and meta-analysis of the efficacy and safety of the interleukin (IL)-12/23 and IL-17 inhibitors ustekinumab, secukinumab, ixekizumab, brodalumab, guselkumab and tildrakizumab for the treatment of moderate to severe plaque psoriasis}},
url = {https://doi.org/10.1080/09546634.2017.1422591},
year = {2018}
}
@article{Bock1985,
abstract = {We investigate the properties of several significance tests for distinguishing between the hypothesisH of a “homogeneous” population and an alternativeA involving “clustering” or “heterogeneity,” with emphasis on the case of multidimensional observationsx1, ...,xnϵℝp. Four types of test statistics are considered: the (s-th) largest gap between observations, their mean distance (or similarity), the minimum within-cluster sum of squares resulting from a k-means algorithm, and the resulting maximum F statistic. The asymptotic distributions underH are given forn→∞ and the asymptotic power of the tests is derived for neighboring alternatives.},
author = {Bock, H H},
doi = {10.1007/BF01908065},
issn = {1432-1343},
journal = {Journal of Classification},
number = {1},
pages = {77--108},
title = {{On some significance tests in cluster analysis}},
volume = {2},
year = {1985}
}
@article{Bohm2019,
abstract = {Background: Implementation of an adaptive study design and leveraging historical data have the potential to significantly reduce the number of patients required for a clinical study. Herein we describe the adaptive study design used in the SPYRAL HTN-OFF MED Pivotal trial. Methods: The SPYRAL HTN-OFF MED Pivotal trial is a randomized, sham-controlled trial to evaluate the safety and efficacy of renal denervation in the absence of antihypertensive medications. The powered primary efficacy endpoint is the baseline-adjusted change in 24-h systolic blood pressure at 3 months. A Bayesian adaptive study design with an informative prior was set up to allow enrollment until a sufficient sample size is achieved to have high probability of meeting the primary efficacy endpoint. In this case the informative prior is data from the 80 patients in the previously published SPYRAL HTN-OFF MED trial, and we use a novel statistical method to incorporate this historical data in the analysis. At each of 2 planned interim analyses, the probability of success or futility will be assessed. If either condition is met, enrollment is stopped, and otherwise enrollment continues. A maximum of 300 patients will be evaluated for the primary and secondary endpoints if enrollment continues after both interim analyses. Results: Interim analyses are forthcoming for the SPYRAL HTN-OFF MED Pivotal trial. If enrollment is stopped at the first or second interim analysis because of a high probability of success, results will be available sooner with fewer patients enrolled. Conclusion: A novel Bayesian adaptive study design with an informative prior was implemented in the SPYRAL HTN-OFF MED Pivotal trial to accurately assess the safety and efficacy of renal denervation in the absence of antihypertensive medications, while reducing the number of enrolled patients, exposure to a sham control, and time to presentation of results. Categories: OTHER: Statistics and Trial Design},
annote = {L2002925494
2019-09-27},
author = {B{\"{o}}hm, M and Townsend, R and Weber, M and Kandzari, D and Mahfoud, F and Kario, K and Schmieder, R and Tsioufis, K and DeBruin, V and Hickey, G and Fahy, M and Pocock, S},
doi = {10.1016/j.jacc.2019.08.721},
issn = {1558-3597 0735-1097},
journal = {Journal of the American College of Cardiology},
keywords = {antihypertensive agent adult blood pressure monito},
language = {English LB  - Bohm2019},
number = {13},
pages = {B597},
title = {{TCT-608 Implementation of Bayesian Study Design in the SPYRAL HTN-OFF MED Pivotal Trial}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L2002925494 http://dx.doi.org/10.1016/j.jacc.2019.08.721},
volume = {74},
year = {2019}
}
@article{Boonstra2018,
abstract = {This article considers Bayesian approaches for incorporating information from a historical model into a current analysis when the historical model includes only a subset of covariates currently of interest. The statistical challenge is 2-fold. First, the parameters in the nested historical model are not generally equal to their counterparts in the larger current model, neither in value nor interpretation. Second, because the historical information will not be equally informative for all parameters in the current analysis, additional regularization may be required beyond that provided by the historical information. We propose several novel extensions of the so-called power prior that adaptively combine a prior based upon the historical information with a variance-reducing prior that shrinks parameter values toward zero. The ideas are directly motivated by our work building mortality risk prediction models for pediatric patients receiving extracorporeal membrane oxygenation (ECMO). We have developed a model on a registry-based cohort of ECMO patients and now seek to expand this model with additional biometric measurements, not available in the registry, collected on a small auxiliary cohort. Our adaptive priors are able to use the information in the original model and identify novel mortality risk factors. We support this with a simulation study, which demonstrates the potential for efficiency gains in estimation under a variety of scenarios.},
address = {Department of Biostatistics, University of Michigan, 1415 Washington Hts, SPHII, Ann Arbor, MI, USA. Division of Pediatric Critical Care and Child Health Evaluation and Research Unit, University of Michigan, 1500 East Medical Center Drive, Mott, Ann Arbor},
annote = {1468-4357
Boonstra, Philip S
Barbaro, Ryan P
P30 CA046592/CA/NCI NIH HHS/United States
R01 CA129102/CA/NCI NIH HHS/United States
Journal Article
England
Biostatistics. 2018 Sep 21. pii: 5105903. doi: 10.1093/biostatistics/kxy053.},
author = {Boonstra, P S and Barbaro, R P},
doi = {10.1093/biostatistics/kxy053},
edition = {2018/09/25},
issn = {1465-4644},
journal = {Biostatistics},
language = {eng LB  - Boonstra2018},
title = {{Incorporating historical models with adaptive Bayesian updates}},
year = {2018}
}
@misc{Borchers2019,
author = {Borchers, Hans W.},
title = {{pracma: Practical Numerical Math Functions. R package version 2.2.9. https://cran.r-project.org/package=pracma}},
url = {https://cran.r-project.org/package=pracma},
year = {2019}
}
@article{Boulet2019,
abstract = {Background: Building tools to support personalized medicine needs to model medical decision-making. For this purpose, both expert and real world data provide a rich source of information. Currently, machine learning techniques are developing to select relevant variables for decision-making. Rather than using data-driven analysis alone, eliciting prior information from physicians related to their medical decision-making processes can be useful in variable selection. Our framework is electronic health records data on repeated dose adjustment of Irinotecan for the treatment of metastatic colorectal cancer. We propose a method that incorporates elicited expert weights associated with variables involved in dose reduction decisions into the Stochastic Search Variable Selection (SSVS), a Bayesian variable selection method, by using a power prior. Methods: Clinician experts were first asked to provide numerical clinical relevance weights to express their beliefs about the importance of each variable in their medical decision making. Then, we modeled the link between repeated dose reduction, patient characteristics, and toxicities by assuming a logistic mixed-effects model. Simulated data were generated based on the elicited weights and combined with the observed dose reduction data via a power prior. We compared the Bayesian power prior-based SSVS performance to the usual SSVS in our case study, including a sensitivity analysis using the power prior parameter. Results: The selected variables differ when using only expert knowledge, only the usual SSVS, or combining both. Our method enables one to select rare variables that may be missed using only the observed data and to discard variables that appear to be relevant based on the data but not relevant from the expert perspective. Conclusion: We introduce an innovative Bayesian variable selection method that adaptively combines elicited expert information and real world data. The method selects a set of variables relevant to model medical decision process.},
address = {S. Boulet, INSERM U1138, University Paris Descartes, Sorbonne University, Paris, France},
annote = {L627200342
2019-04-18},
author = {Boulet, S and Ursino, M and Thall, P and Landi, B and Lep{\`{e}}re, C and Pernot, S and Burgun, A and Taieb, J and Zaanan, A and Zohar, S and Jannot, A S},
doi = {10.1177/0962280219841082},
issn = {1477-0334 0962-2802},
journal = {Statistical Methods in Medical Research},
keywords = {adult article clinician controlled study electroni},
language = {English LB  - Boulet2019},
title = {{Integration of elicited expert information via a power prior in Bayesian variable selection: Application to colon cancer data}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L627200342 http://dx.doi.org/10.1177/0962280219841082},
year = {2019}
}
@article{Bousquet2008,
abstract = {This article focused on the definition and the study of a binary Bayesian criterion which measures a statistical agreement between a subjective prior and data information. The setting of this work is concrete Bayesian studies. It is an alternative and a complementary tool to the method recently proposed by Evans and Moshonov, [M. Evans and H. Moshonov, Checking for Prior-data conflict, Bayesian Anal. 1 (2006), pp. 893-914]. Both methods try to help the work of the Bayesian analyst, from preliminary to the posterior computation. Our criterion is defined as a ratio of Kullback-Leibler divergences; two of its main features are to make easy the check of a hierarchical prior and be used as a default calibration tool to obtain flat but proper priors in applications. Discrete and continuous distributions exemplify the approach and an industrial case study in reliability, involving the Weibull distribution, is highlighted.},
address = {INRIA Futurs and Universit{\'{e}}, Paris-Sud XI, France Universit{\'{e}} Laval, Qu{\'{e}}bec, QC, Canada},
annote = {Cited By :17
Export Date: 12 November 2019},
author = {Bousquet, N},
doi = {10.1080/02664760802192981},
journal = {Journal of Applied Statistics},
keywords = {Discrete distributions Expert opinion Kullback-Lei},
number = {9},
pages = {1011--1029},
title = {{Diagnostics of prior-data agreement in applied Bayesian analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-48749112151{\&}doi=10.1080{\%}2F02664760802192981{\&}partnerID=40{\&}md5=8a76aeaea3c14ef07aab8ab4022e4eb3},
volume = {35},
year = {2008}
}
@article{Box1980,
abstract = {[Scientific learning is an iterative process employing Criticism and Estimation. Correspondingly the formulated model factors into two complementary parts--a predictive part allowing model criticism, and a Bayes posterior part allowing estimation. Implications for significance tests, the theory of precise measurement and for ridge estimates are considered. Predictive checking functions for transformation, serial correlation, bad values, and their relation with Bayesian options are considered. Robustness is seen from a Bayesian viewpoint and examples are given. For the bad value problem a comparison with M estimators is made.]},
author = {Box, G E P},
doi = {10.2307/2982063},
issn = {00359238},
journal = {Journal of the Royal Statistical Society. Series A (General)},
number = {4},
pages = {383--430},
title = {{Sampling and Bayes' Inference in Scientific Modelling and Robustness}},
type = {Journal Article},
url = {www.jstor.org/stable/2982063},
volume = {143},
year = {1980}
}
@article{Brard2019,
abstract = {Background: Performing well-powered randomised controlled trials (RCTs) of new treatments for rare diseases is often infeasible. However, with the increasing availability of historical data, incorporating existing information into trials with small sample sizes is appealing in order to increase the power. Bayesian approaches enable one to incorporate historical data into a trial's analysis through a prior distribution. Methods: Motivated by a RCT intended to evaluate the impact on event-free survival of mifamurtide in patients with osteosarcoma, we performed a simulation study to evaluate the impact on trial operating characteristics of incorporating historical individual control data and aggregate treatment effect estimates. We used power priors derived from historical individual control data for baseline parameters of Weibull and piecewise exponential models, while we used a mixture prior to summarise aggregate information obtained on the relative treatment effect. The impact of prior-data conflicts, both with respect to the parameters and survival models, was evaluated for a set of pre-specified weights assigned to the historical information in the prior distributions. Results: The operating characteristics varied according to the weights assigned to each source of historical information, the variance of the informative and vague component of the mixture prior and the level of commensurability between the historical and new data. When historical and new controls follow different survival distributions, we did not observe any advantage of choosing a piecewise exponential model compared to a Weibull model for the new trial analysis. However, we think that it remains appealing given the uncertainty that will often surround the shape of the survival distribution of the new data. Conclusion: In the setting of Sarcome-13 trial, and other similar studies in rare diseases, the gains in power and accuracy made possible by incorporating different types of historical information commensurate with the new trial data have to be balanced against the risk of biased estimates and a possible loss in power if data are not commensurate. The weights allocated to the historical data have to be carefully chosen based on this trade-off. Further simulation studies investigating methods for incorporating historical data are required to generalise the findings. {\textcopyright} 2019 The Author(s).},
address = {Universit{\'{e}} Paris-Saclay, Universit{\'{e}} Paris-Sud, UVSQ, CESP, INSERM, Villejuif, F-94085, France Service de Biostatistique et d'{\'{E}}pid{\'{e}}miologie, Gustave Roussy, Universit{\'{e}} Paris-Saclay, Villejuif, F-94805, France Statistical Methodology, Novartis Pharma AG, Ba},
annote = {Export Date: 12 November 2019},
author = {Brard, C and Hampson, L V and Gaspar, N and {Le Deley}, M C and {Le Teuff}, G},
doi = {10.1186/s12874-019-0714-z},
journal = {BMC Medical Research Methodology},
keywords = {Aggregate treatment effect Bayesian randomised sur},
number = {1},
title = {{Incorporating individual historical controls and aggregate treatment effect estimates into a Bayesian survival trial: A simulation study}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065319521{\&}doi=10.1186{\%}2Fs12874-019-0714-z{\&}partnerID=40{\&}md5=2e090ce59c4b2e944188ac8311b40184},
volume = {19},
year = {2019}
}
@article{Brard2017,
abstract = {Background Bayesian statistics are an appealing alternative to the traditional frequentist approach to designing, analysing, and reporting of clinical trials, especially in rare diseases. Time-to-event endpoints are widely used in many medical fields. There are additional complexities to designing Bayesian survival trials which arise from the need to specify a model for the survival distribution. The objective of this article was to critically review the use and reporting of Bayesian methods in survival trials. Methods A systematic review of clinical trials using Bayesian survival analyses was performed through PubMed and Web of Science databases. This was complemented by a full text search of the online repositories of pre-selected journals. Cost-effectiveness, dose-finding studies, meta-analyses, and methodological papers using clinical trials were excluded. Results In total, 28 articles met the inclusion criteria, 25 were original reports of clinical trials and 3 were re-analyses of a clinical trial. Most trials were in oncology (n = 25), were randomised controlled (n = 21) phase III trials (n = 13), and half considered a rare disease (n = 13). Bayesian approaches were used for monitoring in 14 trials and for the final analysis only in 14 trials. In the latter case, Bayesian survival analyses were used for the primary analysis in four cases, for the secondary analysis in seven cases, and for the trial re-analysis in three cases. Overall, 12 articles reported fitting Bayesian regression models (semi-parametric, n = 3; parametric, n = 9). Prior distributions were often incompletely reported: 20 articles did not define the prior distribution used for the parameter of interest. Over half of the trials used only non-informative priors for monitoring and the final analysis (n = 12) when it was specified. Indeed, no articles fitting Bayesian regression models placed informative priors on the parameter of interest. The prior for the treatment effect was based on historical data in only four trials. Decision rules were pre-defined in eight cases when trials used Bayesian monitoring, and in only one case when trials adopted a Bayesian approach to the final analysis. Conclusion Few trials implemented a Bayesian survival analysis and few incorporated external data into priors. There is scope to improve the quality of reporting of Bayesian methods in survival trials. Extension of the Consolidated Standards of Reporting Trials statement for reporting Bayesian clinical trials is recommended.},
address = {L.V. Hampson, Medical and Pharmaceutical Statistics Research Unit, Department of Mathematics and Statistics, Fylde College, Lancaster University, Lancaster, , United Kingdom},
annote = {L614399703
2017-02-16
2017-03-15},
author = {Brard, C and {Le Teuff}, G and {Le Deley}, M C and Hampson, L V},
doi = {10.1177/1740774516673362},
issn = {1740-7753 1740-7745},
journal = {Clinical Trials},
keywords = {article Bayes theorem cancer research clinical pra},
language = {English LB  - Brard2017},
number = {1},
pages = {78--87},
title = {{Bayesian survival analysis in clinical trials: What methods are used in practice?}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L614399703 http://dx.doi.org/10.1177/1740774516673362},
volume = {14},
year = {2017}
}
@article{Brunner2020,
abstract = {Objectives This ongoing Phase-2, randomised, placebo-controlled, double-blind study evaluated the efficacy, safety and pharmacokinetics of intravenous belimumab in childhood-onset systemic lupus erythematosus (cSLE).Methods Patients (5 to 17 years) were randomised to belimumab 10 mg/kg intravenous or placebo every 4 weeks, plus standard SLE therapy. Primary endpoint: SLE Responder Index (SRI4) response rate (Week 52). Key major secondary endpoints: proportion of patients achieving the Paediatric Rheumatology International Trials Organisation/American College of Rheumatology (PRINTO/ACR) response using 50 and ‘30 alternative' definitions (Week 52), and sustained response (Weeks 44 to 52) by SRI4 and Parent Global Assessment of well-being (Parent-global). Safety and pharmacokinetics were assessed. Study not powered for statistical testing.Results Ninety-three patients were randomised (belimumab, n=53; placebo, n=40). At Week 52, there were numerically more SRI4 responders with belimumab versus placebo (52.8{\%} vs 43.6{\%}; OR 1.49 (95{\%} CI 0.64 to 3.46)). PRINTO/ACR 30 alternative (52.8{\%} vs 27.5{\%}; OR 2.92 (95{\%} CI 1.19 to 7.17)) and PRINTO/ACR 50 (60.4{\%} vs 35.0{\%}; OR 2.74 (95{\%} CI 1.15 to 6.54)) responses were more frequent with belimumab than placebo, as were sustained responses for SRI4 (belimumab, 43.4{\%}; placebo, 41.0{\%}; OR 1.08 (95{\%} CI 0.46 to 2.52)) and Parent-global (belimumab, 59.1{\%}; placebo, 33.3{\%}; OR 3.49 (95{\%} CI 1.23 to 9.91)). Serious adverse events were reported in 17.0{\%} of belimumab patients and 35.0{\%} of placebo patients; one death occurred (placebo). Week-52, geometric mean (95{\%} CI) belimumab trough concentration was 56.2 (45.2 to 69.8) µg/mL.Conclusion The belimumab intravenous pharmacokinetics and benefit–risk profile in cSLE are consistent with adult belimumab studies and the 10 mg/kg every 4 weeks dose is appropriate.Trial registration number NCT01649765.},
author = {Brunner, Hermine I and Abud-Mendoza, Carlos and Viola, Diego O and {Calvo Penades}, Inmaculada and Levy, Deborah and Anton, Jordi and Calderon, Julia E and Chasnyk, Vyacheslav G and Ferrandiz, Manuel A and Keltsev, Vladimir and {Paz Gastanaga}, Maria E and Shishov, Michael and Boteanu, Alina Lucica and Henrickson, Michael and Bass, Damon and Clark, Kenneth and Hammer, Anne and Ji, Beulah N and Nino, Antonio and Roth, David A and Struemper, Herbert and Wang, Mei-Lun and Martini, Alberto and Lovell, Daniel and Ruperto, Nicolino},
doi = {10.1136/annrheumdis-2020-217101},
journal = {Annals of the Rheumatic Diseases},
month = {oct},
number = {10},
pages = {1340 -- 1348},
title = {{Safety and efficacy of intravenous belimumab in children with systemic lupus erythematosus: results from a randomised, placebo-controlled trial}},
url = {http://ard.bmj.com/content/79/10/1340.abstract},
volume = {79},
year = {2020}
}
@article{Campbell2017,
annote = {Cited By :1
Export Date: 1 November 2019},
author = {Campbell, G},
doi = {10.29220/CSAM.2017.24.6.561},
journal = {Communications for Statistical Applications and Methods},
number = {6 LB  - Campbell2017},
pages = {561--581},
title = {{Bayesian methods in clinical trials with applications to medical devices}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044029535{\&}doi=10.29220{\%}2FCSAM.2017.24.6.561{\&}partnerID=40{\&}md5=6686eafab30d87fa35a5281e353a97d2},
volume = {24},
year = {2017}
}
@article{Carrigan2020,
abstract = {Oncology drug development increasingly relies on single-arm clinical trials. External controls (ECs) derived from electronic health record (EHR) databases may provide additional context. Patients from a US-based oncology EHR database were aligned with patients from randomized controlled trials (RCTs) and trial-specific eligibility criteria were applied to the EHR dataset. Overall survival (OS) in the EC-derived control arm was compared with OS in the RCT experimental arm. The primary outcome was OS, defined as time from randomization or treatment initiation (EHR) to death. Cox regression models were used to obtain effect estimates using EHR data. EC-derived hazard ratio estimates aligned closely with those from the corresponding RCT with one exception. Comparing log HRs among all RCT and EC results gave a Pearson correlation coefficient of 0.86. Properly selected control arms from contemporaneous EHR data could be used to put single-arm trials of OS in advanced non-small cell lung cancer into context.},
author = {Carrigan, Gillis and Whipple, Samuel and Capra, William B and Taylor, Michael D and Brown, Jeffrey S and Lu, Michael and Arnieri, Brandon and Copping, Ryan and Rothman, Kenneth J},
doi = {10.1002/cpt.1586},
edition = {2019/10/11},
issn = {1532-6535},
journal = {Clinical pharmacology and therapeutics},
keywords = {*Research Design,Carcinoma, Non-Small-Cell Lung/*drug therapy/morta,Databases, Factual/*statistics {\&} numerical data,Electronic Health Records/*statistics {\&} numerical,Humans,Lung Neoplasms/*drug therapy/mortality,Proportional Hazards Models,Survival Analysis,United States},
language = {eng},
month = {feb},
number = {2},
pages = {369--377},
publisher = {John Wiley and Sons Inc.},
title = {{Using Electronic Health Records to Derive Control Arms for Early Phase Single-Arm Lung Cancer Trials: Proof-of-Concept in Randomized Controlled Trials}},
url = {https://pubmed.ncbi.nlm.nih.gov/31350853 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7006884/},
volume = {107},
year = {2020}
}
@article{Castro2017,
abstract = {Health Technology Assessment requires estimation of long-term outcome of key endpoints such as Overall Survival (OS). Plausibility (external validity) of the OS extrapolation can be tested comparing estimates using Randomized Clinical Trial (RCT) data to long-term observational data if available (Latimer 2013). According to the American Cancer Society, the 5- year survival rate for stage IV metastatic melanoma ranges between 15{\%} and 20{\%} (American Cancer Society 2016). Models previously applied to extrapolate OS using RCT data severely underestimated the 5-year survival rate due to the severity of the disease in the first years of metastatic diagnosis. We used historical data from the Surveillance Epidemiology and End Results that describe long-term survival rates in metastatic melanoma to accurately reflect the survival rates in the active arm (Xing, et al. 2010). We applied a non-parametric Bayesian approach where the historical survival data are first modelled assuming a Dirichlet process. Then, the fitted Dirichlet process constitutes the prior distribution, whereas the Kaplan Meier estimate from the RCT data constitutes the likelihood function. We then update our prior knowledge (from the historical data) using the RCT data and that constitutes the non-parametric Bayesian estimator (Ibrahim, Chen and Sinha 2001). The estimator is defined for the whole time horizon. We estimate OS using an early datacut of BRIM3 study of Zelboraf and validate the results with an updated one. This trial has a long follow up and reflects the expected behavior of the patient population treated with Zelboraf. This non-parametric Bayesian approach may be particularly useful when there is a drastic change in the hazard function e.g. a fraction of the patients is considered “cured”. The “plateau” in the historical survival data can be captured by the Dirichlet process and it will be reflected in the Bayesian estimator.},
address = {Y. Castro, F. Hoffmann-La Roche Ltd. GPMA/Morse, Basel, Switzerland},
annote = {L617070171
2017-07-06},
author = {Castro, Y},
doi = {10.1111/jdv.06-14275},
issn = {1468-3083},
journal = {Journal of the European Academy of Dermatology and Venereology},
keywords = {vemurafenib behavior clinical trial controlled cli},
language = {English LB  - Castro2017},
pages = {65--66},
title = {{Long-term outcome estimation combining real world with clinical trial data in metastatic melanoma following a Bayesian approach}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L617070171 http://dx.doi.org/10.1111/jdv.06-14275},
volume = {31},
year = {2017}
}
@article{Cawston2018,
abstract = {Objectives: The extrapolation of survival curves is key when conducting cost-effectiveness analyses in oncology, which strongly rely on progression-free and overall survival outcomes. Although methodological guidance for extrapolation have been published, the need to choose a specific distribution through internal validation of model fit, and external validation using long-term data remains arbitrary especially if one expects some heterogeneity in outcomes between patients. The objective was to investigate the use of Bayesian Model Averaging (BMA), using randomized controlled trial data in renal cell carcinoma (Checkmate 214). Methods: Parametric and cubic spline survival analyses were implemented in a Bayesian setting using WinBugs. BMA methods were applied, providing a framework for understanding extrapolation uncertainty by considering probabilities of the distribution selected being the most appropriate given the data. Survival curves were weighted in order to obtain one single extrapolation. This distribution was first weighted on the basis of BIC statistics, using an uninformative prior. The use of informative priors through the elicitation of expert opinions and real world evidence was also investigated. Results: With uninformative priors, the OS extrapolation was driven by the log-normal distribution which obtained a weight of 73{\%} followed by the normal cubic spline model with one knot which obtained a weight of 9{\%}. The mean curve was similar to the distribution with best fit (log-normal). The inclusion of informative priors was evaluated through the use of external studies and experts opinions. Conclusions: The BMA method is a useful additional tool to the currently recognised methodological guidance on extrapolation. With the underlying assumption that no one distribution is appropriate through the entire time horizon given clinical heterogeneity, it allows to empirically account for all data sources in choices of extrapolations through informative priors and the likelihood itself and accounts for the structural uncertainty associated with the choice of distribution.},
annote = {L2001402164
2018-12-28},
author = {Cawston, H and Genestier, V and Dale, P and Doan, J and Malcolm, B},
doi = {10.1016/j.jval.2018.09.2363},
issn = {1524-4733 1098-3015},
journal = {Value in Health},
keywords = {averaging body weight cancer survival conference a},
language = {English LB  - Cawston2018},
pages = {S398},
title = {{EXTRAPOLATION OF SURVIVAL IN THE CONTEXT OF ECONOMIC MODELLING USING BAYESIAN MODEL AVERAGING: AN APPLICATION IN RENAL CELL CARCINOMA}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L2001402164 http://dx.doi.org/10.1016/j.jval.2018.09.2363},
volume = {21},
year = {2018}
}
@article{Chen2014,
abstract = {Recently, the Center for Drug Evaluation and Research at the Food and Drug Administration released a guidance that makes recommendations about how to demonstrate that a new antidiabetic therapy to treat type 2 diabetes is not associated with an unacceptable increase in cardiovascular risk. One of the recommendations from the guidance is that phases II and III trials should be appropriately designed and conducted so that a meta-analysis can be performed. In addition, the guidance implies that a sequential meta-analysis strategy could be adopted. That is, the initial meta-analysis could aim at demonstrating the upper bound of a 95{\%} confidence interval (CI) for the estimated hazard ratio to be{\textless}1.8 for the purpose of enabling a new drug application or a biologics license application. Subsequently after the marketing authorization, a final meta-analysis would need to show the upper bound to be{\textless}1.3. In this context, we develop a new Bayesian sequential meta-analysis approach using survival regression models to assess whether the size of a clinical development program is adequate to evaluate a particular safety endpoint. We propose a Bayesian sample size determination methodology for sequential meta-analysis clinical trial design with a focus on controlling the familywise type I error rate and power. We use the partial borrowing power prior to incorporate the historical survival meta-data into the Bayesian design. We examine various properties of the proposed methodology, and simulation-based computational algorithms are developed to generate predictive data at various interim analyses, sample from the posterior distributions, and compute various quantities such as the power and the type I error in the Bayesian sequential meta-analysis trial design. We apply the proposed methodology to the design of a hypothetical antidiabetic drug development program for evaluating cardiovascular risk. {\textcopyright} 2013 John Wiley {\&} Sons, Ltd.},
address = {J.G. Ibrahim, Department of Biostatistics, University of North Carolina, Chapel Hill, NC 27599, United States},
annote = {L52926830
2013-12-24
2014-04-16},
author = {Chen, M H and Ibrahim, J G and {Amy Xia}, H and Liu, T and Hennessey, V},
doi = {10.1002/sim.6067},
issn = {1097-0258 0277-6715},
journal = {Statistics in Medicine},
keywords = {antidiabetic agent algorithm article Bayes theorem},
language = {English LB  - Chen2014a},
number = {9},
pages = {1600--1618},
title = {{Bayesian sequential meta-analysis design in evaluating cardiovascular risk in a new antidiabetic drug development program}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L52926830 http://dx.doi.org/10.1002/sim.6067},
volume = {33},
year = {2014}
}
@article{Chen2011,
abstract = {We develop a new Bayesian approach of sample size determination (SSD) for the design of noninferiority clinical trials. We extend the fitting and sampling priors of Wang and Gelfand (2002, Statistical Science17, 193-208) to Bayesian SSD with a focus on controlling the type I error and power. Historical data are incorporated via a hierarchical modeling approach as well as the power prior approach of Ibrahim and Chen (2000, Statistical Science15, 46-60). Various properties of the proposed Bayesian SSD methodology are examined and a simulation-based computational algorithm is developed. The proposed methodology is applied to the design of a noninferiority medical device clinical trial with historical data from previous trials. {\textcopyright} 2011, The International Biometric Society.},
address = {M.-H. Chen, Department of Statistics, University of Connecticut, 215 Glenbrook Road, Storrs, CT 06269, United States},
annote = {L51353881
2012-02-29},
author = {Chen, M H and Ibrahim, J G and Lam, P and Yu, A and Zhang, Y},
doi = {10.1111/j.1541-0420.2011.01561.x},
issn = {0006-341X 1541-0420},
journal = {Biometrics},
keywords = {article Bayes theorem biometry clinical trial (top},
language = {English LB  - Chen2011},
number = {3},
pages = {1163--1170},
title = {{Bayesian Design of Noninferiority Trials for Medical Devices Using Historical Data}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L51353881 http://dx.doi.org/10.1111/j.1541-0420.2011.01561.x},
volume = {67},
year = {2011}
}
@article{Chen2014a,
abstract = {In many biomedical studies, patients may experience the same type of recurrent event repeatedly over time, such as bleeding, multiple infections and disease. In this article, we propose a Bayesian design to a pivotal clinical trial in which lower risk myelodysplastic syndromes (MDS) patients are treated with MDS disease modifying therapies. One of the key study objectives is to demonstrate the investigational product (treatment) effect on reduction of platelet transfusion and bleeding events while receiving MDS therapies. In this context, we propose a new Bayesian approach for the design of superiority clinical trials using recurrent events frailty regression models. Historical recurrent events data from an already completed phase 2 trial are incorporated into the Bayesian design via the partial borrowing power prior of Ibrahim et al. (2012, Biometrics 68, 578-586). An efficient Gibbs sampling algorithm, a predictive data generation algorithm, and a simulation-based algorithm are developed for sampling from the fitting posterior distribution, generating the predictive recurrent events data, and computing various design quantities such as the type I error rate and power, respectively. An extensive simulation study is conducted to compare the proposed method to the existing frequentist methods and to investigate various operating characteristics of the proposed design.},
annote = {L609601808
2016-04-11},
author = {Chen, M H and Ibrahim, J G and Zeng, D and Hu, K and Jia, C},
doi = {10.1111/biom.12215},
issn = {1541-0420},
journal = {Biometrics},
keywords = {algorithm Bayes theorem blood transfusion clinical},
language = {English LB  - Chen2014b},
number = {4},
pages = {1003--1013},
title = {{Bayesian design of superiority clinical trials for recurrent events data with applications to bleeding and transfusion events in myelodyplastic syndrome}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L609601808 http://dx.doi.org/10.1111/biom.12215},
volume = {70},
year = {2014}
}
@article{Cheng2019,
abstract = {We consider a situation where there is rich historical data available for the coefficients and their standard errors in an established regression model describing the association between a binary outcome variable Y and a set of predicting factors X, from a large study. We would like to utilize this summary information for improving estimation and prediction in an expanded model of interest, Y| X, B. The additional variable B is a new biomarker, measured on a small number of subjects in a new dataset. We develop and evaluate several approaches for translating the external information into constraints on regression coefficients in a logistic regression model of Y| X, B. Borrowing from the measurement error literature we establish an approximate relationship between the regression coefficients in the models Pr(Y = 1| X , beta), Pr(Y = 1| X, B, gamma) and E(B| X, theta ) for a Gaussian distribution of B. For binary B we propose an alternate expression. The simulation results comparing these methods indicate that historical information on Pr(Y = 1| X , beta) can improve the efficiency of estimation and enhance the predictive power in the regression model of interest Pr(Y = 1| X, B, gamma). We illustrate our methodology by enhancing the High-grade Prostate Cancer Prevention Trial Risk Calculator, with two new biomarkers prostate cancer antigen 3 and TMPRSS2:ERG.},
address = {University of Michigan, Ann Arbor, Michigan, USA.},
annote = {Cheng, Wenting
Taylor, Jeremy M G
Gu, Tian
Tomlins, Scott A
Mukherjee, Bhramar
R01 CA129102/CA/NCI NIH HHS/United States
Journal Article
England
J R Stat Soc Ser C Appl Stat. 2019 Jan;68(1):121-139. doi: 10.1111/rssc.12306. Epub 2018 Aug 13.},
author = {Cheng, W and Taylor, J M G and Gu, T and Tomlins, S A and Mukherjee, B},
doi = {10.1111/rssc.12306},
edition = {2019/05/21},
issn = {0035-9254 (Print) 0035-9254},
journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
keywords = {Bayesian methods Constrained estimation Logistic r},
language = {eng LB  - Cheng2019},
number = {1},
pages = {121--139},
title = {{Informing a Risk Prediction Model for Binary Outcomes with External Coefficient Information}},
volume = {68},
year = {2019}
}
@article{Chowdhury2019,
author = {Chowdhury, Shrabanti and Tiwari, Ram C and Ghosh, Samiran},
doi = {10.1080/19466315.2018.1554504},
journal = {Statistics in Biopharmaceutical Research},
number = {1},
pages = {34--43},
title = {{Bayesian Approach for Assessing Non-Inferiority in Three-Arm Trials for Risk Ratio and Odds Ratio}},
volume = {11},
year = {2019}
}
@article{Chung2018,
author = {Chung, Neo Christopher},
journal = {bioR$\chi$iv (preprint)},
title = {{Statistical significance of cluster membership for determination of cell identities in single cell genomics}},
year = {2018}
}
@article{Cingoz2009,
abstract = {Ustekinumab is an anti-IL12/23 IgG1 kappa human monoclonal antibody currently undergoing US Food and Drug Administration review for use as a psoriasis treatment. The candidate has also been evaluated in Phase 2 studies as a treatment for psoriatic arthritis, Crohn disease and multiple sclerosis. In large clinical trials, ustekinumab has proven effective for treating moderate to severe plaque psoriasis. Although long-term follow-up studies are needed to address safety concerns, the hopes are high for psoriasis treatment. Ustekinumab has recently been approved for marketing in Canada and Europe.},
author = {Cingoz, Oya},
issn = {1942-0862},
journal = {mAbs},
number = {3},
pages = {216--221},
title = {{Ustekinumab}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2726595/},
volume = {1},
year = {2009}
}
@book{Coalition2016,
abstract = {This is a summary table of ongoing and planned global PrEP evaluation studies. A sortable Excel version is available here.},
author = {Coalition, AIDS Vaccine Advocacy},
language = {en},
title = {{Ongoing and Planned PrEP Demonstration and Implementation Studies}},
year = {2016}
}
@book{Cohen2003,
abstract = {The Applied Multiple Regression (LRM) model has been in use in statistical analyses for many years; but it was not until the late 1960's that a model was used to provide a multivariate analysis of the Katsulares/Mitri heart study data that its full power and applicability were totally appreciated. Since then the LRM model has become the standard method for regression analysis of dichotomous data in many fields, especially in the health sciences. This new and updated edition of the classic bestseller provides a focused introduction to the LRM model and its use in methods for modeling the relationship between a dichotomous outcome variable and a set of covariables.},
author = {Cohen, Jacob and Cohen, Patricia},
language = {English LB  - Cohen2003},
publisher = {L. Erlbaum Associates},
title = {{Applied multiple regression/correlation analysis for the behavioral sciences}},
year = {2003}
}
@article{Collignon2019,
abstract = {There has been increasing interest in recent years in the possibility of increasing the efficiency of clinical trials by using historical controls. There has been a general recognition that in replacing concurrent by historical controls, the potential for bias is serious and requires some down-weighting to the apparent amount of historical information available. However, such approaches have generally assumed that what is required is some modification to the standard inferential model offered by the parallel group trial. In our opinion, the correct starting point that requires modification is a trial in which treatments are allocated to clusters. This immediately shows that the amount of information available is governed not just by the number of historical patients but also by the number of centres and of historical studies. Furthermore, once one accepts that external patients may be used as controls, this raises the issue as to which patients should be used. Thus, abandoning concurrent control has implications for many aspects of design and analysis of trials, including (a) identification, pre-specification and agreement on a suitable historical dataset; (b) an agreed, enforceable and checkable plan for recruiting the experimental arm; (c) a finalised analysis plan prior to beginning the trial and (d) use of a hierarchical model with sufficient complexity. We discuss these issues and suggest approaches to design and analysis making extensive reference to the partially randomised Therapeutic Arthritis Research and Gastrointestinal Event Trial study. We also compare some Bayesian and frequentist approaches and provide some important regulatory considerations. We conclude that effective use of historical data will require considerable circumspection and discipline.},
annote = {L629563293},
author = {Collignon, O and Schritz, A and Senn, S J and Spezia, R},
doi = {10.1177/0962280219880213},
issn = {1477-0334},
journal = {Statistical methods in medical research},
keywords = {adult arthritis article controlled study female hu},
language = {English LB  - Collignon2019},
pages = {962280219880213},
title = {{Clustered allocation as a way of understanding historical controls: Components of variation and regulatory considerations}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L629563293 http://dx.doi.org/10.1177/0962280219880213},
year = {2019}
}
@article{USCongress20162016,
author = {Congress, U.S.},
title = {{21st Century Cures Act (Pubic Law 114-255, 130 STAT 1033-1344)}},
year = {2016}
}
@article{Cottler2017,
abstract = {Background Although drug use is common in the population, drug users are sometimes excluded from research without justification. Two models of individualized study matching were compared for effectiveness in enrolling people who “endorsed current drug use” and those who “did not” into appropriate research. Methods Participants in the NIDA-funded Transformative Approach to Reduce Research Disparities Towards Drug Users study (Navigation Study) were recruited through a Clinical and Translational Science Award (CTSA) community engagement model. Of the 614 community-recruited adults, 326 endorsed current drug use (cases); 288 did not (controls). Participants were randomized to one of two intervention groups: Navigation as Usual (NAU) [individualized study matching through a Study Navigator] or Enhanced Navigation (N+) [individualized study matching plus transportation and other assistance through an Ambassador]. Rates of enrollment into research studies were compared. Results At 90 days, N+ vs. the NAU intervention was associated with higher enrollment among both drug users (36.0{\%} N+ vs. 24.9{\%} NAU) and non-drug users (45.5{\%} N+ vs. 25.2{\%} NAU). NAU attained the same rate of enrollment for users of drugs (24.9{\%}) and non-users (25.2{\%}); N+ had similar rates as well (36.0{\%} drug users vs. 45.5{\%} non-drug users). In addition, high rates of enrollment were achieved among all groups of participants, from 24.9{\%} (drug users in NAU) to 45.5{\%} (non-drug users in N+). Conclusions Both the NAU and N+ methods can reduce barriers and help users and non-users become part of the population that participates in research. Working with the local CTSA adds significant value to the research enterprise.},
author = {Cottler, Linda B. and Striley, Catherine W. and Elliott, Amy L. and Zulich, Abigail E. and Kwiatkowski, Evan and Nelson, David R.},
doi = {10.1016/j.drugalcdep.2016.12.031},
issn = {18790046},
journal = {Drug and Alcohol Dependence},
keywords = {Ambassador,CHWs,Drug use,Inclusive research,Navigation,RCT,Research participation},
pmid = {28419890},
title = {{Pragmatic trial of a Study Navigator Model (NAU) vs. Ambassador Model (N+) to increase enrollment to health research among community members who use illicit drugs}},
year = {2017}
}
@article{Cottler2017a,
abstract = {Aims: The aim of these analyses is to describe the association between what participants reported to have in their family's medicine cabinet when a teenager and future opioid dependence in a community sample of drug users. Methods: Data was analyzed from the Prescription Drug Misuse, Abuse, and Dependence NIDA funded study (PI: Dr. Linda Cottler). Participants aged 18+ were screened for use of prescription sedatives, stimulants and opioids in the past 12 months with the Risk Behavior Assessment and the Substance Abuse Module. As part of the information assessed, interviewers asked: "If we looked in your family's medicine cabinet when you were about 14, what medicines would we have found?" and "When you were growing up, did you feel there was a pill for everything?". Participants described up to 12 medications; any who mentioned an opioid were counted as medicine cabinet opioid positive. Lifetime opioid dependence was determined via self-report using DSM-IV criteria with dependence vs abuse/no dependence. Chi-square tests and logistic regression described the associations. Results: Of the 418 respondents, 378 (90{\%}) reported current use of opioids and are included in these analyses. Of them, 9{\%} reported a drug in their family's medicine cabinet at age 14 that counted as an opioid, 40{\%} met criteria for opioid dependence at some point in their lifetime, and 27{\%} reported that there was a pill for everything. The logistic regression found that controlling for gender, there was a strong trend for the association between opioids and content of opioids being recollected in the medicine cabinet; per sons who were currently opioid dependent were more likely to feel that growing up there was a pill for everything (OR = 1.15; CI 1.02-1.29). Conclusions: There was a significant association between feeling there was a pill for everything growing up and DSM-IV dependence, but a trend for the contents of the family's medicine cabinet. A larger study is needed on this important indicator.},
author = {Cottler, Linda and Kwiatkowski, Evan and Striley, Catherine Woodstock},
doi = {10.1016/j.drugalcdep.2016.08.140},
issn = {03768716},
journal = {Drug and Alcohol Dependence},
title = {{What's in your medicine cabinet? Gender differences}},
year = {2017}
}
@article{Crooke2017,
author = {Crooke, Hannah Renee and Cottler, Linda and Kwiatkowski, Evan and Striley, Catherine Woodstock},
doi = {10.1016/j.drugalcdep.2016.08.144},
issn = {03768716},
journal = {Drug and Alcohol Dependence},
title = {{Hypertension medication use among past 30-day marijuana users in a community sample from northeast Florida}},
year = {2017}
}
@article{DAgostino2002,
author = {D'Agostino, Ralph B and Massaro, Joseph M and Sullivan, Lisa},
journal = {Statistics in medicine},
pages = {169--186},
title = {{Non-inferiority trials: design concepts and issues - the encounters of academic consultants in statistics.}},
volume = {22 2},
year = {2002}
}
@article{Damschroder2009,
abstract = {Background Many interventions found to be effective in health services research studies fail to translate into meaningful patient care outcomes across multiple contexts. Health services researchers recognize the need to evaluate not only summative outcomes but also formative outcomes to assess the extent to which implementation is effective in a specific setting, prolongs sustainability, and promotes dissemination into other settings. Many implementation theories have been published to help promote effective implementation. However, they overlap considerably in the constructs included in individual theories, and a comparison of theories reveals that each is missing important constructs included in other theories. In addition, terminology and definitions are not consistent across theories. We describe the Consolidated Framework For Implementation Research (CFIR) that offers an overarching typology to promote implementation theory development and verification about what works where and why across multiple contexts. Methods We used a snowball sampling approach to identify published theories that were evaluated to identify constructs based on strength of conceptual or empirical support for influence on implementation, consistency in definitions, alignment with our own findings, and potential for measurement. We combined constructs across published theories that had different labels but were redundant or overlapping in definition, and we parsed apart constructs that conflated underlying concepts. Results The CFIR is composed of five major domains: intervention characteristics, outer setting, inner setting, characteristics of the individuals involved, and the process of implementation. Eight constructs were identified related to the intervention (e.g., evidence strength and quality), four constructs were identified related to outer setting (e.g., patient needs and resources), 12 constructs were identified related to inner setting (e.g., culture, leadership engagement), five constructs were identified related to individual characteristics, and eight constructs were identified related to process (e.g., plan, evaluate, and reflect). We present explicit definitions for each construct. Conclusion The CFIR provides a pragmatic structure for approaching complex, interacting, multi-level, and transient states of constructs in the real world by embracing, consolidating, and unifying key constructs from published implementation theories. It can be used to guide formative evaluations and build the implementation knowledge base across multiple studies and settings.},
author = {Damschroder, Laura J and Aron, David C and Keith, Rosalind E and Kirsh, Susan R and Alexander, Jeffery A and Lowery, Julie C},
doi = {10.1186/1748-5908-4-50},
issn = {1748-5908},
journal = {Implementation Science : IS},
pages = {50},
title = {{Fostering implementation of health services research findings into practice: a consolidated framework for advancing implementation science}},
volume = {4},
year = {2009}
}
@article{Dane2014,
abstract = {AbstractAt present, there are situations in antibiotic drug development where the low number of enrollable patients with key problem pathogens makes it impossible to conduct fully powered non-inferiority trials in the traditional way. Recent regulatory changes have begun to address this situation. In parallel, statistical issues regarding the application of alternative techniques, balancing the unmet need with the level of certainty in the approval process, and the use of additional sources of data are critical areas to increase development feasibility. Although such approaches increase uncertainty compared with a traditional development program, this will be necessary to allow new agents to be made available. Identification of these risks and explicit discussion around requirements in these areas should help clarify the situation, and hence, the feasibility of developing drugs to treat the most concerning pathogens before the unmet need becomes even more acute than at present. Copyright {\textcopyright} 2014 John Wiley {\&} Sons, Ltd.},
author = {Dane, Aaron and Wetherington, Jeffrey D},
doi = {10.1002/pst.1625},
issn = {1539-1604},
number = {4},
pages = {222--228},
title = {{Statistical considerations associated with a comprehensive regulatory framework to address the unmet need for new antibacterial therapies}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1625},
volume = {13},
year = {2014}
}
@article{DeSantis2006,
annote = {Cited By :15
Export Date: 1 November 2019},
author = {{De Santis}, F},
doi = {10.1198/000313006X109269},
journal = {American Statistician},
number = {2 LB  - DeSantis2006},
pages = {122--129},
title = {{Power priors and their use in clinical trials}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33744509671{\&}doi=10.1198{\%}2F000313006X109269{\&}partnerID=40{\&}md5=f5bd481a5b96c9a359391eae5168f738},
volume = {60},
year = {2006}
}
@article{Dejardin2018,
abstract = {When recruitment into a clinical trial is limited due to rarity of the disease of interest, or when recruitment to the control arm is limited due to ethical reasons (eg, pediatric studies or important unmet medical need), exploiting historical controls to augment the prospectively collected database can be an attractive option. Statistical methods for combining historical data with randomized data, while accounting for the incompatibility between the two, have been recently proposed and remain an active field of research. The current literature is lacking a rigorous comparison between methods but also guidelines about their use in practice. In this paper, we compare the existing methods based on a confirmatory phase III study design exercise done for a new antibacterial therapy with a binary endpoint and a single historical dataset. A procedure to assess the relative performance of the different methods for borrowing information from historical control data is proposed, and practical questions related to the selection and implementation of methods are discussed. Based on our examination, we found that the methods have a comparable performance, but we recommend the robust mixture prior for its ease of implementation.},
address = {D. Dejardin, Department of Biostatistics, F. Hoffmann-La Roche, Basel, Switzerland},
annote = {L621500123
2018-04-05
2018-04-12},
author = {Dejardin, D and Delmar, P and Warne, C and Patel, K and van Rosmalen, J and Lesaffre, E},
doi = {10.1002/pst.1843},
issn = {1539-1612 1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {antiinfective agent article Bayes theorem case stu},
language = {English LB  - Dejardin2018},
number = {2},
pages = {169--181},
title = {{Use of a historical control group in a noninferiority trial assessing a new antibacterial treatment: A case study and discussion of practical implementation aspects}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L621500123 http://dx.doi.org/10.1002/pst.1843},
volume = {17},
year = {2018}
}
@article{Desgraupes2018,
author = {Desgraupes, Bernard},
journal = {R package documentation},
title = {{Package ‘clusterCrit'}},
year = {2018}
}
@book{Draper1998,
address = {Hoboken, New Jersey},
author = {Draper, Norman Richard},
booktitle = {Wiley series in probability and statistics.},
edition = {Third edit},
editor = {Smith, Harry},
isbn = {9781118625620 (e-book)},
language = {English LB  - Draper1998},
publisher = {John Wiley $\backslash${\&} Sons, Inc.},
title = {{Applied regression analysis}},
url = {http://ezproxy.villanova.edu/login?URL=http://ebookcentral.proquest.com/lib/villanova-ebooks/detail.action?docID=1775203},
year = {1998}
}
@article{Dron2019,
abstract = {Background: Enrollment of participants to control arms in clinical trials can be challenging. This is particularly an issue in oncology trials where the standard-of-care is shifting rapidly and several promising experimental treatments are undergoing phase III testing. Novel methods for utilizing external control data may mitigate these challenges, but applied examples are sparse. Here, we therefore illustrate how Bayesian dynamic borrowing of external individual patient level control data from similar clinical trials can often reduce randomization to the control intervention without substantially trading-off precision. We further explore which types of scenarios yield viable trade-offs, and which do not. Patients and methods: We obtained individual patient data on patients being treated with second-line therapy for non-small cell lung cancer from Project Data Sphere with minimal in/exclusion criteria restrictions, and applied Bayesian hierarchical models with uninformative priors to generate illustrative synthetic control groups. Results: Four phase III clinical trials were identified and utilized in our analysis. Even when studies which are knowingly incongruent with one another are selected to generate a synthetic control, the nature of this methodology minimizes improper borrowing from historical data. The use of a small concurrent control group within a trial greatly reduces penalized selection, and our results demonstrate the ability to reduce allocation to the control group by up to 80{\%} with a minimal increase in uncertainty when closely matched historical data is available. Conclusion: Dynamic borrowing using Bayesian hierarchical models with uninformative priors represents a novel approach to utilizing external controls for comparative estimates using single arm evidence.},
address = {K. Thorlund, Department of Health Research Methodology, Evidence, and Impact, McMaster University, Hamilton, Canada},
annote = {L2002868584
2019-09-20},
author = {Dron, L and Golchi, S and Hsu, G and Thorlund, K},
doi = {10.1016/j.conctc.2019.100446},
issn = {2451-8654},
journal = {Contemporary Clinical Trials Communications},
keywords = {article cancer therapy clinical assessment clinica},
language = {English LB  - Dron2019},
title = {{Minimizing control group allocation in randomized trials using dynamic borrowing of external control data – An application to second line therapy for non-small cell lung cancer}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L2002868584 http://dx.doi.org/10.1016/j.conctc.2019.100446},
volume = {16},
year = {2019}
}
@article{Durrleman1990,
abstract = {Demonstrating therapeutic equivalence of two treatments is the goal of many clinical trials. For instance, when the toxicity of an effective standard treatment is of concern, much effort is devoted to developing new therapies that would be both as effective and less toxic. In this paper we review the special characteristics of these trials and describe sequential monitoring of equivalence studies using repeated confidence intervals. We show how sequential monitoring may be of particular value in this setting and critically discuss the choice of some important design parameters. We also provide tables for use when planning a sequential equivalence trial.},
author = {Durrleman, Sylvain and Simon, Richard},
issn = {0006341X, 15410420},
journal = {Biometrics},
number = {2},
pages = {329--336},
title = {{Planning and Monitoring of Equivalence Studies}},
volume = {46},
year = {1990}
}
@article{Eekhout2018,
abstract = {Previous studies showed that missing data in multi-item scales can best be handled by multiple imputation of item scores. However, when many scales are used, the number of items will become too large for the imputation model to reliably estimate imputations. A solution is to use passive imputation or a parcel summary score that combine and consequently reduce the number of variables in the imputation model. The performance of these methods was evaluated in a simulation study and illustrated in an example. Passive imputation, which updated scale scores from imputed items, and parcel summary scores that use the average over available item scores were compared to using all items simultaneously, imputing total scores of scales and complete-case analysis. Scale scores and coefficient estimates from linear regression were compared to “true” parameters on bias and precision. Passive imputation and using parcel summaries showed smaller bias and more precision than imputing total scores and complete-case analyses. Passive imputation or using parcel summary scores are valid missing data solutions in studies that include many multi-item scales.},
author = {Eekhout, Iris and de Vet, Henrica C W and de Boer, Michiel R and Twisk, Jos W R and Heymans, Martijn W},
doi = {10.1177/0962280216654511},
keywords = {Multiple imputation,missing data,questionnaires,it},
number = {4},
pages = {1128--1140},
title = {{Passive imputation and parcel summaries are both valid to handle missing items in studies with many multi-item scales}},
url = {https://journals.sagepub.com/doi/abs/10.1177/0962280216654511},
volume = {27},
year = {2018}
}
@article{Eekhout2014,
abstract = {Objectives Regardless of the proportion of missing values, complete-case analysis is most frequently applied, although advanced techniques such as multiple imputation (MI) are available. The objective of this study was to explore the performance of simple and more advanced methods for handling missing data in cases when some, many, or all item scores are missing in a multi-item instrument. Study Design and Setting Real-life missing data situations were simulated in a multi-item variable used as a covariate in a linear regression model. Various missing data mechanisms were simulated with an increasing percentage of missing data. Subsequently, several techniques to handle missing data were applied to decide on the most optimal technique for each scenario. Fitted regression coefficients were compared using the bias and coverage as performance parameters. Results Mean imputation caused biased estimates in every missing data scenario when data are missing for more than 10{\%} of the subjects. Furthermore, when a large percentage of subjects had missing items ({\textgreater}25{\%}), MI methods applied to the items outperformed methods applied to the total score. Conclusion We recommend applying MI to the item scores to get the most accurate regression model estimates. Moreover, we advise not to use any form of mean imputation to handle missing data.},
author = {Eekhout, Iris and de Vet, Henrica C W and Twisk, Jos W R and Brand, Jaap P L and de Boer, Michiel R and Heymans, Martijn W},
doi = {https://doi.org/10.1016/j.jclinepi.2013.09.009},
issn = {0895-4356},
journal = {Journal of Clinical Epidemiology},
keywords = {Missing data Multiple imputation Multi-item questi},
number = {3},
pages = {335--342},
title = {{Missing data in a multi-item instrument were best handled by multiple imputation at the item score level}},
url = {http://www.sciencedirect.com/science/article/pii/S0895435613003879},
volume = {67},
year = {2014}
}
@article{Eggleston2017,
abstract = {Immune Thrombocytopenia is an autoimmune disease associated with bleeding that is treated by increasing the platelet count to a level where the chance of uncontrollable bleeding is low. Failure occurs when platelet counts are not raised sufficiently (initial failure), or when high platelet counts are not maintained after initial success (relapse). In this paper, we propose a Bayesian clinical trial design that uses a Markov multistate model along with a power prior for the parameters which incorporates historical control data to estimate transition rates among two randomized groups as defined by the model. A detailed simulation is carried out to examine the operating characteristics of a trial to test whether a new treatment reduces the relapse rate by 40{\%} relative to standard care when data from 60 historical controls treated with standard care is available. We also use simulated data to demonstrate effects of discordance between historical and randomized controls on the estimated hazard ratios. Finally, we use a simulated trial to demonstrate briefly what type of results the model can give and how those results can be used to address hypotheses regarding treatment effects. Using simulated data, we show that the model yields good operating characteristics when the historical and randomized controls are from the same population, and demonstrate how discordance between the control groups affects the operating characteristics.},
address = {J.G. Ibrahim, Department of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, NC, United States},
annote = {L614575285
2017-03-02
2018-07-20},
author = {Eggleston, B S and Ibrahim, J G and Catellier, D},
doi = {10.1016/j.cct.2017.02.004},
issn = {1559-2030 1551-7144},
journal = {Contemporary Clinical Trials},
keywords = {article autoimmune disease Bayes theorem clinical },
language = {English LB  - Eggleston2017},
pages = {73--83},
title = {{Bayesian clinical trial design using Markov models with applications to autoimmune disease}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L614575285 http://dx.doi.org/10.1016/j.cct.2017.02.004},
volume = {63},
year = {2017}
}
@article{Ehrhart2014,
abstract = {BACKGROUND: Although the importance of the organizational environment for implementing evidence-based practices (EBP) has been widely recognized, there are limited options for measuring implementation climate in public sector health settings. The goal of this research was to develop and test a measure of EBP implementation climate that would both capture a broad range of issues important for effective EBP implementation and be of practical use to researchers and managers seeking to understand and improve the implementation of EBPs. METHODS: Participants were 630 clinicians working in 128 work groups in 32 US-based mental health agencies. Items to measure climate for EBP implementation were developed based on past literature on implementation climate and other strategic climates and in consultation with experts on the implementation of EBPs in mental health settings. The sample was randomly split at the work group level of analysis; half of the sample was used for exploratory factor analysis (EFA), and the other half was used for confirmatory factor analysis (CFA). The entire sample was utilized for additional analyses assessing the reliability, support for level of aggregation, and construct-based evidence of validity. RESULTS: The EFA resulted in a final factor structure of six dimensions for the Implementation Climate Scale (ICS): 1) focus on EBP, 2) educational support for EBP, 3) recognition for EBP, 4) rewards for EBP, 5) selection for EBP, and 6) selection for openness. This structure was supported in the other half of the sample using CFA. Additional analyses supported the reliability and construct-based evidence of validity for the ICS, as well as the aggregation of the measure to the work group level. CONCLUSIONS: The ICS is a very brief (18 item) and pragmatic measure of a strategic climate for EBP implementation. It captures six dimensions of the organizational context that indicate to employees the extent to which their organization prioritizes and values the successful implementation of EBPs. The ICS can be used by researchers to better understand the role of the organizational context on implementation outcomes and by organizations to evaluate their current climate as they consider how to improve the likelihood of implementation success.},
author = {Ehrhart, Mark G and Aarons, Gregory A and Farahnak, Lauren R},
doi = {10.1186/s13012-014-0157-1},
issn = {1748-5908},
journal = {Implementation science: IS},
keywords = {Humans Statistical Female Male Middle Aged Califor},
language = {eng},
pages = {157},
title = {{Assessing the organizational context for EBP implementation: the development and validity testing of the Implementation Climate Scale (ICS)}},
volume = {9},
year = {2014}
}
@article{Evans2011,
abstract = {We consider checking for prior-data conflict in a Bayesian analysis via a tail probability based on the prior predictive distribution. We establish the appropriateness of this measure in the sense that the limiting value of the tail probability measures the extent to which the true value of the parameter is a surprising value from the prior. {\textcopyright} 2011 Elsevier B.V.},
address = {Department of Statistics, University of Toronto, Canada Department of Biostatistics and Epidemiology, University of Pennsylvania, United States},
annote = {Cited By :14
Export Date: 12 November 2019},
author = {Evans, M and Jang, G H},
doi = {10.1016/j.spl.2011.02.025},
journal = {Statistics and Probability Letters},
keywords = {Convergence Minimal sufficiency Prior predictive P},
number = {8},
pages = {1034--1038},
title = {{A limit result for the prior predictive applied to checking for prior-data conflict}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956209495{\&}doi=10.1016{\%}2Fj.spl.2011.02.025{\&}partnerID=40{\&}md5=5febc10a885414093d5ccfc2cfb55731},
volume = {81},
year = {2011}
}
@article{Evans2006,
abstract = {Inference proceeds from ingredients chosen by the analyst and data. To validate any inferences drawn it is essential that the inputs chosen be deemed appropriate for the data. In the Bayesian context these inputs consist of both the sampling model and the prior. There are thus two possibilities for failure: the data may not have arisen from the sampling model, or the prior may place most of its mass on parameter values that are not feasible in light of the data (referred to here as prior-data conflict). Failure of the sampling model can only be fixed by modifying the model, while prior-data conflict can be overcome if sufficient data is available. We examine how to assess whether or not a prior-data conflict exists, and how to assess when its effects can be ignored for inferences. The concept of prior-data conflict is seen to lead to a partial characterization of what is meant by a noninformative prior or a noninformative sequence of priors. {\textcopyright} 2006 International Society for Bayesian Analysis.},
address = {University of Toronto, Toronto, Canada},
annote = {Cited By :61
Export Date: 12 November 2019},
author = {Evans, M and Moshonov, H},
doi = {10.1214/06-BA129},
journal = {Bayesian Analysis},
keywords = {Ancillarity Hierarchically specified priors Prior-},
number = {4},
pages = {893--914},
title = {{Checking for prior-data conflict}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-48749087559{\&}doi=10.1214{\%}2F06-BA129{\&}partnerID=40{\&}md5=d7b99cbb848e0e8ad0987b8c916529a2},
volume = {1},
year = {2006}
}
@article{FAYERS1997,
author = {Fayers, Peter M. and Ashby, Deborah and Parmar, Mahesh K. B.},
doi = {10.1002/(SICI)1097-0258(19970630)16:12<1413::AID-SIM578>3.0.CO;2-U},
file = {:Users/kwiatkoe/Library/Application Support/Mendeley Desktop/Downloaded/Fayers, Ashby, Parmar - 1997 - Tutorial in Biostatistics Bayesian Data Monitoring in Clinical Trials.pdf:pdf},
issn = {0277-6715},
journal = {Statistics in Medicine},
month = {jun},
number = {12},
pages = {1413--1430},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Tutorial in Biostatistics: Bayesian Data Monitoring in Clinical Trials}},
url = {http://doi.wiley.com/10.1002/{\%}28SICI{\%}291097-0258{\%}2819970630{\%}2916{\%}3A12{\%}3C1413{\%}3A{\%}3AAID-SIM578{\%}3E3.0.CO{\%}3B2-U},
volume = {16},
year = {1997}
}
@article{Flight2016,
abstract = {A sample size justification is a vital part of any trial design. However, estimating the number of participants required to give a meaningful result is not always straightforward. A number of components are required to facilitate a suitable sample size calculation. In this paper, the steps for conducting sample size calculations for non-inferiority and equivalence trials are summarised. Practical advice and examples are provided that illustrate how to carry out the calculations by hand and using the app SampSize. Copyright {\textcopyright} 2015 John Wiley {\&} Sons, Ltd.},
author = {Flight, Laura and Julious, Steven A},
doi = {10.1002/pst.1716},
journal = {Pharmaceutical Statistics},
keywords = {power sample size non-inferiority clinical trials },
number = {1},
pages = {80--89},
title = {{Practical guide to sample size calculations: non-inferiority and equivalence trials}},
volume = {15},
year = {2016}
}
@article{Freedman1989,
abstract = {We describe some problems with applying methods based on classical sequential analysis to monitoring clinical trials. A Bayesian method is developed and the boundaries are compared with frequentist schemes. For the examples chosen, the Bayesian boundaries can be quite similar to those obtained from Pocock and O'Brien and Fleming (OBF) rules, depending on the choice of prior distribution. They converge less rapidly than OBF's but more rapidly than Pocock's. In general the Bayesian methods provide the same desirable features as frequentist methods, without sacrificing flexibility and simplicity of interpretation.},
author = {Freedman, L S and Spiegelhalter, D J},
issn = {0197-2456},
journal = {Controlled Clinical Trials},
keywords = {Bayes Theorem Decision Support Techniques Decision},
number = {4},
pages = {357--367},
title = {{Comparison of Bayesian with group sequential methods for monitoring clinical trials}},
type = {Journal Article},
volume = {10},
year = {1989}
}
@article{Freedman1992,
author = {Freedman, Laurence S. and Spiegelhalter, David J.},
doi = {10.1002/sim.4780110105},
file = {:Users/kwiatkoe/Library/Application Support/Mendeley Desktop/Downloaded/Freedman, Spiegelhalter - 1992 - Application of bayesian statistics to decision making during a clinical trial.pdf:pdf},
issn = {02776715},
journal = {Statistics in Medicine},
month = {jan},
number = {1},
pages = {23--35},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Application of bayesian statistics to decision making during a clinical trial}},
url = {http://doi.wiley.com/10.1002/sim.4780110105},
volume = {11},
year = {1992}
}
@article{French2012,
abstract = {This article presents methods that were used to monitor two recent clinical trials for the early development of a novel therapeutic compound. We present Bayesian methods that were used to incorporate historical control data for monitoring early in the trials when there were very limited trial data. However, decisions to continue the study or terminate the experimental treatment had to be made to protect the patients in the trial. In the first trial, a pause in accrual was planned to allow assessment before a larger cohort could be recruited using more clinical centers. The primary endpoint for the continuation decision was binary, with accrual suspended until all patients in the first phase reached the endpoint time. The Bayesian method replaced decision criteria that regarded the historical data as a known standard, with the concurrent control data used to informally assist interpretation by the study clinicians. Monitoring of the subsequent study was planned without pauses in accrual. Survival methods used the partial information available on the eventual longer-term binary outcome. The Bayesian methods were approximately calibrated to avoid terminating the experimental compound incorrectly, and they were compared with some common, similarly calibrated non-Bayesian methods. The Bayesian methods were more likely to stop the experimental treatment correctly under conditions likely to arise in the trial. {\textcopyright} American Statistical Association Statistics in Biopharmaceutical Research.},
address = {N. Thomas, Pfizer, Inc., Groton, CT 06340, United States},
annote = {L365833276
2012-10-20
2012-10-29},
author = {French, J L and Thomas, N and Wang, C},
doi = {10.1080/19466315.2012.707088},
issn = {1946-6315},
journal = {Statistics in Biopharmaceutical Research},
keywords = {acute graft rejection article autoimmune disease B},
language = {English LB  - French2012},
number = {4},
pages = {384--394},
title = {{Using historical data with Bayesian methods in early clinical trial monitoring}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L365833276 http://dx.doi.org/10.1080/19466315.2012.707088},
volume = {4},
year = {2012}
}
@article{Furie2011,
abstract = {Abstract Objective To assess the efficacy/safety of the B lymphocyte stimulator inhibitor belimumab plus standard therapy compared with placebo plus standard therapy in active systemic lupus erythematosus (SLE). Methods In a phase III, multicenter, randomized, placebo-controlled trial, 819 antinuclear antibody?positive or anti?double-stranded DNA?positive SLE patients with scores ≥6 on the Safety of Estrogens in Lupus Erythematosus National Assessment (SELENA) version of the SLE Disease Activity Index (SLEDAI) were randomized in a 1:1:1 ratio to receive 1 mg/kg belimumab, 10 mg/kg belimumab, or placebo intravenously on days 0, 14, and 28 and then every 28 days for 72 weeks. The primary efficacy end point was the SLE Responder Index (SRI) response rate at week 52 (an SRI response was defined as a ≥4-point reduction in SELENA?SLEDAI score, no new British Isles Lupus Assessment Group [BILAG] A organ domain score and no more than 1 new BILAG B score, and no worsening in physician's global assessment score versus baseline). Results Belimumab at 10 mg/kg plus standard therapy met the primary efficacy end point, generating a significantly greater SRI response at week 52 compared with placebo (43.2{\%} versus 33.5{\%}; P = 0.017). The rate with 1 mg/kg belimumab was 40.6{\%} (P = 0.089). Response rates at week 76 were 32.4{\%}, 39.1{\%}, and 38.5{\%} with placebo, 1 mg/kg belimumab, and 10 mg/kg belimumab, respectively. In post hoc sensitivity analyses evaluating higher SELENA?SLEDAI score thresholds, 10 mg/kg belimumab achieved better discrimination at weeks 52 and 76. Risk of severe flares over 76 weeks (based on the modified SLE Flare Index) was reduced with 1 mg/kg belimumab (34{\%}) (P = 0.023) and 10 mg/kg belimumab (23{\%}) (P = 0.13). Serious and severe adverse events, including infections, laboratory abnormalities, malignancies, and deaths, were comparable across groups. Conclusion Belimumab plus standard therapy significantly improved SRI response rate, reduced SLE disease activity and severe flares, and was generally well tolerated in SLE.},
annote = {https://doi.org/10.1002/art.30613},
author = {Furie, Richard and Petri, Michelle and Zamani, Omid and Cervera, Ricard and Wallace, Daniel J and Tegzov{\'{a}}, Dana and Sanchez-Guerrero, Jorge and Schwarting, Andreas and Merrill, Joan T and Chatham, W Winn and Stohl, William and Ginzler, Ellen M and Hough, Douglas R and Zhong, Z John and Freimuth, William and van Vollenhoven, Ronald F and Group, BLISS-76 Study},
doi = {https://doi.org/10.1002/art.30613},
issn = {0004-3591},
journal = {Arthritis {\&} Rheumatism},
month = {dec},
number = {12},
pages = {3918--3930},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{A phase III, randomized, placebo-controlled study of belimumab, a monoclonal antibody that inhibits B lymphocyte stimulator, in patients with systemic lupus erythematosus}},
url = {https://doi.org/10.1002/art.30613},
volume = {63},
year = {2011}
}
@article{Galaznik2019,
author = {Galaznik, A and Berger, M and Lempernesse, B and Ransom, J and Shilnikova, A},
doi = {10.1016/j.jval.2019.04.1171 LB  - Galaznik2019},
issn = {1098-3015},
journal = {Value in Health},
month = {feb},
pages = {S250},
title = {{PMU8 A SYSTEMATIC APPROACH FOR SYNTHETIC REPLICATION OF CLINICAL TRIAL COHORTS USING RETROSPECTIVE REAL-WORLD AND CLINICAL TRIAL DATA}},
url = {https://doi.org/10.1016/j.jval.2019.04.1171},
volume = {22},
year = {2019}
}
@article{Galwey2017,
abstract = {There are strong arguments, ethical, logistical and financial, for supplementing the evidence from a new clinical trial using data from previous trials with similar control treatments. There is a consensus that historical information should be down-weighted or discounted relative to information from the new trial, but the determination of the appropriate degree of discounting is a major difficulty. The degree of discounting can be represented by a bias parameter with specified variance, but a comparison between the historical and new data gives only a poor estimate of this variance. Hence, if no strong assumption is made concerning its value (i.e. if ‘dynamic borrowing' is practiced), there may be little or no gain from using the historical data, in either frequentist terms (type I error rate and power) or Bayesian terms (posterior distribution of the treatment effect). It is therefore best to compare the consequences of a range of assumptions. This paper presents a clear, simple graphical tool for doing so on the basis of the mean square error, and illustrates its use with historical data from clinical trials in amyotrophic lateral sclerosis. This approach makes it clear that different assumptions can lead to very different conclusions. External information can sometimes provide strong additional guidance, but different stakeholders may still make very different judgements concerning the appropriate degree of discounting. Copyright {\textcopyright} 2016 John Wiley {\&} Sons, Ltd.},
address = {N.W. Galwey, GlaxoSmithKline R{\&}D, Medicines Research Centre, Stevenage, Hertfordshire, United Kingdom},
annote = {L613834771
2016-12-27
2017-02-27},
author = {Galwey, N W},
doi = {10.1002/sim.7180},
issn = {1097-0258 0277-6715},
journal = {Statistics in Medicine},
keywords = {amyotrophic lateral sclerosis article Bayesian lea},
language = {English LB  - Galwey2017},
number = {6},
pages = {899--916},
title = {{Supplementation of a clinical trial by historical control data: is the prospect of dynamic borrowing an illusion?}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L613834771 http://dx.doi.org/10.1002/sim.7180},
volume = {36},
year = {2017}
}
@article{Gamalo2011,
annote = {Cited By :19
Export Date: 1 November 2019},
author = {Gamalo, M A and Wu, R and Tiwari, R C},
doi = {10.1080/10543406.2011.589646},
journal = {Journal of Biopharmaceutical Statistics},
number = {5 LB  - Gamalo2011},
pages = {902--919},
title = {{Bayesian approach to noninferiority trials for proportions}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051761935{\&}doi=10.1080{\%}2F10543406.2011.589646{\&}partnerID=40{\&}md5=b1b336e5ea4487f723e825dc8ab539e3},
volume = {21},
year = {2011}
}
@article{Garrett2003,
abstract = {Abstract The number of studies designed specifically to demonstrate therapeutic equivalence or alternatively non-inferiority of pharmaceutical treatments has increased dramatically in recent years, during which time awareness of the methodological issues has increased. Regulatory authorities have been quick to recognize the need for specific support and have either published or initiated the creation of relevant guidance. Common misconceptions prevail however regarding sample size estimation and the choice of the most appropriate patient population to analyse while other areas such as equivalence margin specification and covariate adjustment have been neglected. This paper challenges some of the regulatory advice and the interpretation that others have made of this guidance with the aim of stimulating further debate. Copyright {\textcopyright} 2003 John Wiley {\&} Sons, Ltd.},
author = {Garrett, Andrew D},
doi = {10.1002/sim.1360},
journal = {Statistics in Medicine},
keywords = {analysis populations covariate adjustment drug reg},
number = {5},
pages = {741--762},
title = {{Therapeutic equivalence: fallacies and falsification}},
volume = {22},
year = {2003}
}
@article{Gaynor2017,
author = {Gaynor, Sheila and Bair, Eric},
doi = {10.1016/j.csda.2017.06.003},
issn = {0167-9473},
journal = {Computational statistics and data analysis},
pages = {139--154},
title = {{Identification of relevant subtypes via preweighted sparse clustering}},
volume = {116},
year = {2017}
}
@article{Ghosh2015,
author = {Ghosh, Samiran and Ghosh, Santu and {C. Tiwari}, Ram},
doi = {10.1002/sim.6746},
journal = {Statistics in Medicine},
pages = {n/a--n/a},
title = {{Bayesian approach for assessing non-inferiority in a three-arm trial with pre-specified margin}},
volume = {35},
year = {2015}
}
@article{Ghosh2017,
abstract = {Non-inferiority trials are becoming very popular for comparative effectiveness research. These trials are required to show that the effect of an experimental treatment is not worse than that of a reference treatment by more than a specified margin. Hence non-inferiority trials are of great importance, when superiority cannot be claimed. A three-arm non-inferiority trial consists of a placebo, a reference treatment, and an experimental treatment is considered. However unlike the traditional choices, it is assumed that the distributions of the end points corresponding to these treatments are unknown and suggested test procedures for a three-arm non-inferiority trial based on monotone transformations in conjunction with a normal approximation. The resulting test procedures are flexible and robust. Theoretical properties of the proposed methods are also investigated. The performance of the suggested test procedures is compared to their counterparts using simulations. In terms of type I error and power, the proposed methods perform better than their counterparts in most cases. The usefulness of the proposed methods is further illustrated through an example.},
author = {Ghosh, Santu and Chatterjee, Arpita and Ghosh, Samiran},
doi = {https://doi.org/10.1016/j.csda.2016.10.004},
issn = {0167-9473},
journal = {Computational Statistics and Data Analysis},
keywords = {Edgeworth expansion Level error Non-inferiority Ra},
pages = {73--87},
title = {{Non-inferiority test based on transformations for non-normal distributions}},
volume = {113},
year = {2017}
}
@article{Ghosh2018,
abstract = {With the recent advancement in many therapeutic areas, quest for better and enhanced treatment options is ever increasing. While the “efficacy” metric plays the most important role in this development, emphasis on other important clinical factors such as less intensive side effects, lower toxicity, ease of delivery, and other less debilitating factors may result in the selection of treatment options, which may not beat current established treatment option in terms efficacy, yet prove to be desirable for subgroups of patients. The resultant clinical trial by means of which one establishes such slightly less efficacious treatment is known as noninferiority (NI) trial. Noninferiority trials often involve an active established comparator arm, along with a placebo and an experimental treatment arm, resulting into a 3-arm trial. Most of the past developments in a 3-arm NI trial consider defining a prespecified fraction of unknown effect size of reference drug, i.e., without directly specifying a fixed NI margin. However, in some recent developments, more direct approach is being considered with prespecified fixed margin, albeit in the frequentist setup. In this article, we consider Bayesian implementation of such trial when primary outcome of interest is binary. Bayesian paradigm is important, as it provides a path to integrate historical trials and current trial information via sequential learning. We use several approximation-based and 2 exact fully Bayesian methods to evaluate the feasibility of the proposed approach. Finally, a clinical trial example is reanalyzed to demonstrate the benefit of the proposed approach.},
author = {Ghosh, Santu and Tiwari, Ram C and Ghosh, Samiran},
doi = {10.1002/pst.1851},
journal = {Pharmaceutical Statistics},
keywords = {assay sensitivity Bayesian method Jeffreys prior M},
number = {4},
pages = {342--357},
title = {{Bayesian approach for assessing noninferiority in a three-arm trial with binary endpoint}},
volume = {17},
year = {2018}
}
@article{Gondi2019,
abstract = {This Viewpoint describes trends favoring private equity acquisition of health care practices and companies, and calls for research to better characterize potential risks and benefits relative to health care quality, outcomes, and costs.},
author = {Gondi, Suhas and Song, Zirui},
doi = {10.1001/jama.2019.1077},
journal = {JAMA},
language = {en},
title = {{Potential Implications of Private Equity Investments in Health Care Delivery}},
year = {2019}
}
@article{Gottschall2012,
author = {Gottschall, Amanda C and West, Stephen G and Enders, Craig K},
doi = {10.1080/00273171.2012.640589},
issn = {0027-3171},
journal = {Multivariate Behavioral Research},
number = {1 LB  - Gottschall2012},
pages = {1--25},
title = {{A Comparison of Item-Level and Scale-Level Multiple Imputation for Questionnaire Batteries}},
url = {https://doi.org/10.1080/00273171.2012.640589},
volume = {47},
year = {2012}
}
@article{Gould1991,
annote = {Cited By :1
Export Date: 1 November 2019},
author = {Gould, A L},
doi = {10.1177/009286159102500307},
journal = {Therapeutic Innovation and Regulatory Science},
number = {3 LB  - Gould1991},
pages = {369--380},
title = {{Using prior findings to augment active-controlled trials and trials with small placebo groups}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973758446{\&}doi=10.1177{\%}2F009286159102500307{\&}partnerID=40{\&}md5=9365ff96c10f6098958b430686176c76},
volume = {25},
year = {1991}
}
@article{Gravestock2019,
annote = {Cited By :2
Export Date: 1 November 2019},
author = {Gravestock, I and Held, L},
doi = {10.1002/bimj.201700246},
journal = {Biometrical Journal},
number = {5 LB  - Gravestock2019},
pages = {1201--1218},
title = {{Power priors based on multiple historical studies for binary outcomes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055054113{\&}doi=10.1002{\%}2Fbimj.201700246{\&}partnerID=40{\&}md5=07da8e74f26961b9db8d29e1f66fbf60},
volume = {61},
year = {2019}
}
@article{Gravestock2017,
abstract = {Incorporating historical information into the design and analysis of a new clinical trial has been the subject of much discussion as a way to increase the feasibility of trials in situations where patients are difficult to recruit. The best method to include this data is not yet clear, especially in the case when few historical studies are available. This paper looks at the power prior technique afresh in a binomial setting and examines some previously unexamined properties, such as Box P values, bias, and coverage. Additionally, it proposes an empirical Bayes-type approach to estimating the prior weight parameter by marginal likelihood. This estimate has advantages over previously criticised methods in that it varies commensurably with differences in the historical and current data and can choose weights near 1 when the data are similar enough. Fully Bayesian approaches are also considered. An analysis of the operating characteristics shows that the adaptive methods work well and that the various approaches have different strengths and weaknesses.},
address = {I. Gravestock, Epidemiology, Biostatistics and Prevention Institute, University of Zurich, Zurich, Switzerland},
annote = {L616587941
2017-06-07
2018-03-14},
author = {Gravestock, I and Held, L},
doi = {10.1002/pst.1814},
issn = {1539-1612 1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {clinical trial human statistical significance},
language = {English LB  - Gravestock2017},
number = {5},
pages = {349--360},
title = {{Adaptive power priors with empirical Bayes for clinical trials}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L616587941 http://dx.doi.org/10.1002/pst.1814},
volume = {16},
year = {2017}
}
@article{Greenhouse2005,
abstract = {One feature of the Bayesian approach is that it provides methods for synthesizing what is known about a question of interest and provides a formalism based on the laws of probability for incorporating this auxiliary knowledge into the planning and the analysis of the next study. In this comment, we use elements of the Goodman-Sladky case study to illustrate (1) the use of Bayesian methods to quantify historical information about an intervention through the specification of a prior distribution, (2) an approach to the analysis of the sensitivity of the conclusions of a Bayesian analysis to the specification of the prior distribution, and (3) we comment on the role of research synthesis for combining information about an intervention from different data sources as a tool to help summarize evidence about the intervention. {\textcopyright} Society for Clinical Trials 2005.},
address = {J.B. Greenhouse, Department of Statistics, Carnegie Mellon University, Pittsburgh, PA 15213, United States},
annote = {L41306273
2005-10-11},
author = {Greenhouse, J B and Seltman, H},
doi = {10.1191/1740774505cn095oa},
issn = {1740-7745 1740-7753},
journal = {Clinical Trials},
keywords = {immunoglobulin placebo Bayes theorem case study co},
language = {English LB  - Greenhouse2005},
number = {4},
pages = {311--318},
title = {{Using prior distributions to synthesize historical evidence: Comments on the Goodman-Sladky case study of IVIg in Guillain-Barr{\'{e}} syndrome}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L41306273 http://dx.doi.org/10.1191/1740774505cn095oa},
volume = {2},
year = {2005}
}
@article{Gsteiger2013,
abstract = {Results from clinical trials are never interpreted in isolation. Previous studies in a similar setting provide valuable information for designing a new trial. For the analysis, however, the use of trial-external information is challenging and therefore controversial, although it seems attractive from an ethical or efficiency perspective. Here, we consider the formal use of historical control data on lesion counts in a multiple sclerosis trial. The approach to incorporating historical data is Bayesian, in that historical information is captured in a prior that accounts for between-trial variability and hence leads to discounting of historical data. We extend the meta-analytic-predictive approach, a random-effects meta-analysis of historical data combined with the prediction of the parameter in the new trial, from normal to overdispersed count data of individual-patient or aggregate-trial format. We discuss the prior derivation for the lesion mean count in the control group of the new trial for two populations. For the general population (without baseline enrichment), with 1936 control patients from nine historical trials, between-trial variability was moderate to substantial, leading to a prior effective sample size of about 45 control patients. For the more homogenous population (with enrichment), with 412 control patients from five historical trials, the prior effective sample size was approximately 63 patients. Although these numbers are small relative to the historical data, they are fairly typical in settings where between-trial heterogeneity is moderate. For phase II, reducing the number of control patients by 45 or by 63 may be an attractive option in many multiple sclerosis trials. {\textcopyright} 2013 John Wiley {\&} Sons, Ltd.},
address = {S. Gsteiger, Novartis Pharma AG, Statistical Modeling and Simulation, WSJ-27.6.076, CH-4002 Basel, Switzerland},
annote = {L52615146
2013-06-06
2013-09-11},
author = {Gsteiger, S and Neuenschwander, B and Mercier, F and Schmidli, H},
doi = {10.1002/sim.5851},
issn = {0277-6715 1097-0258},
journal = {Statistics in Medicine},
keywords = {article Bayes theorem clinical trial (topic) contr},
language = {English LB  - Gsteiger2013},
number = {21},
pages = {3609--3622},
title = {{Using historical control information for the design and analysis of clinical trials with overdispersed count data}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L52615146 http://dx.doi.org/10.1002/sim.5851},
volume = {32},
year = {2013}
}
@article{Han2017,
abstract = {The borrowing of historical control data can be an efficient way to improve the treatment effect estimate of the current control group in a randomized clinical trial. When the historical and current control data are consistent, the borrowing of historical data can increase power and reduce Type I error rate. However, when these 2 sources of data are inconsistent, it may result in a combination of biased estimates, reduced power, and inflation of Type I error rate. In some situations, inconsistency between historical and current control data may be caused by a systematic variation in the measured baseline prognostic factors, which can be appropriately addressed through statistical modeling. In this paper, we propose a Bayesian hierarchical model that can incorporate patient-level baseline covariates to enhance the appropriateness of the exchangeability assumption between current and historical control data. The performance of the proposed method is shown through simulation studies, and its application to a clinical trial design for amyotrophic lateral sclerosis is described. The proposed method is developed for scenarios involving multiple imbalanced prognostic factors and thus has meaningful implications for clinical trials evaluating new treatments for heterogeneous diseases such as amyotrophic lateral sclerosis.},
address = {B. Han, Biogen, Cambridge, MA, United States},
annote = {L616557626
2017-06-06
2017-07-20},
author = {Han, B and Zhan, J and {John Zhong}, Z and Liu, D and Lindborg, S},
doi = {10.1002/pst.1815},
issn = {1539-1612 1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {riluzole amyotrophic lateral sclerosis article Bay},
language = {English LB  - Han2017},
number = {4},
pages = {296--308},
title = {{Covariate-adjusted borrowing of historical control data in randomized clinical trials}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L616557626 http://dx.doi.org/10.1002/pst.1815},
volume = {16},
year = {2017}
}
@article{Hauck1999,
abstract = {Given the number of approved drugs, it is increasingly the case that the comparison arm for a new drug or combination product is another drug or combination, that is, the trial uses an “active-control.” Such active-controlled trials raise issues not seen in placebo-controlled trials. This note reviews and discusses some issues associated with the design and analysis of equivalence trials. Included are discussions of the choice of the equivalence allowance in designing the trial, and the roles of confidence intervals and intent-to-treat analyses.},
author = {Hauck, Walter W and Anderson, Sharon},
doi = {10.1177/009286159903300114},
journal = {Drug Information Journal},
number = {1},
pages = {109--118},
title = {{Some Issues in the Design and Analysis of Equivalence Trials}},
volume = {33},
year = {1999}
}
@article{Health2016,
author = {of Health, U S Department and {Human Services. FDA  CDER}, CBER.},
journal = {Guidance for industry},
title = {{Non-inferiority clinical trials to establish effectiveness.}},
year = {2016}
}
@article{Held2017,
abstract = {The prior distribution is a key ingredient in Bayesian inference. Prior information on regression coefficients may come from different sources and may or may not be in conflict with the observed data. Various methods have been proposed to quantify a potential prior-data conflict, such as Box's p-value. However, there are no clear recommendations how to react to possible prior-data conflict in generalized regression models. To address this deficiency, we propose to adaptively weight a prespecified multivariate normal prior distribution on the regression coefficients. To this end, we relate empirical Bayes estimates of prior weight to Box's p-value and propose alternative fully Bayesian approaches. Prior weighting can be done for the joint prior distribution of the regression coefficients or—under prior independence—separately for prespecified blocks of regression coefficients. We outline how the proposed methodology can be implemented using integrated nested Laplace approximations (INLA) and illustrate the applicability with a Bayesian logistic regression model for data from a cross-sectional study. We also provide a simulation study that shows excellent performance of our approach in the case of prior misspecification in terms of root mean squared error and coverage. Supplementary Materials give details on software implementation and code and another application to binary longitudinal data from a randomized clinical trial using a Bayesian generalized linear mixed model. {\textcopyright} 2016, The International Biometric Society},
address = {Department of Biostatistics, Epidemiology, Biostatistics and Prevention Institute, University of Zurich, Hirschengraben 84, Zurich, 8001, Switzerland},
annote = {Cited By :7
Export Date: 12 November 2019},
author = {Held, L and Sauter, R},
doi = {10.1111/biom.12541},
journal = {Biometrics},
keywords = {g-prior Generalized regression Hyper-g prior INLA },
number = {1},
pages = {242--251},
title = {{Adaptive prior weighting in generalized regression}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971250026{\&}doi=10.1111{\%}2Fbiom.12541{\&}partnerID=40{\&}md5=826276b529f3159f2a54f71fa4cea8a0},
volume = {73},
year = {2017}
}
@article{Helgeson2016,
author = {Helgeson, Erika S and Bair, Eric},
journal = {arXiv (preprint)},
title = {{Non-Parametric Cluster Significance Testing with Reference to a Unimodal Null Distribution}},
year = {2016}
}
@book{HessKLanskyAMerminJHallHI,
abstract = {This news release provides the latest developments in the prevention and treatment of HIV and related infectious diseases during CROI 2016.},
author = {{Hess K  Lansky A, Mermin J, Hall HI}, Hu X},
language = {en-us},
title = {{Estimating the lifetime risk of a diagnosis of HIV infection in the United States. Conference on Retroviruses and Opportunistic Infections, Boston, MA, February 22-25, 2016; Abstract {\#}52, and CDC Press Release}}
}
@article{Hobbs2011,
abstract = {Bayesian clinical trial designs offer the possibility of a substantially reduced sample size, increased statistical power, and reductions in cost and ethical hazard. However when prior and current information conflict, Bayesian methods can lead to higher than expected type I error, as well as the possibility of a costlier and lengthier trial. This motivates an investigation of the feasibility of hierarchical Bayesian methods for incorporating historical data that are adaptively robust to prior information that reveals itself to be inconsistent with the accumulating experimental data. In this article, we present several models that allow for the commensurability of the information in the historical and current data to determine how much historical information is used. A primary tool is elaborating the traditional power prior approach based upon a measure of commensurability for Gaussian data. We compare the frequentist performance of several methods using simulations, and close with an example of a colon cancer trial that illustrates a linear models extension of our adaptive borrowing approach. Our proposed methods produce more precise estimates of the model parameters, in particular, conferring statistical significance to the observed reduction in tumor size for the experimental regimen as compared to the control regimen. {\textcopyright} 2011, The International Biometric Society.},
address = {B.P. Hobbs, Department of Biostatistics, M.D. Anderson Cancer Center, Houston, TX 77030, United States},
annote = {L51353884
2012-02-29},
author = {Hobbs, B P and Carlin, B P and Mandrekar, S J and Sargent, D J},
doi = {10.1111/j.1541-0420.2011.01564.x},
issn = {0006-341X 1541-0420},
journal = {Biometrics},
keywords = {article Bayes theorem biometry clinical trial (top},
language = {English LB  - Hobbs2011},
number = {3},
pages = {1047--1056},
title = {{Hierarchical Commensurate and Power Prior Models for Adaptive Incorporation of Historical Information in Clinical Trials}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L51353884 http://dx.doi.org/10.1111/j.1541-0420.2011.01564.x},
volume = {67},
year = {2011}
}
@article{Hobbs2013,
abstract = {Background Prospective trial design often occurs in the presence of acceptable historical control data. Typically, these data are only utilized for treatment comparison in a posteriori retrospective analysis to estimate population-averaged effects in a random-effects meta-analysis. Purpose We propose and investigate an adaptive trial design in the context of an actual randomized controlled colorectal cancer trial. This trial, originally reported by Goldberg et al., succeeded a similar trial reported by Saltz et al., and used a control therapy identical to that tested (and found beneficial) in the Saltz trial. Methods The proposed trial implements an adaptive randomization procedure for allocating patients aimed at balancing total information (concurrent and historical) among the study arms. This is accomplished by assigning more patients to receive the novel therapy in the absence of strong evidence for heterogeneity among the concurrent and historical controls. Allocation probabilities adapt as a function of the effective historical sample size (EHSS), characterizing relative informativeness defined in the context of a piecewise exponential model for evaluating time to disease progression. Commensurate priors are utilized to assess historical and concurrent heterogeneity at interim analyses and to borrow strength from the historical data in the final analysis. The adaptive trials frequentist properties are simulated using the actual patient-level historical control data from the Saltz trial and the actual enrollment dates for patients enrolled into the Goldberg trial. Results Assessing concurrent and historical heterogeneity at interim analyses and balancing total information with the adaptive randomization procedure lead to trials that on average assign more new patients to the novel treatment when the historical controls are unbiased or slightly biased compared to the concurrent controls. Large magnitudes of bias lead to approximately equal allocation of patients among the treatment arms. Using the proposed commensurate prior model to borrow strength from the historical data, after balancing total information with the adaptive randomization procedure, provides admissible estimators of the novel treatment effect with desirable bias-variance trade-offs. Limitations Adaptive randomization methods in general are sensitive to population drift and more suitable for trials that initiate with gradual enrollment. Balancing information among study arms in time-to-event analyses is difficult in the presence of informative right-censoring. Conclusions The proposed design could prove important in trials that follow recent evaluations of a control therapy. Efficient use of the historical controls is especially important in contexts where reliance on preexisting information is unavoidable because the control therapy is exceptionally hazardous, expensive, or the disease is rare. {\textcopyright} 2013 The Author(s).},
address = {B.P. Hobbs, Department of Biostatistics, University of Texas MD Anderson Cancer Center, Houston, TX, 77030, United States},
annote = {L368997389
2013-06-04
2013-06-07},
author = {Hobbs, B P and Carlin, B P and Sargent, D J},
doi = {10.1177/1740774513483934},
issn = {1740-7745 1740-7753},
journal = {Clinical Trials},
keywords = {fluorouracil folinic acid irinotecan oxaliplatin a},
language = {English LB  - Hobbs2013},
number = {3},
pages = {430--440},
title = {{Adaptive adjustment of the randomization ratio using historical control data}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L368997389 http://dx.doi.org/10.1177/1740774513483934},
volume = {10},
year = {2013}
}
@article{Hobbs2012,
annote = {Cited By :55
Export Date: 1 November 2019},
author = {Hobbs, B P and Sargent, D J and Carlin, B P},
doi = {10.1214/12-BA722},
journal = {Bayesian Analysis},
number = {3 LB  - Hobbs2012},
pages = {639--674},
title = {{Commensurate priors for incorporating historical information in clinical trials using general and generalized linear models}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865835107{\&}doi=10.1214{\%}2F12-BA722{\&}partnerID=40{\&}md5=3b6e6c7de90083ac77883e5b5bc1f0e1},
volume = {7},
year = {2012}
}
@article{Hoeting1999,
author = {Hoeting, J A Jennifer A and Madigan, David and Raftery, Adrian E A E and Volinsky, Chris T},
doi = {10.2307/2676803},
issn = {08834237},
journal = {Statistical science},
keywords = {Markov chain Monte Carlo PREDICTION and phrases Ba},
number = {4},
pages = {382--401},
title = {{Bayesian model averaging: A tutorial}},
volume = {14},
year = {1999}
}
@article{Holzhauer2019,
abstract = {This article deals with comparing a test with a control therapy using meta-analyses of data from randomized controlled trials with a time-to-event endpoint. Such analyses can often benefit from prior information about the distribution of control group outcomes. One possible source of this information is the published aggregate data about control groups of historical trials from the medical literature. We review methods for making posterior inference about exponentially distributed event times more robust to prior-data conflicts by discounting the prior information based on the extent of observed prior-data conflict. We use simulations to compare analyses without prior information with the meta-analytic combined, meta-analytic predictive and robust meta-analytic predictive approaches, as well as Bayesian model averaging using shrinkage priors. Bayesian model averaging via shrinkage priors with well-chosen hyperpriors performed best in terms of credible interval coverage and mean-squared error across scenarios. For the robust meta-analytic predictive approach, there was little benefit in increasing the weight of the informative mixture components beyond 0.2–0.5. This was the case even when little prior-data conflict was expected, except with very sparse data or substantial between-trial heterogeneity in control group hazard rates. Supplementary materials for this article are available online.},
address = {B. Holzhauer, Novartis Pharma AG, Postfach, Basel, Switzerland},
annote = {L628468947
2019-07-16},
author = {Holzhauer, B},
doi = {10.1080/19466315.2019.1610043},
issn = {1946-6315},
journal = {Statistics in Biopharmaceutical Research},
keywords = {article averaging controlled study human medical l},
language = {English LB  - Holzhauer2019},
title = {{Methods for Using Aggregate Historical Control Data in Meta-Analyses of Clinical Trials With Time-to-Event Endpoints}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L628468947 http://dx.doi.org/10.1080/19466315.2019.1610043},
year = {2019}
}
@article{Hsu2019,
abstract = {In pediatric drug development, large amounts of adult data are often available before the start of a pediatric study. It is believed that borrowing this information will improve the efficiency. However, when adult information is not sufficiently similar to that of pediatrics, incorporating adult data will introduce bias and consequently result in efficiency loss. A Bayesian alternative-namely, commensurate prior approach where the level of information borrowing is based on the concordance of adult and pediatric data-was investigated. Simulation results indicate that the commensurate prior approach, in general, provides a balanced and robust trade-off between bias and efficiency gain. The benefit of this approach was quantified in terms of sample size savings, and recommended sample sizes are provided.},
address = {Janssen Research {\&} Development, Raritan, NJ, USA. Food and Drug Administration, Silver Spring, MD, USA.},
annote = {1552-4604
Hsu, Chyi-Hung
ORCID: https://orcid.org/0000-0003-1961-7759
Steven Xu, Xu
Wang, Jian
Zhang, Liping
Liu, Chao
Wang, Yaning
Journal Article
England
J Clin Pharmacol. 2019 Jul;59(7):989-996. doi: 10.1002/jcph.1390. Epub 2019 Feb 12.},
author = {Hsu, C H and {Steven Xu}, X and Wang, J and Zhang, L and Liu, C and Wang, Y},
doi = {10.1002/jcph.1390},
edition = {2019/02/13},
issn = {0091-2700},
journal = {The Journal of Clinical Pharmacology},
keywords = {Bayesian analysis borrowing commensurate prior his},
language = {eng LB  - Hsu2019},
number = {7},
pages = {989--996},
title = {{Utilization of Adult Data in Designing Pediatric Pharmacokinetic Studies: How Much Are Historical Adult Data Worth?}},
volume = {59},
year = {2019}
}
@article{Huang2015,
author = {Huang, Hanwen and Liu, Yufeng and Yuan, Ming and Marron, J S},
doi = {10.1080/10618600.2014.948179},
journal = {Journal of Computational and Graphical Statistics},
number = {4},
pages = {975--993},
title = {{Statistical Significance of Clustering Using Soft Thresholding}},
volume = {24},
year = {2015}
}
@article{Hwang1999,
abstract = {When designing a noninferiority/equivalence trial, the sponsor intends to show efficacy by demonstrating that a new treatment is as good as or not worse than a known effective treatment by a small predefined margin. To confirm noninferiority/equivalence of the new treatment to an active control, “sensitivity-to-drug-effects” and “assay sensitivity,” as defined in the International Conference on Harmonization (ICH) E10 Guideline (1, 2) must be supported. Otherwise, a finding of mere nonsignificant difference between treatments in the traditional setting of significance testing leaves the question unanswered: Would the trial have concluded noninferiority while the new treatment was, in fact, inferior?This paper first reviews the choice of control and the crucial issues of sensitivity-to-drug-effects and assay sensitivity. Then, it discusses the choice of the noninferiority/equivalence margin and the forms of the null and alternative hypotheses and confidence intervals. Finally, it addresses the inherent difficulties and some useful design alternatives to the noninferiority/equivalence trials.},
author = {Hwang, Irving K and Morikawa, Toshihiko},
doi = {10.1177/009286159903300424},
journal = {Drug Information Journal},
number = {4},
pages = {1205--1218},
title = {{Design Issues in Noninferiority/Equivalence Trials}},
volume = {33},
year = {1999}
}
@article{Hyams2012,
abstract = {Background {\&} Aims: We evaluated the efficacy and safety of infliximab for inducing and maintaining benefit in children with moderately to severely active ulcerative colitis (UC). Methods: Patients (6-17 years old) who had active UC (Mayo scores of 6-12; endoscopic subscores ≥2) and had not responded to or tolerated conventional treatment were given 5 mg/kg infliximab at weeks 0, 2, and 6. The primary end point was response at week 8 (decreases in Mayo scores ≥30{\%} and ≥3 points and decreases in rectal bleeding subscores of ≥1 or an absolute subscore of ≤1). At week 8, only responders were randomly assigned to groups given infliximab every 8 or 12 weeks (q8w or q12w) and followed through week 54. Maintenance end points included pediatric UC activity index scores {\textless}10 points, defined as remission. Results: At week 8, infliximab induced a response in 73.3{\%} of patients (44 of 60) (95{\%} confidence interval, 62.1{\%}-84.5{\%}; a positive result was defined by 95{\%} confidence interval lower limit {\textgreater}40{\%}). Among responders, twice as many were in remission at week 54 after q8w (8 of 21, 38.1{\%}) than q12w (4 of 22, 18.2{\%}; P = .146) therapy. Assuming the q8w remission rate for responders, the overall remission rate at week 54 would be 28.6{\%}. Serious adverse events and infusion reactions occurred in similar proportions in the q8w and q12w groups. No deaths, malignancies, opportunistic infections, tuberculosis, or delayed hypersensitivity reactions were reported. Conclusions: Infliximab was safe and effective, inducing a response at week 8 in 73.3{\%} of pediatric patients with moderate to severely active UC who did not respond to conventional therapy. The overall remission rate at week 54 for all enrolled patients was 28.6{\%}, assuming the more effective q8w remission rate. {\textcopyright} 2012 AGA Institute.},
author = {Hyams, Jeffrey and Damaraju, Lakshmi and Blank, Marion and Johanns, Jewel and Guzzo, Cynthia and Winter, Harland S. and Kugathasan, Subra and Cohen, Stanley and Markowitz, James and Escher, Johanna C. and Veereman-Wauters, Gigi and Crandall, Wallace and Baldassano, Robert and Griffiths, Anne},
doi = {10.1016/j.cgh.2011.11.026},
issn = {15423565},
journal = {Clinical Gastroenterology and Hepatology},
keywords = {Clinical trial,Inflammatory bowel disease (IBD),Mucosal healing,Pediatric ulcerative colitis activity index (PUCAI},
pages = {391--399},
pmid = {22155755},
title = {{Induction and Maintenance Therapy With Infliximab for Children With Moderate to Severe Ulcerative Colitis}},
volume = {10},
year = {2012}
}
@article{Hyman2015a,
abstract = {BackgroundBRAF V600 mutations occur in various nonmelanoma cancers. We undertook a histology-independent phase 2 “basket” study of vemurafenib in BRAF V600 mutation–positive nonmelanoma cancers. Me...},
author = {Hyman, David M and Puzanov, Igor and Subbiah, Vivek and Faris, Jason E and Chau, Ian and Blay, Jean-Yves and Wolf, Jrgen and Raje, Noopur S and Diamond, Eli L and Hollebecque, Antoine and Gervais, Radj and Elez-Fernandez, Maria Elena and Italiano, Antoine and Hofheinz, Ralf-Dieter and Hidalgo, Manuel and Chan, Emily and Schuler, Martin and Lasserre, Susan Frances and Makrutzki, Martina and Sirzen, Florin and Veronese, Maria Luisa and Tabernero, Josep and Baselga, Jos},
doi = {10.1056/NEJMoa1502309},
issn = {0028-4793},
journal = {New England Journal of Medicine},
number = {8 LB  - Hyman2015},
pages = {726--736},
title = {{Vemurafenib in Multiple Nonmelanoma Cancers with $\backslash$textless i $\backslash$textgreater BRAF $\backslash$textless /i $\backslash$textgreater V600 Mutations}},
url = {http://www.nejm.org/doi/10.1056/NEJMoa1502309},
volume = {373},
year = {2015}
}
@article{Hyman2015,
abstract = {BackgroundBRAF V600 mutations occur in various nonmelanoma cancers. We undertook a histology-independent phase 2 “basket” study of vemurafenib in BRAF V600 mutation–positive nonmelanoma cancers. Me...},
author = {Hyman, David M. and Puzanov, Igor and Subbiah, Vivek and Faris, Jason E. and Chau, Ian and Blay, Jean-Yves and Wolf, J{\"{u}}rgen and Raje, Noopur S. and Diamond, Eli L. and Hollebecque, Antoine and Gervais, Radj and Elez-Fernandez, Maria Elena and Italiano, Antoine and Hofheinz, Ralf-Dieter and Hidalgo, Manuel and Chan, Emily and Schuler, Martin and Lasserre, Susan Frances and Makrutzki, Martina and Sirzen, Florin and Veronese, Maria Luisa and Tabernero, Josep and Baselga, Jos{\'{e}}},
doi = {10.1056/NEJMoa1502309},
issn = {0028-4793},
journal = {New England Journal of Medicine},
month = {aug},
number = {8},
pages = {726--736},
publisher = {Massachusetts Medical Society},
title = {{Vemurafenib in Multiple Nonmelanoma Cancers with {\textless}i{\textgreater}BRAF{\textless}/i{\textgreater} V600 Mutations}},
url = {http://www.nejm.org/doi/10.1056/NEJMoa1502309},
volume = {373},
year = {2015}
}
@article{Ibrahim2015,
abstract = {The power prior has been widely used in many applications covering a large number of disciplines. The power prior is intended to be an informative prior constructed from historical data. It has been used in clinical trials, genetics, health care, psychology, environmental health, engineering, economics, and business. It has also been applied for a wide variety of models and settings, both in the experimental design and analysis contexts. In this review article, we give an A-to-Z exposition of the power prior and its applications to date. We review its theoretical properties, variations in its formulation, statistical contexts for which it has been used, applications, and its advantages over other informative priors. We review models for which it has been used, including generalized linear models, survival models, and random effects models. Statistical areas where the power prior has been used include model selection, experimental design, hierarchical modeling, and conjugate priors. Frequentist properties of power priors in posterior inference are established, and a simulation study is conducted to further examine the empirical performance of the posterior estimates with power priors. Real data analyses are given illustrating the power prior as well as the use of the power prior in the Bayesian design of clinical trials.},
address = {J.G. Ibrahim, Department of Biostatistics, University of North Carolina, Chapel Hill, NC, United States},
annote = {L605952644
2015-09-15
2016-04-05},
author = {Ibrahim, J G and Chen, M H and Gwon, Y and Chen, F},
doi = {10.1002/sim.6728},
issn = {1097-0258 0277-6715},
journal = {Statistics in Medicine},
keywords = {article Bayes theorem linear system logistic regre},
language = {English LB  - Ibrahim2015a},
number = {28},
pages = {3724--3749},
title = {{The power prior: Theory and applications}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L605952644 http://dx.doi.org/10.1002/sim.6728},
volume = {34},
year = {2015}
}
@article{Ibrahim2015a,
abstract = {Developing sophisticated statistical methods for go/no-go decisions is crucial for clinical trials, as planning phase III or phase IV trials is costly and time consuming. In this paper, we develop a novel Bayesian methodology for determining the probability of success of a treatment regimen on the basis of the current data of a given trial. We introduce a new criterion for calculating the probability of success that allows for inclusion of covariates as well as allowing for historical data based on the treatment regimen, and patient characteristics. A new class of prior distributions and covariate distributions is developed to achieve this goal. The methodology is quite general and can be used with univariate or multivariate continuous or discrete data, and it generalizes Chuang-Stein's work. This methodology will be invaluable for informing the scientist on the likelihood of success of the compound, while including the information of covariates for patient characteristics in the trial population for planning future pre-market or post-market trials.},
address = {J.G. Ibrahim, Department of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, NC, United States},
annote = {L600747364
2015-01-16
2015-01-29},
author = {Ibrahim, J G and Chen, M H and Lakshminarayanan, M and Liu, G F and Heyse, J F},
doi = {10.1002/sim.6339},
issn = {1097-0258 0277-6715},
journal = {Statistics in Medicine},
keywords = {aprepitant paroxetine placebo varicella zoster vac},
language = {English LB  - Ibrahim2015b},
number = {2},
pages = {249--264},
title = {{Bayesian probability of success for clinical trials using historical data}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L600747364 http://dx.doi.org/10.1002/sim.6339},
volume = {34},
year = {2015}
}
@article{Ibrahim2012,
abstract = {Recent guidance from the Food and Drug Administration for the evaluation of new therapies in the treatment of type 2 diabetes (T2DM) calls for a program-wide meta-analysis of cardiovascular (CV) outcomes. In this context, we develop a new Bayesian meta-analysis approach using survival regression models to assess whether the size of a clinical development program is adequate to evaluate a particular safety endpoint. We propose a Bayesian sample size determination methodology for meta-analysis clinical trial design with a focus on controlling the type I error and power. We also propose thepartial borrowing power priorto incorporate the historical survival meta data into the statistical design. Various properties of the proposed methodology are examined and an efficient Markov chain Monte Carlo sampling algorithm is developed to sample from the posterior distributions. In addition, we develop a simulation-based algorithm for computing various quantities, such as the power and the type I error in the Bayesian meta-analysis trial design. The proposed methodology is applied to the design of a phase 2/3 development program including a noninferiority clinical trial for CV risk assessment in T2DM studies. {\textcopyright} 2011, The International Biometric Society.},
address = {J.G. Ibrahim, Department of Biostatistics, University of North Carolina, McGavran-Greenberg Hall, Chapel Hill, NC 27599, United States},
annote = {L51655008
2012-11-08},
author = {Ibrahim, J G and Chen, M H and Xia, H A and Liu, T},
doi = {10.1111/j.1541-0420.2011.01679.x},
issn = {0006-341X 1541-0420},
journal = {Biometrics},
keywords = {antidiabetic agent algorithm article Bayes theorem},
language = {English LB  - Ibrahim2012},
number = {2},
pages = {578--586},
title = {{Bayesian Meta-Experimental Design: Evaluating Cardiovascular Risk in New Antidiabetic Therapies to Treat Type 2 Diabetes}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L51655008 http://dx.doi.org/10.1111/j.1541-0420.2011.01679.x},
volume = {68},
year = {2012}
}
@article{III2005,
author = {III, Hal Daum{\'{e}} and Marcu, Daniel},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
pages = {1551--1577},
title = {{A Bayesian Model for Supervised Clustering with the Dirichlet Process Prior}},
volume = {6},
year = {2005}
}
@article{Isogawa2019,
abstract = {Background: In the process of research and development of a new treatment, clinical trials are conducted to evaluate its safety and efficacy. Key to streamlining the process is to utilize appropriate historical information on an outcome of a control treatment when designing and analyzing a clinical trial. Methods: For the use of such historical control information, there exist a meta-analytic approach and power prior approach. In this article, we evaluate their performance with regard to the type I error (TIE) rate and power through a simulation study where we analyze the data on a binary outcome of an experimental treatment and a control treatment from a new small-scale trial, along with the corresponding data of the control treatment from multiple historical trials. The reason is that the difference in the performance between the 2 approaches has not been clear. Results: When historical trials were homogeneous, the power was higher in the power prior approach and the meta-analytic approach using a beta-binomial model with a less noninformative prior than the other approaches. However, when heterogeneous historical trials were mixed, the power was lower, or the TIE rates got inflated. Conclusions: To make use of historical control data, if importance is attached to control of the TIE rate, the meta-analytic approach using a normal-normal hierarchical model may be preferable to the power prior approach, whereas if attached to improvement of the power, this preference be reversed. Anyway, the best approach should be chosen by comparing the operational characteristics of the approaches.},
address = {N. Isogawa, Clinical Statistics, Pfizer R{\&}D Japan, Shibuya-ku, Tokyo, Japan},
annote = {L628857550
2019-08-14},
author = {Isogawa, N and Takeda, K and Maruo, K and Daimon, T},
doi = {10.1177/2168479019862531},
issn = {2168-4804 2168-4790},
journal = {Therapeutic Innovation and Regulatory Science},
keywords = {article controlled clinical trial controlled study},
language = {English LB  - Isogawa2019},
title = {{A Comparison Between a Meta-analytic Approach and Power Prior Approach to Using Historical Control Information in Clinical Trials With Binary Endpoints}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L628857550 http://dx.doi.org/10.1177/2168479019862531},
year = {2019}
}
@article{Jarow2017,
abstract = {The expanded use of electronic data retrieval systems has greatly expanded the potential sources of real-world data and presents new opportunities for evidence generation outside of the traditional research trial. These data may be used to inform trial design and interpretation as well. Externally controlled trials, such as single-arm and noninferiority designs, have long been used in regulatory decision-making despite the potential flaws based on assumptions of assay sensitivity and constancy.},
author = {Jarow, J P},
doi = {10.1002/cpt.652},
issn = {0009-9236},
journal = {Clinical Pharmacology and Therapeutics},
number = {5 LB  - Jarow2017},
pages = {595--596},
title = {{Use of External Controls in Regulatory Decision-Making}},
url = {https://ascpt.onlinelibrary.wiley.com/doi/abs/10.1002/cpt.652},
volume = {101},
year = {2017}
}
@book{Jennison2000,
address = {Boca Raton},
author = {Jennison, Christopher and Turnbull, Bruce W.},
publisher = {Chapman {\&} Hall/CRC},
title = {{Group sequential methods with applications to clinical trials}},
year = {2000}
}
@article{Jiao2019,
abstract = {Recruitment of patients in concurrent control arms can be very challenging for clinical trials for pediatric and rare diseases. Innovative approaches, such as platform trial designs, including shared internal control arm(s), can potentially reduce the needed sample size, improving the efficiency and speed of the drug development program. Furthermore, historical borrowing, which involves leveraging information from control arms in previous relevant clinical trials, may further enhance a clinical trial's efficiency. In this paper, we discuss platform trials highlighting their advantages and limitations. We then compare various strategies that borrow historical data or information, such as pooling data from different studies, analyzing data from studies separately, test-then-pool, dynamic pooling, and Bayesian hierarchical modeling, which focuses on the meta-analytic-predictive (MAP) prior. We further propose a procedure to illustrate the feasibility of utilizing historical controls under a platform setting and describe the statistical performance of our method via simulations.},
address = {Y.-F. Chen, Center for Drug Evaluation and Research, U.S. Food and Drug Administration, 10903 New Hampshire Ave, Silver Spring, MD, United States},
annote = {L2002616046
2019-09-02
2019-10-31},
author = {Jiao, F and Tu, W and Jimenez, S and Crentsil, V and Chen, Y F},
doi = {10.1080/10543406.2019.1657132},
issn = {1520-5711 1054-3406},
journal = {Journal of Biopharmaceutical Statistics},
keywords = {article clinical trial (topic) feasibility study h},
language = {English LB  - Jiao2019},
number = {5},
pages = {845--859},
title = {{Utilizing shared internal control arms and historical information in small-sized platform clinical trials}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L2002616046 http://dx.doi.org/10.1080/10543406.2019.1657132},
volume = {29},
year = {2019}
}
@article{Jones1996,
author = {Jones, B and Jarvis, P and Lewis, J A and Ebbutt, A F},
doi = {10.1136/bmj.313.7048.36},
issn = {0959-8138},
journal = {BMJ},
number = {7048},
pages = {36--39},
title = {{Trials to assess equivalence: the importance of rigorous methods}},
volume = {313},
year = {1996}
}
@article{Julious2004,
abstract = {This article gives an overview of sample size calculations for parallel group and cross?over studies with Normal data. Sample size derivation is given for trials where the objective is to demonstrate: superiority, equivalence, non?inferiority, bioequivalence and estimation to a given precision, for different types I and II errors. It is demonstrated how the different trial objectives influence the null and alternative hypotheses of the trials and how these hypotheses influence the calculations. Sample size tables for the different types of trials and worked examples are given.},
annote = {$\backslash$copyright 2004 John Wiley {\&} Sons, Ltd. This is an author-produced version of a paper subsequently published in Statistics in Medicine. Uploaded in accordance with the publisher's self-archiving policy.},
author = {Julious, S A},
journal = {Statistics in Medicine},
keywords = {bioequivalence baselines cross-over trials equival},
number = {12},
pages = {1921--1986},
title = {{Tutorial in biostatistics - Sample sizes for clinical trials with Normal data}},
volume = {23},
year = {2004}
}
@article{Kenward1997,
abstract = {Restricted maximum likelihood (REML) is now well established as a method for estimating the parameters of the general Gaussian linear model with a structured covariance matrix, in particular for mixed linear models. Conventionally, estimates of precision and inference for fixed effects are based on their asymptotic distribution, which is known to be inadequate for some small-sample problems. In this paper, we present a scaled Wald statistic, together with an F approximation to its sampling distribution, that is shown to perform well in a range of small sample settings. The statistic uses an adjusted estimator of the covariance matrix that has reduced small sample bias. This approach has the advantage that it reproduces both the statistics and F distributions in those settings where the latter is exact, namely for Hotelling T2 type statistics and for analysis of variance F-ratios. The performance of the modified statistics is assessed through simulation studies of four different REML analyses and the methods are illustrated using three examples.},
author = {Kenward, Michael G and Roger, James H},
doi = {10.2307/2533558},
issn = {0006-341X},
journal = {Biometrics},
number = {3 LB  - Kenward1997},
pages = {983--997},
title = {{Small Sample Inference for Fixed Effects from Restricted Maximum Likelihood}},
volume = {53},
year = {1997}
}
@article{Khozin2017,
abstract = {Conventional cancer clinical trials can be slow and costly, often produce results with limited external validity, and are difficult for patients to participate in. Recent technological advances and a dynamic policy landscape in the United States have created a fertile ground for the use of real-world data (RWD) to improve current methods of clinical evidence generation. Sources of RWD include electronic health records, insurance claims, patient registries, and digital health solutions outside of conventional clinical trials. A definition focused on the original intent of data collected at the point of care can distinguish RWD from conventional clinical trial data. When the intent of data collection at the point of care is research, RWD can be generated using experimental designs similar to those employed in conventional clinical trials, but with several advantages that include gains in efficient execution of studies with an appropriate balance between internal and external validity. RWD can support active pharmacovigilance, insights into the natural history of disease, and the development of external control arms. Prospective collection of RWD can enable evidence generation based on pragmatic clinical trials (PCTs) that support randomized study designs and expand clinical research to the point of care. PCTs may help address the growing demands for access to experimental therapies while increasing patient participation in cancer clinical trials. Conducting valid real-world studies requires data quality assurance through auditable data abstraction methods and new incentives to drive electronic capture of clinically relevant data at the point of care.},
author = {Khozin, Sean and Blumenthal, Gideon M and Pazdur, Richard},
doi = {10.1093/jnci/djx187},
issn = {0027-8874},
journal = {Journal of the National Cancer Institute},
month = {nov},
number = {11 LB  - Khozin2017},
title = {{Real-world Data for Clinical Evidence Generation in Oncology}},
url = {https://doi.org/10.1093/jnci/djx187},
volume = {109},
year = {2017}
}
@article{Kim2018,
abstract = {High quality historical control data, if incorporated, may reduce sample size, trial cost, and duration. A too optimistic use of the data, however, may result in bias under prior-data conflict. Motivated by well-publicized two-arm comparative trials in stroke, we propose a Bayesian design that both adaptively incorporates historical control data and selectively adapt the treatment allocation ratios within an ongoing trial responsively to the relative treatment effects. The proposed design differs from existing designs that borrow from historical controls. As opposed to reducing the number of subjects assigned to the control arm blindly, this design does so adaptively to the relative treatment effects only if evaluation of cumulated current trial data combined with the historical control suggests the superiority of the intervention arm. We used the effective historical sample size approach to quantify borrowed information on the control arm and modified the treatment allocation rules of the doubly adaptive biased coin design to incorporate the quantity. The modified allocation rules were then implemented under the Bayesian framework with commensurate priors addressing prior-data conflict. Trials were also more frequently concluded earlier in line with the underlying truth, reducing trial cost, and duration and yielded parameter estimates with smaller standard errors.},
address = {M.-O. Kim, UCSF Helen Diller Family Comprehensive Cancer Center, San Francisco, CA, United States},
annote = {L624376036
2018-10-22},
author = {Kim, M O and Harun, N and Liu, C and Khoury, J C and Broderick, J P},
doi = {10.1002/sim.7836},
issn = {1097-0258 0277-6715},
journal = {Statistics in Medicine},
keywords = {adult article controlled study drug combination er},
language = {English LB  - Kim2018},
number = {26},
pages = {3709--3722},
title = {{Bayesian selective response-adaptive design using the historical control}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L624376036 http://dx.doi.org/10.1002/sim.7836},
volume = {37},
year = {2018}
}
@article{Kopp-Schneider2020,
abstract = {In the era of precision medicine, novel designs are developed to deal with flexible clinical trials that incorporate many treatment strategies for multiple diseases in one trial setting. This situation often leads to small sample sizes in disease-treatment combinations and has fostered the discussion about the benefits of borrowing of external or historical information for decision-making in these trials. Several methods have been proposed that dynamically discount the amount of information borrowed from historical data based on the conformity between historical and current data. Specifically, Bayesian methods have been recommended and numerous investigations have been performed to characterize the properties of the various borrowing mechanisms with respect to the gain to be expected in the trials. However, there is common understanding that the risk of type I error inflation exists when information is borrowed and many simulation studies are carried out to quantify this effect. To add transparency to the debate, we show that if prior information is conditioned upon and a uniformly most powerful test exists, strict control of type I error implies that no power gain is possible under any mechanism of incorporation of prior information, including dynamic borrowing. The basis of the argument is to consider the test decision function as a function of the current data even when external information is included. We exemplify this finding in the case of a pediatric arm appended to an adult trial and dichotomous outcome for various methods of dynamic borrowing from adult information to the pediatric arm. In conclusion, if use of relevant external data is desired, the requirement of strict type I error control has to be replaced by more appropriate metrics.},
author = {Kopp-Schneider, Annette and Calderazzo, Silvia and Wiesenfarth, Manuel},
doi = {10.1002/bimj.201800395},
issn = {15214036},
journal = {Biometrical Journal},
keywords = {Bayesian dynamic borrowing of information,evidence synthesis,frequentist error control,historical information,robust prior},
number = {2},
pages = {361--374},
pmid = {31265159},
title = {{Power gains by using external information in clinical trials are typically not possible when requiring strict type I error control}},
volume = {62},
year = {2020}
}
@article{Kwiatkowski2015,
abstract = {Ensemble filters implement sequential Bayesian estimation by representing the probability distribution by an ensemble mean and covariance. Unbiased square root ensemble filters use deterministic algorithms to produce an analysis (posterior) ensemble with a prescribed mean and covariance, consistent with the Kalman update. This includes several filters used in practice, such as the ensemble transform Kalman filter, the ensemble adjustment Kalman filter, and a filter by Whitaker and Hamill. We show that at every time index, as the number of ensemble members increases to infinity, the mean and covariance of an unbiased ensemble square root filter converge to those of the Kalman filter, in the case of a linear model and an initial distribution of which all moments exist. The convergence is in all Lp, 1 ≤ p {\textless} ∞, with the usual rate 1/N, and the constant does not depend on the model or the data dimensions. The result holds in infinite-dimensional separable Hilbert spaces as well.},
archivePrefix = {arXiv},
arxivId = {1404.4093},
author = {Kwiatkowski, Evan and Mandel, Jan},
doi = {10.1137/140965363},
eprint = {1404.4093},
issn = {21662525},
journal = {SIAM-ASA Journal on Uncertainty Quantification},
keywords = {Continuity,Data assimilation,Ensemble kalman filter,Hilbert space,Kalman filter,Lp laws of large numbers,Stability},
title = {{Convergence of the square root ensemble kalman filter in the large ensemble limit}},
year = {2015}
}
@book{LeCam2000,
address = {New York},
author = {{Le Cam}, L. and Yang, G. L.},
publisher = {Springer},
title = {{Asymptotics in Statistics: Some Basic Concepts}},
year = {2000}
}
@article{Lek2019,
abstract = {The present paper contrasts two related criteria for the evaluation of prior-data conflict: the Data Agreement Criterion (DAC; Bousquet, 2008) and the criterion of Nott et al. (2016). One aspect that these criteria have in common is that they depend on a distance measure, of which dozens are available, but so far, only the Kullback-Leibler has been used. We describe and compare both criteria to determine whether a different choice of distance measure might impact the results. By means of a simulation study, we investigate how the choice of a specific distance measure influences the detection of prior-data conflict. The DAC seems more susceptible to the choice of distance measure, while the criterion of Nott et al. seems to lead to reasonably comparable conclusions of prior-data conflict, regardless of the distance measure choice. We conclude with some practical suggestions for the user of the DAC and the criterion of Nott et al. {\textcopyright} 2019 by the authors.},
address = {Department of Methods and Statistics, Utrecht University, 14 Utrecht, 3584 CH, Netherlands Optentia Research Program, Faculty of Humanities, North-West University, Vanderbijlpark, 1900, South Africa},
annote = {Export Date: 12 November 2019},
author = {Lek, K and {Van De Schoot}, R},
doi = {10.3390/e21050446},
journal = {Entropy},
keywords = {Data agreement criterion Distance measure Kullback},
number = {5},
title = {{How the choice of distance measure influences the detection of prior-data conflict}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066619915{\&}doi=10.3390{\%}2Fe21050446{\&}partnerID=40{\&}md5=724735d83aba34124ddbc0e2c9a796f8},
volume = {21},
year = {2019}
}
@article{Lewis2019,
abstract = {Some clinical trialists, especially those working in rare or pediatric disease, have suggested borrowing information from similar but already-completed clinical trials. This article begins with a case study in which relying solely on historical control information would have erroneously resulted in concluding a significant treatment effect. We then attempt to catalog situations where borrowing historical information may or may not be advisable using a series of carefully designed simulation studies. We use an MCMC-driven Bayesian hierarchical parametric survival modeling approach to analyze data from a sponsor's colorectal cancer study. We also apply these same models to simulated data comparing the effective historical sample size, bias, 95{\%} credible interval widths, and empirical coverage probabilities across the simulated cases. We find that even after accounting for variations in study design, baseline characteristics, and standard-of-care improvement, our approach consistently identifies Bayesianly significant differences between the historical and concurrent controls under a range of priors on the degree of historical data borrowing. Our simulation studies are far from exhaustive, but inform the design of future trials. When the historical and current controls are dissimilar, Bayesian methods can still moderate borrowing to a more appropriate level by adjusting for important covariates and adopting sensible priors.},
address = {B.P. Carlin, Counterpoint Statistical Consulting, Edina, MN, United States},
annote = {L627800299
2019-05-29
2019-06-03},
author = {Lewis, C J and Sarkar, S and Zhu, J and Carlin, B P},
doi = {10.1080/19466315.2018.1497533},
issn = {1946-6315},
journal = {Statistics in Biopharmaceutical Research},
keywords = {oxaliplatin article Bayes theorem Bayesian learnin},
language = {English LB  - Lewis2019},
number = {1},
pages = {67--78},
title = {{Borrowing From Historical Control Data in Cancer Drug Development: A Cautionary Tale and Practical Guidelines}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L627800299 http://dx.doi.org/10.1080/19466315.2018.1497533},
volume = {11},
year = {2019}
}
@article{Li2016,
annote = {Cited By :3
Export Date: 1 November 2019},
author = {Li, J X and Chen, W C and Scott, J A},
doi = {10.1080/10543406.2016.1226324},
journal = {Journal of Biopharmaceutical Statistics},
number = {6 LB  - Li2016},
pages = {1056--1066},
title = {{Addressing prior-data conflict with empirical meta-analytic-predictive priors in clinical studies with historical information}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989911474{\&}doi=10.1080{\%}2F10543406.2016.1226324{\&}partnerID=40{\&}md5=b8d9e32528c2f0378c26ec4d5947eb50},
volume = {26},
year = {2016}
}
@article{Li2019,
author = {Li, Xihao and Song, Yang},
doi = {10.1080/19466315.2019.1654913 LB  - Li2019},
issn = {null},
journal = {Statistics in Biopharmaceutical Research},
pages = {1--12},
title = {{Target Population Statistical Inference With Data Integration Across Multiple Sources—An Approach to Mitigate Information Shortage in Rare Disease Clinical Trials}},
url = {https://doi.org/10.1080/19466315.2019.1654913},
year = {2019}
}
@article{Lim2018,
abstract = {The goal of clinical trial research is to deliver safe and efficacious new treatments to patients in need in a timely and cost-effective manner. There is precedent in using historical control data to reduce the number of concurrent control subjects required in developing medicines for rare diseases and other areas of unmet need. The purpose of this paper is to provide a review for a regulatory and industry audience of the current state of relevant statistical methods, and of the uptake of these approaches and the opportunities for broader use of historical data in confirmatory clinical trials. General principles to consider when incorporating historical control data in a new trial are presented. Bayesian and frequentist approaches are outlined including how the operating characteristics for such a trial can be obtained. Finally, examples of approved new treatments that incorporated historical controls in their confirmatory trials are presented.},
address = {J. Lim, GlaxoSmithKline, 1250 S. Collegeville Road, Collegeville, PA, United States},
annote = {L622718846
2018-06-29
2018-10-02},
author = {Lim, J and Walley, R and Yuan, J and Liu, J and Dabral, A and Best, N and Grieve, A and Hampson, L and Wolfram, J and Woodward, P and Yong, F and Zhang, X and Bowen, E},
doi = {10.1177/2168479018778282},
issn = {2168-4804 2168-4790},
journal = {Therapeutic Innovation and Regulatory Science},
keywords = {Bayes theorem clinical trial (topic) drug industry},
language = {English LB  - Lim2018},
number = {5},
pages = {546--559},
title = {{Minimizing Patient Burden Through the Use of Historical Subject-Level Data in Innovative Confirmatory Clinical Trials: Review of Methods and Opportunities}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L622718846 http://dx.doi.org/10.1177/2168479018778282},
volume = {52},
year = {2018}
}
@article{Lin2018,
abstract = {Existing statutes in the United States and Europe require manufacturers to demonstrate evidence of effectiveness through the conduct of adequate and well-controlled studies to obtain marketing approval of a therapeutic product. What constitutes adequate and well-controlled studies is usually interpreted as randomized controlled trials (RCTs). However, these trials are sometimes unfeasible because of their size, duration, cost, patient preference, or in some cases, ethical concerns. For example, RCTs may not be fully powered in rare diseases or in infections caused by multidrug resistant pathogens because of the low number of enrollable patients. In this case, data available from external controls (including historical controls and observational studies or data registries) can complement information provided by RCT. Propensity score matching methods can be used to select or "borrow" additional patients from the external controls, for maintaining a one-to-one randomization between the treatment arm and active control, by matching the new treatment and control units based on a set of measured covariates, ie, model-based pairing of treatment and control units that are similar in terms of their observable pretreatment characteristics. To this end, 2 matching schemes based on propensity scores are explored and applied to a real clinical data example with the objective of using historical or external observations to augment data in a trial where the randomization is disproportionate or asymmetric.},
address = {AbbVie, North Chicago, IL, 60064, USA. Eli Lilly and Co, Indianapolis, IN, 46225, USA. Division of Biostatistics, Center for Devices and Radiological Health, Food and Drug Administration, Silver Spring, MD, 20993-0000, USA.},
annote = {1539-1612
Lin, Junjing
Gamalo-Siebers, Margaret
Orcid: 0000-0003-2428-3298
Tiwari, Ram
Journal Article
England
Pharm Stat. 2018 Sep;17(5):629-647. doi: 10.1002/pst.1879. Epub 2018 Jul 31.},
author = {Lin, J and Gamalo-Siebers, M and Tiwari, R},
doi = {10.1002/pst.1879},
edition = {2018/08/02},
issn = {1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {Drug Approval/*legislation {\&} jurisprudence Europe },
language = {eng LB  - Lin2018},
number = {5},
pages = {629--647},
title = {{Propensity score matched augmented controls in randomized clinical trials: A case study}},
volume = {17},
year = {2018}
}
@article{Lin2019,
abstract = {Drug developers are required to demonstrate substantial evidence of effectiveness through the conduct of adequate and well-controlled (A{\&}WC) studies to obtain marketing approval of their medicine. What constitutes A{\&}WC is interpreted as the conduct of randomized controlled trials (RCTs). However, these trials are sometimes unfeasible because of their size, duration, and cost. One way to reduce sample size is to leverage information on the control through a prior. One consideration when forming data-driven prior is the consistency of the external and the current data. It is essential to make this process less susceptible to choosing information that only helps improve the chances toward making an effectiveness claim. For this purpose, propensity score methods are employed for two reasons: (1) it gives the probability of a patient to be in the trial, and (2) it minimizes selection bias by pairing together treatment and control within the trial and control subjects in the external data that are similar in terms of their pretreatment characteristics. Two matching schemes based on propensity scores, estimated through generalized boosted methods, are applied to a real example with the objective of using external data to perform Bayesian augmented control in a trial where the allocation is disproportionate. The simulation results show that the data augmentation process prevents prior and data conflict and improves the precision of the estimator of the average treatment effect.},
address = {M. Gamalo-Siebers, Eli Lilly and Company, Indianapolis, IN, United States},
annote = {L625411680
2018-12-17
2019-04-02},
author = {Lin, J and Gamalo-Siebers, M and Tiwari, R},
doi = {10.1002/pst.1918},
issn = {1539-1612 1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {article Bayes theorem clinical effectiveness data },
language = {English LB  - Lin2019},
number = {2},
pages = {223--238},
title = {{Propensity-score-based priors for Bayesian augmented control design}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L625411680 http://dx.doi.org/10.1002/pst.1918},
volume = {18},
year = {2019}
}
@article{Liu2014,
abstract = {A critical step in group sequential designs is computation of the appropriate critical values for rejecting H0 at the interim look to keep the overall type I error rate at a prespecified level. When applying the sequential test in a study with an equivalence hypothesis, calculation of the critical values is complicated by the dependency between the dual test statistics at each interim look. Current methods for calculating critical values apply two primary approximations: z-statistics assuming a large sample size, and ignorance of the contribution to the overall type I error rate from rejecting one out of the two one-sided hypotheses under a null value. In the sequential testing, with smaller stagewise sample size and type I error rate, the first approximation would result in unsatisfactory inflation of the type I error rate, and the second approximation could lead to excessive conservatism. We establish a mathematical and computational framework of the exact sequential test based on bivariate non-central t statistics and propose several numerical approaches for computing the exact equivalence boundaries and futility boundaries. Examples and simulation studies are used to compare the operating characteristics between the exact test procedure and three other approximate test procedures.},
author = {Liu, Fang and Li, Qing},
doi = {https://doi.org/10.1016/j.csda.2014.02.007},
issn = {0167-9473},
journal = {Computational Statistics and Data Analysis},
keywords = {Equivalence boundaries Equivalence hypothesis Expe},
pages = {14--24},
title = {{Exact sequential test of equivalence hypothesis based on bivariate non-central t-statistics}},
volume = {77},
year = {2014}
}
@article{Liu2018,
abstract = {Traditionally, noninferiority hypotheses have been tested using a frequentist method with a fixed margin. Given that information for the control group is often available from previous studies, it is interesting to consider a Bayesian approach in which information is “borrowed” for the control group to improve efficiency. However, construction of an appropriate informative prior can be challenging. In this paper, we consider a hybrid Bayesian approach for testing noninferiority hypotheses in studies with a binary endpoint. To account for heterogeneity between the historical information and the current trial for the control group, a dynamic P value–based power prior parameter is proposed to adjust the amount of information borrowed from the historical data. This approach extends the simple test-then-pool method to allow a continuous discounting power parameter. An adjusted $\alpha$ level is also proposed to better control the type I error. Simulations are conducted to investigate the performance of the proposed method and to make comparisons with other methods including test-then-pool and hierarchical modeling. The methods are illustrated with data from vaccine clinical trials.},
address = {G.F. Liu, Merck {\&} Co., Inc., North Wales, PA, United States},
annote = {L619224225
2017-11-17
2018-12-21},
author = {Liu, G F},
doi = {10.1002/pst.1836},
issn = {1539-1612 1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {article Bayes theorem data analysis information re},
language = {English LB  - Liu2018},
number = {1},
pages = {61--73},
title = {{A dynamic power prior for borrowing historical data in noninferiority trials with binary endpoint}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L619224225 http://dx.doi.org/10.1002/pst.1836},
volume = {17},
year = {2018}
}
@article{Liu2008,
author = {Liu, Yufeng and Hayes, David Neil and Nobel, Andrew and Marron, J S},
doi = {10.1198/016214508000000454},
journal = {Journal of the American Statistical Association},
number = {483},
pages = {1281--1293},
title = {{Statistical Significance of Clustering for High-Dimension, Low-Sample Size Data}},
volume = {103},
year = {2008}
}
@article{Lystig2018,
author = {Lystig, T},
doi = {10.1177/1740774518790846},
journal = {Clinical Trials},
number = {2{\_}suppl LB  - Lystig2018},
pages = {S35--S192},
title = {{Invited Session 22 - Dynamic Determination of a Power Prior Parameter – the Discount Prior Approach}},
url = {https://journals.sagepub.com/doi/abs/10.1177/1740774518790846},
volume = {15},
year = {2018}
}
@article{Madigan1994,
author = {Madigan, David and Raftery, Adrian E},
doi = {10.2307/2291017},
issn = {01621459},
journal = {Journal of the American Statistical Association},
number = {428},
pages = {1535},
title = {{Model Selection and Accounting for Model Uncertainty in Graphical Models Using Occam's Window}},
volume = {89},
year = {1994}
}
@article{Martina2018,
abstract = {Background: When designing studies it is common to search the literature to investigate variability estimates to use in sample size calculations. Proprietary data of previously designed trials in a particular indication are also used to obtain estimates of variability. Estimates of treatment effects are typically obtained from randomised controlled clinical trials (RCTs). Based on the observed estimates of treatment effect, variability and the minimum clinical relevant difference to detect, the sample size for a subsequent trial is estimated. However, data from real world evidence (RWE) studies, such as observational studies and other interventional studies in patients in routine clinical practice, are not widely used in a systematic manner when designing studies. In this paper, we propose a framework for inclusion of RWE in planning of a clinical development programme. Methods: In our proposed approach, all evidence, from both RCTs and RWE (i.e. from studies in routine clinical practice), available at the time of designing of a new clinical trial is combined in a Bayesian network meta-analysis (NMA). The results can be used to inform the design of the next clinical trial in the programme. The NMA was performed at key milestones, such as at the end of the phase II trial and prior to the design of key phase III studies. To illustrate the methods, we designed an alternative clinical development programme in multiple sclerosis using RWE through clinical trial simulations. Results: Inclusion of RWE in the NMA and the resulting trial simulations demonstrated that 284 patients per arm were needed to achieve 90{\%} power to detect effects of predetermined size in the TRANSFORMS study. For the FREEDOMS and FREEDOMS II clinical trials, 189 patients per arm were required. Overall there was a reduction in sample size of at least 40{\%} across the three phase III studies, which translated to a time savings of at least 6months for the undertaking of the fingolimod phase III programme. Conclusion: The use of RWE resulted in a reduced sample size of the pivotal phase III studies, which led to substantial time savings compared to the approach of sample size calculations without RWE.},
address = {R. Martina, University of Leicester, Department of Health Sciences, University Road, Leicester, United Kingdom},
annote = {L623684406
2018-09-05
2019-10-31},
author = {Martina, R and Jenkins, D and Bujkiewicz, S and Dequen, P and Abrams, K},
doi = {10.1186/s13063-018-2769-2},
issn = {1745-6215},
journal = {Trials},
keywords = {beta1a interferon fingolimod glatiramer interferon},
language = {English LB  - Martina2018},
number = {1},
title = {{The inclusion of real world evidence in clinical development planning}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L623684406 http://dx.doi.org/10.1186/s13063-018-2769-2},
volume = {19},
year = {2018}
}
@article{McCarron2017,
abstract = {Background: Non-randomised studies (non-RCTs), primarily, observational studies, make up the bulk of 'real world' evidence. By combining randomised controlled trials (RCTs) with non-RCTs, we attempt to expand the evidence base for evaluating comparative effectiveness in the real world. This strategy supplements insufficient data based solely on RCTs for patient outcomes which are directly relevant to evidence-based decision making. Objectives: To propose a Bayesian framework for synthesising RCT and non-RCT studies to estimate comparative effectiveness. Methods: As an intervention (e.g., drug, medical device) matures over its life cycle, different sources of evidence on its effect may become available. The proposed framework adopts an iterative Bayesian approach wherein evidence from RCTs is used as a prior distribution that is updated with information from non-RCTs. Results: A Bayesian framework is proposed for synthesising information on the effect of an intervention based on both RCTs and non-RCTs. The application of the proposed framework is demonstrated in the context of a case study. The case study consists of 4 RCTs and 40 non-RCTs comparing endovascular and open surgical repair for the treatment of abdominal aortic aneurysms. The proposed approach involves the synthesis of comparative data on the odds of 30-day mortality from the RCTs, the result of which is then used as a prior distribution for a Bayesian meta-analysis combining the 40 non-RCTs. The impact of the relative weighting of the evidence sources is also assessed. Conclusions: Interventions adopted for use in routine practice will have a life cycle spanning adoption to possible displacement or disinvestment. Evidencebased decisions will require information on the 'real world' effect of the intervention over its life cycle. A Bayesian framework capable of synthesising information from both RCTs and non-RCTs will allow for decisions based on 'real world' evidence of comparative effectiveness.},
address = {C.E. McCarron, CADTH, Ottawa, ON, Canada},
annote = {L618125339
2017-09-08},
author = {McCarron, C E and Yuan, H},
doi = {10.1002/pds.4275},
issn = {1099-1557},
journal = {Pharmacoepidemiology and Drug Safety},
keywords = {abdominal aortic aneurysm adoption comparative eff},
language = {English LB  - McCarron2017},
pages = {527},
title = {{Comparative effectiveness research in the real world: A bayesian framework for synthesising evidence from RCT and non-RCT studies}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L618125339 http://dx.doi.org/10.1002/pds.4275},
volume = {26},
year = {2017}
}
@article{McNeish2017,
abstract = {Two classes of methods properly account for clustering of data: design-based methods and model-based methods. Estimates from both methods have been shown to be approximately equal with large samples. However, both classes are known to produce biased standard error estimates with small samples. This paper compares the bias of standard errors and statistical power of marginal effects for generalized estimating equations (a design-based method) and generalized/linear mixed effects models (model-based methods) with small sample sizes via a simulation study. Provided that the distributional assumptions are met, model-based methods produced the least-biased standard error estimates and greater relative statistical power.},
author = {McNeish, Daniel M and Harring, Jeffery R},
doi = {10.1080/03610918.2014.983648},
issn = {0361-0918},
journal = {Communications in Statistics - Simulation and Computation},
keywords = {62J05 62J12 GEE Kenward-Roger Mixed model Multilev},
number = {2},
pages = {855--869},
title = {{Clustered data with small sample sizes: Comparing the performance of model-based and design-based approaches}},
volume = {46},
year = {2017}
}
@article{Mielke2018,
abstract = {For the approval of biosimilars, it is, in most cases, necessary to conduct large Phase III clinical trials in patients to convince the regulatory authorities that the product is comparable in terms of efficacy and safety to the originator product. As the originator product has already been studied in several trials beforehand, it seems natural to include this historical information into the showing of equivalent efficacy. Since all studies for the regulatory approval of biosimilars are confirmatory studies, it is required that the statistical approach has reasonable frequentist properties, most importantly, that the Type I error rate is controlled-at least in all scenarios that are realistic in practice. However, it is well known that the incorporation of historical information can lead to an inflation of the Type I error rate in the case of a conflict between the distribution of the historical data and the distribution of the trial data. We illustrate this issue and confirm, using the Bayesian robustified meta-analytic-predictive (MAP) approach as an example, that simultaneously controlling the Type I error rate over the complete parameter space and gaining power in comparison to a standard frequentist approach that only considers the data in the new study, is not possible. We propose a hybrid Bayesian-frequentist approach for binary endpoints that controls the Type I error rate in the neighborhood of the center of the prior distribution, while improving the power. We study the properties of this approach in an extensive simulation study and provide a real-world example.},
annote = {L626379148
2019-02-20
2019-06-20},
author = {Mielke, J and Schmidli, H and Jones, B},
doi = {10.1002/bimj.201700152},
issn = {1521-4036},
journal = {Biometrical Journal.},
keywords = {biosimilar agent Bayes theorem biometry clinical t},
language = {English LB  - Mielke2018},
number = {3},
pages = {564--582},
title = {{Incorporating historical information in biosimilar trials: Challenges and a hybrid Bayesian-frequentist approach}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L626379148 http://dx.doi.org/10.1002/bimj.201700152},
volume = {60},
year = {2018}
}
@article{Mitroiu2018,
abstract = {Background: The ASTERIX project developed a number of novel methods suited to study small populations. The objective of this exercise was to evaluate the applicability and added value of novel methods to improve drug development in small populations, using real world drug development programmes as reported in European Public Assessment Reports. Methods: The applicability and added value of thirteen novel methods developed within ASTERIX were evaluated using data from 26 European Public Assessment Reports (EPARs) for orphan medicinal products, representative of rare medical conditions as predefined through six clusters. The novel methods included were 'innovative trial designs' (six methods), 'level of evidence' (one method), 'study endpoints and statistical analysis' (four methods), and 'meta-analysis' (two methods) and they were selected from the methods developed within ASTERIX based on their novelty; methods that discussed already available and applied strategies were not included for the purpose of this validation exercise. Pre-requisites for application in a study were systematized for each method, and for each main study in the selected EPARs it was assessed if all pre-requisites were met. This direct applicability using the actual study design was firstly assessed. Secondary, applicability and added value were explored allowing changes to study objectives and design, but without deviating from the context of the drug development plan. We evaluated whether differences in applicability and added value could be observed between the six predefined condition clusters. Results and discussion: Direct applicability of novel methods appeared to be limited to specific selected cases. The applicability and added value of novel methods increased substantially when changes to the study setting within the context of drug development were allowed. In this setting, novel methods for extrapolation, sample size re-assessment, multi-armed trials, optimal sequential design for small sample sizes, Bayesian sample size re-estimation, dynamic borrowing through power priors and fall-back tests for co-primary endpoints showed most promise - applicable in more than 40{\%} of evaluated EPARs in all clusters. Most of the novel methods were applicable to conditions in the cluster of chronic and progressive conditions, involving multiple systems/organs. Relatively fewer methods were applicable to acute conditions with single episodes. For the chronic clusters, Goal Attainment Scaling was found to be particularly applicable as opposed to other (non-chronic) clusters. Conclusion: Novel methods as developed in ASTERIX can improve drug development programs. Achieving optimal added value of these novel methods often requires consideration of the entire drug development program, rather than reconsideration of methods for a specific trial. The novel methods tested were mostly applicable in chronic conditions, and acute conditions with recurrent episodes.},
address = {C. Pontes, Departament de Farmacologia de Terap{\`{e}}utica i de Toxicologia, Universitat Aut{\`{o}}noma de Barcelona, Unitat Docent Parc Taul{\'{i}}, c/ Parc Taul{\'{i}} 1, Sabadell, Spain},
annote = {L624843192
2019-01-11
2019-05-14},
author = {Mitroiu, M and Rengerink, K O and Pontes, C and Sancho, A and Vives, R and Pesiou, S and Fontanet, J M and Torres, F and Nikolakopoulos, S and Pateras, K and Rosenkranz, G and Posch, M and Urach, S and Ristl, R and Koch, A and Loukia, S and {Van Der Lee}, J H and Roes, K C B},
doi = {10.1186/s13023-018-0925-0},
issn = {1750-1172},
journal = {Orphanet Journal of Rare Diseases},
keywords = {herbaceous agent analytic method article clinical },
language = {English LB  - Mitroiu2018},
number = {1},
title = {{Applicability and added value of novel methods to improve drug development in rare diseases}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L624843192 http://dx.doi.org/10.1186/s13023-018-0925-0},
volume = {13},
year = {2018}
}
@article{Morikawa1995,
author = {Morikawa, Toshihiko and Yoshida, Michihiro},
doi = {10.1080/10543409508835115},
journal = {Journal of biopharmaceutical statistics},
pages = {297--306},
title = {{A useful testing strategy in phase III trials: Combined test of superiority and test of equivalence}},
volume = {5},
year = {1995}
}
@article{Murray2014,
abstract = {Trial investigators often have a primary interest in the estimation of the survival curve in a population for which there exists acceptable historical information from which to borrow strength. However, borrowing strength from a historical trial that is non-exchangeable with the current trial can result in biased conclusions. In this article we propose a fully Bayesian semiparametric method for the purpose of attenuating bias and increasing efficiency when jointly modeling time-to-event data from two possibly non-exchangeable sources of information. We illustrate the mechanics of our methods by applying them to a pair of post-market surveillance datasets regarding adverse events in persons on dialysis that had either a bare metal or drug-eluting stent implanted during a cardiac revascularization surgery. We finish with a discussion of the advantages and limitations of this approach to evidence synthesis, as well as directions for future work in this area. The article's Supplementary Materials offer simulations to show our procedure's bias, mean squared error, and coverage probability properties in a variety of settings.},
address = {Division of Biostatistics, School of Public Health, University of Minnesota, Minneapolis, Minnesota, U.S.A.; United States Renal Data System, Minneapolis Medical Research Foundation, Minneapolis, Minnesota, U.S.A.},
annote = {1541-0420
Murray, Thomas A
Hobbs, Brian P
Lystig, Theodore C
Carlin, Bradley P
P30 CA016672/CA/NCI NIH HHS/United States
R01 CA157458/CA/NCI NIH HHS/United States
1-R01-CA157458-01A1/CA/NCI NIH HHS/United States
Journal Article
Research Support, N.I.H., Extramural
United States
Biometrics. 2014 Mar;70(1):185-91. doi: 10.1111/biom.12115. Epub 2013 Dec 5.},
author = {Murray, T A and Hobbs, B P and Lystig, T C and Carlin, B P},
doi = {10.1111/biom.12115},
edition = {2013/12/07},
issn = {0006-341x},
journal = {Biometrics},
keywords = {Adult Aged *Bayes Theorem Computer Simulation Drug},
language = {eng LB  - Murray2014},
number = {1},
pages = {185--191},
title = {{Semiparametric Bayesian commensurate survival model for post-market medical device surveillance with non-exchangeable historical data}},
volume = {70},
year = {2014}
}
@article{Mutsvari2017,
abstract = {The authors wish to correct several typographical errors in the publication. In section 2.2, the mean of the component-specific posterior density should read as follows: (Formula presented.) In the second paragraph of section 4.2, the precise prior has a standard deviation of $\sigma$0 and the simulated discrepancies between the true mean and the mean of the precise prior are 0, 2$\sigma$0 and 4$\sigma$0. Similarly in the second paragraph of section 5.1 a true mean of 0.81 is equal to 2.58$\sigma$0. In each of the above cases the error relates to the subscript for $\sigma$. In addition, in the case study in section 6, the Bayesian prior for the thiotepa study should be referenced to Table 5.3 of Spiegelhalter et al. and reference 18 should be for Ibrahim and Chen. Copyright {\textcopyright} 2017 John Wiley {\&} Sons, Ltd.},
annote = {Export Date: 12 November 2019},
author = {Mutsvari, T and Tytgat, D and Walley, R},
doi = {10.1002/pst.1802},
journal = {Pharmaceutical Statistics},
number = {2 LB  - Mutsvari2017},
pages = {174},
title = {{Erratum to: Addressing potential prior-data conflict when using informative priors in proof-of-concept studies (Pharmaceutical Statistics, (2016), 15, 1, (28-36), 10.1002/pst.1722)}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013680698{\&}doi=10.1002{\%}2Fpst.1802{\&}partnerID=40{\&}md5=8daaa03010d30e63f9695686a734154e},
volume = {16},
year = {2017}
}
@article{Mutsvari2016,
abstract = {Bayesian methods are increasingly used in proof-of-concept studies. An important benefit of these methods is the potential to use informative priors, thereby reducing sample size. This is particularly relevant for treatment arms where there is a substantial amount of historical information such as placebo and active comparators. One issue with using an informative prior is the possibility of a mismatch between the informative prior and the observed data, referred to as prior-data conflict. We focus on two methods for dealing with this: a testing approach and a mixture prior approach. The testing approach assesses prior-data conflict by comparing the observed data to the prior predictive distribution and resorting to a non-informative prior if prior-data conflict is declared. The mixture prior approach uses a prior with a precise and diffuse component. We assess these approaches for the normal case via simulation and show they have some attractive features as compared with the standard one-component informative prior. For example, when the discrepancy between the prior and the data is sufficiently marked, and intuitively, one feels less certain about the results, both the testing and mixture approaches typically yield wider posterior-credible intervals than when there is no discrepancy. In contrast, when there is no discrepancy, the results of these approaches are typically similar to the standard approach. Whilst for any specific study, the operating characteristics of any selected approach should be assessed and agreed at the design stage; we believe these two approaches are each worthy of consideration.},
address = {R. Walley, UCB Pharma, Global Exploratory Development, 208 Bath Road, Slough, Berkshire, United Kingdom},
annote = {L607769291
2016-01-25},
author = {Mutsvari, T and Tytgat, D and Walley, R},
doi = {10.1002/pst.1722},
issn = {1539-1612 1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {controlled study},
language = {English LB  - Mutsvari2016},
number = {1},
pages = {28--36},
title = {{Addressing potential prior-data conflict when using informative priors in proof-of-concept studies}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L607769291 http://dx.doi.org/10.1002/pst.1722},
volume = {15},
year = {2016}
}
@article{Mutze2018,
abstract = {Prior information is often incorporated informally when planning a clinical trial. Here, we present an approach on how to incorporate prior information, such as data from historical clinical trials, into the nuisance parameter–based sample size re-estimation in a design with an internal pilot study. We focus on trials with continuous endpoints in which the outcome variance is the nuisance parameter. For planning and analyzing the trial, frequentist methods are considered. Moreover, the external information on the variance is summarized by the Bayesian meta-analytic-predictive approach. To incorporate external information into the sample size re-estimation, we propose to update the meta-analytic-predictive prior based on the results of the internal pilot study and to re-estimate the sample size using an estimator from the posterior. By means of a simulation study, we compare the operating characteristics such as power and sample size distribution of the proposed procedure with the traditional sample size re-estimation approach that uses the pooled variance estimator. The simulation study shows that, if no prior-data conflict is present, incorporating external information into the sample size re-estimation improves the operating characteristics compared to the traditional approach. In the case of a prior-data conflict, that is, when the variance of the ongoing clinical trial is unequal to the prior location, the performance of the traditional sample size re-estimation procedure is in general superior, even when the prior information is robustified. When considering to include prior information in sample size re-estimation, the potential gains should be balanced against the risks.},
address = {T. M{\"{u}}tze, Department of Medical Statistics, University Medical Center G{\"{o}}ttingen, G{\"{o}}ttingen, Germany},
annote = {L619465662
2017-12-05
2018-04-05},
author = {Mutze, T and Schmidli, H and Friede, T},
doi = {10.1002/pst.1837},
issn = {1539-1612 1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {clinical trial controlled clinical trial controlle},
language = {English LB  - M{\"{u}}tze2018},
number = {2},
pages = {126--143},
title = {{Sample size re-estimation incorporating prior information on a nuisance parameter}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L619465662 http://dx.doi.org/10.1002/pst.1837},
volume = {17},
year = {2018}
}
@article{Nadarajah2005,
author = {Nadarajah, Saralees},
doi = {10.1080/02664760500079464},
issn = {0266-4763},
journal = {Journal of Applied Statistics},
number = {7},
pages = {685--694},
title = {{A generalized normal distribution}},
type = {Journal Article},
url = {https://doi.org/10.1080/02664760500079464},
volume = {32},
year = {2005}
}
@article{Nagase2019,
abstract = {Background: Determination of the number of subjects is one among the most important aspects in clinical study design. Use of historical data (borrowing) from past studies is an attractive approach. Here, we propose a practical and relevant approach to guide the optimal borrowing rate a0 ({\%} of subjects in an earlier study, from whom data were borrowed) and the number of subjects in the new study n. Methods: The Power Prior (PP) (Ibrahim 2000) approach is applied to assess the posterior distribution for a future study. Researchers usually set acceptable ranges for parameters, eg mean and 95{\%} CI. The probability of obtaining parameters within these ranges (i) can be explicitly computed based on the posterior distribution, expressed as a function of n and a0, and (ii) should be proportional both to the probability of getting positive trial results and the expected revenue. This probability, divided by the cost of the new trial (fixed cost + n × unit variable cost), then provides a measure for the Return on Investment (ROI). The cost being a function of n, one may then find an optimal {\{}n, a0{\}} based on ROI. Results: We applied the PP method retrospectively to a dapagliflozin 24-week global trial in type 2 diabetes (65 patients on treatment, 75 on placebo) and investigated mean differences in HbA1c changes, treatment vs. placebo. This reduced the number of subjects in the planned Japan trial by 42.5{\%} (50 patients in a borrowing vs. 87 in a non-borrowing scenario) and increase the ROI by 9.1{\%}. Conclusion: The PP approach can guide efficient clinical trial design. In particular, when a determination in subject number is needed, the approach is useful in estimating a reasonable study size based on ROI. We identified the optimal borrowing rate and subject number under conditions necessary for possible successful regulatory approval.},
address = {M. Nagase, AstraZeneca, Waltham, MA, United States},
annote = {L626603050
2019-03-08},
author = {Nagase, M and Dunyak, J and Al-Huniti, N},
doi = {10.1002/(ISSN)1532-6535},
issn = {1532-6535},
journal = {Clinical Pharmacology and Therapeutics},
keywords = {dapagliflozin hemoglobin A1c placebo adult confere},
language = {English LB  - Nagase2019},
pages = {S64},
title = {{A bayesian method for the modeling, design, and analysis of drug development bridging studies across geographies}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L626603050 http://dx.doi.org/10.1002/(ISSN)1532-6535},
volume = {105},
year = {2019}
}
@article{Nagase2019a,
abstract = {As described in the ICH E5 guidelines, a bridging study is an additional study executed in a new geographical region or subpopulation to link or “build a bridge” from global clinical trial outcomes to the new region. The regulatory and scientific goals of a bridging study is to evaluate potential subpopulation differences while minimizing duplication of studies and meeting unmet medical needs expeditiously. Use of historical data (borrowing) from global studies is an attractive approach to meet these conflicting goals. Here, we propose a practical and relevant approach to guide the optimal borrowing rate (percent of subjects in earlier studies) and the number of subjects in the new regional bridging study. We address the limitations in global/regional exchangeability through use of a Bayesian power prior method and then optimize bridging study design with a return on investment viewpoint. The method is demonstrated using clinical data from global and Japanese trials in dapagliflozin for type 2 diabetes.},
address = {M. Nagase, Clinical Pharmacology {\&} Safety Sciences, R{\&}D, AstraZeneca, Boston, United States},
annote = {L2002612386
2019-09-02},
author = {Nagase, M and Ueda, S and Higashimori, M and Ichikawa, K and Dunyak, J and Al-Huniti, N},
doi = {10.1002/pst.1967},
issn = {1539-1612 1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {adult article controlled study drug therapy human },
language = {English LB  - Nagase2019},
title = {{Optimal designs for regional bridging studies using the Bayesian power prior method}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L2002612386 http://dx.doi.org/10.1002/pst.1967},
year = {2019}
}
@article{Navarra2011,
annote = {doi: 10.1016/S0140-6736(10)61354-2},
author = {Navarra, Sandra V and Guzm{\'{a}}n, Renato M and Gallacher, Alberto E and Hall, Stephen and Levy, Roger A and Jimenez, Renato E and Li, Edmund K-M and Thomas, Mathew and Kim, Ho-Youn and Le{\'{o}}n, Manuel G and Tanasescu, Coman and Nasonov, Eugeny and Lan, Joung-Liang and Pineda, Lilia and Zhong, Z John and Freimuth, William and Petri, Michelle A},
doi = {10.1016/S0140-6736(10)61354-2},
issn = {0140-6736},
journal = {The Lancet},
month = {feb},
number = {9767},
pages = {721--731},
publisher = {Elsevier},
title = {{Efficacy and safety of belimumab in patients with active systemic lupus erythematosus: a randomised, placebo-controlled, phase 3 trial}},
url = {https://doi.org/10.1016/S0140-6736(10)61354-2},
volume = {377},
year = {2011}
}
@article{Neuenschwander2010,
abstract = {Background Historical information is always relevant when designing clinical trials, but it might also be incorporated in the analysis. It seems appropriate to exploit past information on comparable control groups. Purpose Phase IV and proof-of-concept trials are used to discuss aspects of summarizing historical control data as prior information in a new trial. The importance of a fair assessment of the similarity of control parameters is emphasized. Methods The methodology is meta-analytic-predictive. Heterogeneity of control parameters is expressed via the between-trial variation, which is the key parameter determining the prior effective sample size and its upper bound (prior maximum sample size). Results For a Phase IV trial (930 control patients in 11 historical trials) between-trial heterogeneity was fairly small, resulting in a prior effective sample size of approximately 90 patients. For a proof-of-concept trial (363 patients in four historical trials) heterogeneity was moderate to substantial, resulting in a prior effective sample size of approximately 20. For another proof-of-concept trial (14 patients in one historical trial), assuming substantial heterogeneity implied a prior effective sample size of 7. The prior effective sample size can only be large if the amount of historical data is large and between-trial heterogeneity is small. The prior effective sample size is bounded by the prior maximum sample size (ratio of within- to between-trial variance), irrespective of the amount of historical data. Limitations The meta-analytic-predictive approach assumes exchangeability of control parameters across trials. Due to the difficulty to quantify between-trial variability, sensitivity of conclusions regarding assumptions and type of inference should be assessed. Conclusions The use of historical control information is a valuable option and may lead to more efficient clinical trials. The proposed approach is attractive for nonconfirmatory trials, but under certain circumstances extensions to the confirmatory setting could be envisaged as well.},
address = {B. Neuenschwander, Clinical Information Sciences, Novartis Pharma, 4002 Basel, Switzerland},
annote = {L358409442
2010-03-16
2010-04-16},
author = {Neuenschwander, B and Capkun-Niggli, G and Branson, M and Spiegelhalter, D J},
doi = {10.1177/1740774509356002},
issn = {1740-7745 1740-7753},
journal = {Clinical Trials},
keywords = {anxiety article Bayes theorem binomial distributio},
language = {English LB  - Neuenschwander2010},
number = {1},
pages = {5--18},
title = {{Summarizing historical information on controls in clinical trials}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L358409442 http://dx.doi.org/10.1177/1740774509356002},
volume = {7},
year = {2010}
}
@article{Ng1995,
author = {Ng, Tie-Hua},
doi = {https://doi.org/10.1016/0197-2456(95)00040-2},
issn = {0197-2456},
journal = {Controlled Clinical Trials},
number = {5},
pages = {356--358},
title = {{Conventional null hypothesis testing in active control equivalence studies}},
volume = {16},
year = {1995}
}
@article{Nikolakopoulos2018,
abstract = {In order for historical data to be considered for inclusion in the design and analysis of clinical trials, prospective rules are essential. Incorporation of historical data may be of particular interest in the case of small populations where available data is scarce and heterogeneity is not as well understood, and thus conventional methods for evidence synthesis might fall short. The concept of power priors can be particularly useful for borrowing evidence from a single historical study. Power priors employ a parameter {\textless}mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"{\textgreater}{\textless}mml:mi{\textgreater}$\gamma${\textless}/mml:mi{\textgreater} {\textless}mml:mo{\textgreater}∈{\textless}/mml:mo{\textgreater} {\textless}mml:mo{\textgreater}[{\textless}/mml:mo{\textgreater} {\textless}mml:mn{\textgreater}0{\textless}/mml:mn{\textgreater} {\textless}mml:mo{\textgreater},{\textless}/mml:mo{\textgreater} {\textless}mml:mn{\textgreater}1{\textless}/mml:mn{\textgreater} {\textless}mml:mo{\textgreater}]{\textless}/mml:mo{\textgreater}{\textless}/mml:math{\textgreater} that quantifies the heterogeneity between the historical study and the new study. However, the possibility of borrowing data from a historical trial will usually be associated with an inflation of the type I error. We suggest a new, simple method of estimating the power parameter suitable for the case when only one historical dataset is available. The method is based on predictive distributions and parameterized in such a way that the type I error can be controlled by calibrating to the degree of similarity between the new and historical data. The method is demonstrated for normal responses in a one or two group setting. Generalization to other models is straightforward.},
annote = {L627188433
2019-04-17},
author = {Nikolakopoulos, S and van der Tweel, I and Roes, K C B},
doi = {10.1111/biom.12835},
issn = {1541-0420},
journal = {Biometrics},
keywords = {clinical trial (topic) epidemiology information pr},
language = {English LB  - Nikolakopoulos2018},
number = {3},
pages = {874--880},
title = {{Dynamic borrowing through empirical power priors that control type I error}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L627188433 http://dx.doi.org/10.1111/biom.12835},
volume = {74},
year = {2018}
}
@article{Nott2016,
author = {Nott, D J and Xueou, W and Evans, M and Englert, B.-G. L B - Nott2016},
journal = {2016},
title = {{Checking for prior-data conflict using prior to posterior divergences.}},
volume = {arXiv:1611},
year = {2016}
}
@article{Ochiai2017,
author = {Ochiai, Toshimitsu and Hamasaki, Toshimitsu and Evans, Scott R and Asakura, Koko and Ohno, Yuko},
doi = {10.1080/10543406.2016.1148710},
journal = {Journal of Biopharmaceutical Statistics},
number = {1},
pages = {1--24},
title = {{Group-sequential three-arm noninferiority clinical trial designs}},
volume = {27},
year = {2017}
}
@article{Ollier2019,
author = {Ollier, Adrien and Morita, Satoshi and Ursino, Moreno and Zohar, Sarah},
doi = {10.1177/0962280219886609},
issn = {0962-2802},
journal = {Statistical Methods in Medical Research},
month = {apr},
pages = {0962280219886609},
title = {{An adaptive power prior for sequential clinical trials – Application to bridging studies}},
url = {https://doi.org/10.1177/0962280219886609},
year = {2019}
}
@article{Pan2017,
annote = {Cited By :3
Export Date: 1 November 2019},
author = {Pan, H and Yuan, Y and Xia, J},
doi = {10.1111/rssc.12204},
journal = {Journal of the Royal Statistical Society. Series C: Applied Statistics},
number = {5 LB  - Pan2017},
pages = {979--996},
title = {{A calibrated power prior approach to borrow information from historical data with application to biosimilar clinical trials}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007467246{\&}doi=10.1111{\%}2Frssc.12204{\&}partnerID=40{\&}md5=bf8eee6fb63c294ef6c88e31533a4d2e},
volume = {66},
year = {2017}
}
@article{Powell2012,
abstract = {Efforts to identify, develop, refine, and test strategies to disseminate and implement evidence-based treatments have been prioritized in order to improve the quality of health and mental health care delivery. However, this task is complicated by an implementation science literature characterized by inconsistent language use and inadequate descriptions of implementation strategies. This article brings more depth and clarity to implementation research and practice by presenting a consolidated compilation of discrete implementation strategies, based on a review of 205 sources published between 1995 and 2011. The resulting compilation includes 68 implementation strategies and definitions, which are grouped according to six key implementation processes: planning, educating, financing, restructuring, managing quality, and attending to the policy context. This consolidated compilation can serve as a reference to stakeholders who wish to implement clinical innovations in health and mental health care and can facilitate the development of multifaceted, multilevel implementation plans that are tailored to local contexts.},
author = {Powell, Byron J and McMillen, J Curtis and Proctor, Enola K and Carpenter, Christopher R and Griffey, Richard T and Bunger, Alicia C and Glass, Joseph E and York, Jennifer L},
doi = {10.1177/1077558711430690},
issn = {1552-6801},
journal = {Medical care research and review: MCRR},
keywords = {Humans Delivery of Health Care Diffusion of Innova},
language = {eng},
number = {2},
pages = {123--157},
title = {{A compilation of strategies for implementing clinical innovations in health and mental health}},
volume = {69},
year = {2012}
}
@book{Prevention2016,
author = {and Prevention, Centers for Disease Control},
title = {{CDC Issue Brief: HIV in the Southern United States.}},
year = {2016}
}
@book{Prevention.2016,
abstract = {Surveillance reports cover the ongoing, systematic collection, analysis, interpretation, and dissemination of data regarding a HIV/AIDS related events.},
author = {and Prevention., Centers for Disease Control},
language = {en-us},
title = {{HIV Surveillance Report, 2015; vol. 27}},
year = {2016}
}
@article{Psioda2018,
abstract = {In this paper, we develop a general Bayesian clinical trial design methodology, tailored for time-to-event trials with a cured fraction in scenarios where a previously completed clinical trial is available to inform the design and analysis of the new trial. Our methodology provides a conceptually appealing and computationally feasible framework that allows one to construct a fixed, maximally informative prior a priori while simultaneously identifying the minimum sample size required for the new trial so that the design has high power and reasonable type I error control from a Bayesian perspective. This strategy is particularly well suited for scenarios where adaptive borrowing approaches are not practical due to the nature of the trial, complexity of the model, or the source of the prior information. Control of a Bayesian type I error rate offers a sensible balance between wanting to use high-quality information in the design and analysis of future trials while still controlling type I errors in an equitable way. Moreover, sample size determination based on our Bayesian view of power can lead to a more adequately sized trial by virtue of taking into account all the uncertainty in the treatment effect. We demonstrate our methodology by designing a cancer clinical trial in high-risk melanoma.},
address = {M.A. Psioda, Department of Biostatistics, University of North Carolina, Chapel Hill, NC, United States},
annote = {L624376056
2018-10-22
2018-10-25},
author = {Psioda, M A and Ibrahim, J G},
doi = {10.1002/sim.7846},
issn = {1097-0258 0277-6715},
journal = {Statistics in Medicine},
keywords = {alpha2b interferon article Bayesian learning cance},
language = {English LB  - Psioda2018a},
number = {26},
pages = {3814--3831},
title = {{Bayesian design of a survival trial with a cured fraction using historical data}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L624376056 http://dx.doi.org/10.1002/sim.7846},
volume = {37},
year = {2018}
}
@article{Psioda2018a,
abstract = {In this paper, we develop the fixed-borrowing adaptive design, a Bayesian adaptive design which facilitates information borrowing from a historical trial using subject-level control data while assuring a reasonable upper bound on the maximum type I error rate and lower bound on the minimum power. First, one constructs an informative power prior from the historical data to be used for design and analysis of the new trial. At an interim analysis opportunity, one evaluates the degree of prior-data conflict. If there is too much conflict between the new trial data and the historical control data, the prior information is discarded and the study proceeds to the final analysis opportunity at which time a noninformative prior is used for analysis. Otherwise, the trial is stopped early and the informative power prior is used for analysis. Simulation studies are used to calibrate the early stopping rule. The proposed design methodology seamlessly accommodates covariates in the statistical model, which the authors argue is necessary to justify borrowing information from historical controls. Implementation of the proposed methodology is straightforward for many common data models, including linear regression models, generalized linear regression models, and proportional hazards models. We demonstrate the methodology to design a cardiovascular outcomes trial for a hypothetical new therapy for treatment of type 2 diabetes mellitus and borrow information from the SAVOR trial, one of the earliest cardiovascular outcomes trials designed to assess cardiovascular risk in antidiabetic therapies.},
address = {M.A. Psioda, Department of Biostatistics, University of North Carolina, Chapel Hill, NC, United States},
annote = {L623262504
2018-08-02
2018-11-08},
author = {Psioda, M A and Soukup, M and Ibrahim, J G},
doi = {10.1002/sim.7897},
issn = {1097-0258 0277-6715},
journal = {Statistics in Medicine},
keywords = {alogliptin hemoglobin A1c placebo saxagliptin sita},
language = {English LB  - Psioda2018b},
number = {27},
pages = {4054--4070},
title = {{A practical Bayesian adaptive design incorporating data from historical controls}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L623262504 http://dx.doi.org/10.1002/sim.7897},
volume = {37},
year = {2018}
}
@article{Psioda2018b,
abstract = {We consider the problem of Bayesian sample size determination for a clinical trial in the presence of historical data that inform the treatment effect. Our broadly applicable, simulation-based methodology provides a framework for calibrating the informativeness of a prior while simultaneously identifying the minimum sample size required for a new trial such that the overall design has appropriate power to detect a non-null treatment effect and reasonable type I error control. We develop a comprehensive strategy for eliciting null and alternative sampling prior distributions which are used to define Bayesian generalizations of the traditional notions of type I error control and power. Bayesian type I error control requires that a weighted-average type I error rate not exceed a prespecified threshold. We develop a procedure for generating an appropriately sized Bayesian hypothesis test using a simple partial-borrowing power prior which summarizes the fraction of information borrowed from the historical trial. We present results from simulation studies that demonstrate that a hypothesis test procedure based on this simple power prior is as efficient as those based on more complicated meta-analytic priors, such as normalized power priors or robust mixture priors, when all are held to precise type I error control requirements. We demonstrate our methodology using a real data set to design a follow-up clinical trial with time-to-event endpoint for an investigational treatment in high-risk melanoma.},
annote = {10.1093/biostatistics/kxy009},
author = {Psioda, Matthew A and Ibrahim, Joseph G},
issn = {1465-4644},
journal = {Biostatistics},
pages = {kxy009--kxy009},
title = {{Bayesian clinical trial design using historical data that inform the treatment effect}},
year = {2018}
}
@article{Psioda2019,
abstract = {In this article, we develop a Bayesian adaptive design methodology for oncology basket trials with binary endpoints using a Bayesian model averaging framework. Most existing methods seek to borrow information based on the degree of homogeneity of estimated response rates across all baskets. In reality, an investigational product may only demonstrate activity for a subset of baskets, and the degree of activity may vary across the subset. A key benefit of our Bayesian model averaging approach is that it explicitly accounts for the possibility that any subset of baskets may have similar activity and that some may not. Our proposed approach performs inference on the basket-specific response rates by averaging over the complete model space for the response rates, which can include thousands of models. We present results that demonstrate that this computationally feasible Bayesian approach performs favorably compared to existing state-of-the-art approaches, even when held to stringent requirements regarding false positive rates.},
author = {Psioda, Matthew A and Xu, Jiawei and Jiang, Qi and Ke, Chunlei and Yang, Zhao and Ibrahim, Joseph G},
doi = {10.1093/biostatistics/kxz014},
issn = {1465-4644},
journal = {Biostatistics},
title = {{Bayesian adaptive basket trial design using model averaging}},
url = {https://doi.org/10.1093/biostatistics/kxz014},
year = {2019}
}
@article{Quan2019,
abstract = {Through the use of an informative prior, Bayesian methodologies could potentially borrow the strength of historical information and become more and more popular for their applications to clinical trials. Nonetheless, even with tremendous effort, the reconciliation of the formulation of the hypotheses and the calculation of type I error between a Bayesian analysis and traditional frequentist analysis is still not very clear. In this research, we apply an inferential prior, null prior and design prior to the Bayesian data analysis, type I error control and sample size calculation. As demonstrated theoretically, the type I error control denies any borrowing of favorable prior information. Thus, the use of the calibrated critical value obtained through simulation for the commensurate or power prior for a Bayesian analysis has the effect of eliminating the borrowing of historical information. The validity of a Bayesian analysis with the borrowing of historical data should rest on the a priori assumption of consistency of data from the historical and current studies. Just in case the consistency assumption is not totally true, dynamic borrowing through the commensurate or power prior can regulate the level of borrowing based on the degree of consistency in the data. An example along with simulations are used to illustrate the applications and compare the characteristics of the methods.},
author = {Quan, Hui and Zhang, Bingzhi and Lan, Yu and Luo, Xiaodong and Chen, Xun},
doi = {10.1016/j.cct.2019.105858},
issn = {15592030},
journal = {Contemporary Clinical Trials},
keywords = {Design posterior,Historical data borrowing,Inferential prior,Interim analysis,Power,Type I error rate},
pages = {105858},
pmid = {31669448},
title = {{Bayesian hypothesis testing with frequentist characteristics in clinical trials}},
url = {http://www.sciencedirect.com/science/article/pii/S1551714419305737},
volume = {87},
year = {2019}
}
@misc{R2017,
abstract = {R Core Team (2018). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL http://www.R-project.org/.},
address = {Vienna, Austria},
author = {{R Core Team}},
booktitle = {R: A language and Environment for Statistical Computing.},
isbn = {3900051070},
pages = {https://www.R--project.org},
publisher = {R Foundation for Statistical Computing},
title = {{A Language and Environment for Statistical Computing}},
type = {Generic},
url = {http://www.r-project.org},
volume = {2},
year = {2017}
}
@article{Raftery1995,
author = {Raftery, Adrian E},
doi = {10.2307/271063},
issn = {00811750},
journal = {Sociological Methodology},
pages = {111},
title = {{Bayesian Model Selection in Social Research}},
volume = {25},
year = {1995}
}
@article{Rasmussen2019,
abstract = {Summary Sample size reestimation in a crossover, bioequivalence study can be a useful adaptive design tool, particularly when the intrasubject variability of the drug formulation under investigation is not well understood. When sample size reestimation is done based on an interim estimate of the intrasubject variability and bioequivalence is tested using the pooled estimate of intrasubject variability, type 1 error inflation will occur. Type 1 error inflation is caused by the pooled estimate being a biased estimator of the intrasubject variability. The type 1 error inflation and bias of the pooled estimator of variability are well characterized in the setting of a two-arm, parallel study. The purpose of this work is to extend this characterization to the setting of a crossover, bioequivalence study with sample size reestimation and to propose an estimator of the intrasubject variability that will prevent type 1 error inflation.},
author = {Rasmussen, Hans E and Ma, Rick and Wang, Jessie J},
doi = {10.1002/pst.1911},
journal = {Pharmaceutical Statistics},
number = {1},
pages = {96--105},
title = {{Controlling type 1 error rate for sequential, bioequivalence studies with crossover designs}},
volume = {18},
year = {2019}
}
@article{Rietbergen2011,
abstract = {Historical studies provide a valuable source of information for the motivation and design of later trials. Bayesian techniques offer possibilities for the quantitative inclusion of prior knowledge within the analysis of current trial data. Combining information from previous studies into an informative prior distribution is, however, a delicate case. The power prior distribution is a tool to estimate the effect of an intervention in a current study sample, while accounting for the information provided by previous research. In this study we evaluate the use of the power prior distribution, illustrated with data from a large randomized clinical trial on the effect of ST-wave analysis in intrapartum fetal monitoring. We advocate the use of a power prior distribution with pre-specified fixed study weights based on differences in study characteristics. We propose obtaining a ranking of the historical studies via expert elicitation, based on relevance for the current study, and specify study weights accordingly. {\textcopyright} 2011 Elsevier Inc.},
address = {C. Rietbergen, Heidelberglaan 1, 3584 CS Utrecht, Netherlands},
annote = {L51533430
2011-07-28
2011-10-14},
author = {Rietbergen, C and Klugkist, I and Janssen, K J M and Moons, K G M and Hoijtink, H J A},
doi = {10.1016/j.cct.2011.06.002},
issn = {1551-7144 1559-2030},
journal = {Contemporary Clinical Trials},
keywords = {article Bayes theorem data analysis fetus monitori},
language = {English LB  - Rietbergen2011},
number = {6},
pages = {848--855},
title = {{Incorporation of historical data in the analysis of randomized therapeutic trials}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L51533430 http://dx.doi.org/10.1016/j.cct.2011.06.002},
volume = {32},
year = {2011}
}
@article{Rittmeyer2017,
abstract = {BACKGROUND: Atezolizumab is a humanised antiprogrammed death-ligand 1 (PD-L1) monoclonal antibody that inhibits PD-L1 and programmed death-1 (PD-1) and PD-L1 and B7-1 interactions, reinvigorating anticancer immunity. We assessed its efficacy and safety versus docetaxel in previously treated patients with non-small-cell lung cancer. METHODS: We did a randomised, open-label, phase 3 trial (OAK) in 194 academic or community oncology centres in 31 countries. We enrolled patients who had squamous or non-squamous non-small-cell lung cancer, were 18 years or older, had measurable disease per Response Evaluation Criteria in Solid Tumors, and had an Eastern Cooperative Oncology Group performance status of 0 or 1. Patients had received one to two previous cytotoxic chemotherapy regimens (one or more platinum based combination therapies) for stage IIIB or IV non-small-cell lung cancer. Patients with a history of autoimmune disease and those who had received previous treatments with docetaxel, CD137 agonists, anti-CTLA4, or therapies targeting the PD-L1 and PD-1 pathway were excluded. Patients were randomly assigned (1:1) to intravenously receive either atezolizumab 1200 mg or docetaxel 75 mg/m(2) every 3 weeks by permuted block randomisation (block size of eight) via an interactive voice or web response system. Coprimary endpoints were overall survival in the intention-to-treat (ITT) and PD-L1-expression population TC1/2/3 or IC1/2/3 (≥1{\%} PD-L1 on tumour cells or tumour-infiltrating immune cells). The primary efficacy analysis was done in the first 850 of 1225 enrolled patients. This study is registered with ClinicalTrials.gov, number NCT02008227. FINDINGS: Between March 11, 2014, and April 29, 2015, 1225 patients were recruited. In the primary population, 425 patients were randomly assigned to receive atezolizumab and 425 patients were assigned to receive docetaxel. Overall survival was significantly longer with atezolizumab in the ITT and PD-L1-expression populations. In the ITT population, overall survival was improved with atezolizumab compared with docetaxel (median overall survival was 13{\textperiodcentered}8 months [95{\%} CI 11{\textperiodcentered}8-15{\textperiodcentered}7] vs 9{\textperiodcentered}6 months [8{\textperiodcentered}6-11{\textperiodcentered}2]; hazard ratio [HR] 0{\textperiodcentered}73 [95{\%} CI 0{\textperiodcentered}62-0{\textperiodcentered}87], p=0{\textperiodcentered}0003). Overall survival in the TC1/2/3 or IC1/2/3 population was improved with atezolizumab (n=241) compared with docetaxel (n=222; median overall survival was 15{\textperiodcentered}7 months [95{\%} CI 12{\textperiodcentered}6-18{\textperiodcentered}0] with atezolizumab vs 10{\textperiodcentered}3 months [8{\textperiodcentered}8-12{\textperiodcentered}0] with docetaxel; HR 0{\textperiodcentered}74 [95{\%} CI 0{\textperiodcentered}58-0{\textperiodcentered}93]; p=0{\textperiodcentered}0102). Patients in the PD-L1 low or undetectable subgroup (TC0 and IC0) also had improved survival with atezolizumab (median overall survival 12{\textperiodcentered}6 months vs 8{\textperiodcentered}9 months; HR 0{\textperiodcentered}75 [95{\%} CI 0{\textperiodcentered}59-0{\textperiodcentered}96]). Overall survival improvement was similar in patients with squamous (HR 0{\textperiodcentered}73 [95{\%} CI 0{\textperiodcentered}54-0{\textperiodcentered}98]; n=112 in the atezolizumab group and n=110 in the docetaxel group) or non-squamous (0{\textperiodcentered}73 [0{\textperiodcentered}60-0{\textperiodcentered}89]; n=313 and n=315) histology. Fewer patients had treatment-related grade 3 or 4 adverse events with atezolizumab (90 [15{\%}] of 609 patients) versus docetaxel (247 [43{\%}] of 578 patients). One treatment-related death from a respiratory tract infection was reported in the docetaxel group. INTERPRETATION: To our knowledge, OAK is the first randomised phase 3 study to report results of a PD-L1-targeted therapy, with atezolizumab treatment resulting in a clinically relevant improvement of overall survival versus docetaxel in previously treated non-small-cell lung cancer, regardless of PD-L1 expression or histology, with a favourable safety profile. FUNDING: F. Hoffmann-La Roche Ltd, Genentech, Inc.},
author = {Rittmeyer, Achim and Barlesi, Fabrice and Waterkamp, Daniel and Park, Keunchil and Ciardiello, Fortunato and von Pawel, Joachim and Gadgeel, Shirish M and Hida, Toyoaki and Kowalski, Dariusz M and Dols, Manuel Cobo and Cortinovis, Diego L and Leach, Joseph and Polikoff, Jonathan and Barrios, Carlos and Kabbinavar, Fairooz and Frontera, Osvaldo Ar{\'{e}}n and {De Marinis}, Filippo and Turna, Hande and Lee, Jong-Seok and Ballinger, Marcus and Kowanetz, Marcin and He, Pei and Chen, Daniel S and Sandler, Alan and Gandara, David R and Group, O A K Study},
doi = {10.1016/S0140-6736(16)32517-X},
edition = {2016/12/13},
issn = {1474-547X},
journal = {Lancet (London, England)},
keywords = {Adult,Aged,Aged, 80 and over,Antibodies, Monoclonal, Humanized,Antibodies, Monoclonal/*administration {\&} dosage,Antineoplastic Agents/*administration {\&} dosage,Carcinoma, Non-Small-Cell Lung/*drug therapy/morta,Disease-Free Survival,Docetaxel,Drug Administration Schedule,Female,Humans,Infusions, Intravenous,Kaplan-Meier Estimate,Lung Neoplasms/*drug therapy/mortality,Male,Middle Aged,Taxoids/*administration {\&} dosage,Treatment Outcome},
language = {eng},
month = {jan},
number = {10066},
pages = {255--265},
title = {{Atezolizumab versus docetaxel in patients with previously treated non-small-cell lung cancer (OAK): a phase 3, open-label, multicentre randomised controlled trial}},
url = {https://pubmed.ncbi.nlm.nih.gov/27979383 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6886121/},
volume = {389},
year = {2017}
}
@article{Rogers2019,
abstract = {A key challenge in Structural Health Monitoring (SHM) is the lack of availability of data from a full range of changing operational and damage conditions, with which to train an identification/classification algorithm. This paper presents a framework based on Bayesian non-parametric clustering, in particular Dirichlet Process (DP) mixture models, for performing SHM tasks in a semi-supervised manner, including an online feature extraction method. Previously, methods applied for SHM of structures in operation, such as bridges, have required at least a year's worth of data before any inferences on performance or structural condition can be made. The method introduced here avoids the need for training data to be collected before inference can begin and increases in robustness as more data are added online. The method is demonstrated on two datasets; one from a laboratory test, the other from a full scale test on civil infrastructure. Results show very good classification accuracy and the ability to incorporate information online (e.g. regarding environmental changes).},
author = {Rogers, T J and Worden, K and Fuentes, R and Dervilis, N and Tygesen, U T and Cross, E J},
doi = {https://doi.org/10.1016/j.ymssp.2018.09.013},
issn = {0888-3270},
journal = {Mechanical Systems and Signal Processing},
keywords = {Bayesian methods Clustering Damage detection Semi-},
pages = {100--119},
title = {{A Bayesian non-parametric clustering approach for semi-supervised Structural Health Monitoring}},
volume = {119},
year = {2019}
}
@article{Rover2019,
abstract = {Extrapolation from a source to a target, eg, from adults to children, is a promising approach to utilize external information when data are sparse. In the context of meta-analyses, one is commonly faced with a small number of studies, whereas potentially relevant additional information may also be available. Here, we describe a simple extrapolation strategy using heavy-tailed mixture priors for effect estimation in meta-analysis, which effectively results in a model-averaging technique. The described method is robust in the sense that a potential prior-data conflict, ie, a discrepancy between source and target data, is explicitly anticipated. The aim of this paper is to develop a solution for this particular application to showcase the ease of implementation by providing R code, and to demonstrate the robustness of the general approach in simulations. {\textcopyright} 2018 John Wiley {\&} Sons, Ltd.},
address = {Department of Medical Statistics, University Medical Center G{\"{o}}ttingen, G{\"{o}}ttingen, Germany Novartis Pharma AG, Basel, Switzerland},
annote = {Cited By :1
Export Date: 12 November 2019},
author = {R{\"{o}}ver, C and Wandel, S and Friede, T},
doi = {10.1002/sim.7991},
journal = {Statistics in Medicine},
keywords = {bridging extrapolation informative prior meta-anal},
number = {4},
pages = {674--694},
title = {{Model averaging for robust extrapolation in evidence synthesis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054619452{\&}doi=10.1002{\%}2Fsim.7991{\&}partnerID=40{\&}md5=6c8d66298f954d642ee5b960df8d329a},
volume = {38},
year = {2019}
}
@book{Rubin2008,
author = {Rubin, Donald B},
publisher = {John Wiley $\backslash${\&} Sons, Inc.},
title = {{Multiple Imputation for Nonresponse in Surveys}},
year = {2008}
}
@article{Rutgeerts2005,
author = {Rutgeerts, Paul and Sandborn, William J and Feagan, Brian G and Reinisch, Walter and Olson, Allan and Johanns, Jewel and Travers, Suzanne and Rachmilewitz, Daniel and Hanauer, Stephen B and Lichtenstein, Gary R and de Villiers, Willem J S and Present, Daniel and Sands, Bruce E and Colombel, Jean Fr{\'{e}}d{\'{e}}ric},
doi = {10.1056/NEJMoa050516},
journal = {New England Journal of Medicine},
number = {23},
pages = {2462--2476},
title = {{Infliximab for Induction and Maintenance Therapy for Ulcerative Colitis}},
type = {Journal Article},
volume = {353},
year = {2005}
}
@article{Sachdev2014,
author = {Sachdev, Darpun D and Stojanovski, Kristefer and Liu, Albert Y and Buchbinder, Susan P and Macalino, Grace E},
doi = {10.1093/cid/ciu229},
issn = {1058-4838},
journal = {Clinical Infectious Diseases: An Official Publication of the Infectious Diseases Society of America},
number = {12},
pages = {1786--1787},
title = {{Intentions to Prescribe Preexposure Prophylaxis Are Associated With Self-efficacy and Normative Beliefs}},
volume = {58},
year = {2014}
}
@article{Sales2019,
abstract = {BACKGROUND: Black adolescent and young adult women (AYAW) in the Southern United States are disproportionately affected by HIV. Pre-exposure prophylaxis (PrEP) is an effective, scalable, individual-controlled HIV prevention strategy that is grossly underutilized among women of all ages and requires innovative delivery approaches to optimize its benefit. Anchoring PrEP delivery to health services that AYAW already trust, access routinely, and deem useful for their sexual health may offer an ideal opportunity to reach women at risk for HIV and to enhance their PrEP uptake and adherence. These services include those of family planning (FP) providers in high HIV incidence settings. However, PrEP has not been widely integrated into FP services, including Title X-funded FP clinics that provide safety net sources of care for AYAW. To overcome potential implementation challenges for AYAW, Title X clinics in the Southern United States are uniquely positioned to be focal sites for conceptually informed and thoroughly evaluated PrEP implementation science studies. OBJECTIVE: The aim of this study is to assess inner and outer context factors (barriers and facilitators) that may influence the adoption of PrEP prescription and treatment services in Title X clinics serving AYAW in the Southern United States. METHODS: Phase 1 of Planning4PrEP is an explanatory sequential, mixed methods study consisting of a geographically-targeted Web-based survey of Title X clinic administrators and providers in the Southern United States, followed by key informant interviews among a purposively selected subset of responders to more comprehensively assess inner and outer context factors that may influence adoption and implementation of PrEP in Title X FP clinics in the South. RESULTS: Phase 1 of Planning4PrEP research activities began in October 2017 and are ongoing. To date, survey and key informant interview administration is near completion, with quantitative and qualitative data analysis scheduled to begin soon after data collection completion. CONCLUSIONS: This study seeks to assess inner and outer contextual factors (barriers and facilitators) that may influence the adoption and integration of PrEP prescription and treatment services in Title X clinics serving AYAW in the Southern United States. Data gained from this study will inform a type 1 hybrid effectiveness implementation study, which will evaluate the multilevel factors associated with successful PrEP implementation while evaluating the degree of PrEP uptake, continuation, and adherence among women seen in Title X clinics. INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): DERR1-10.2196/12774.},
annote = {31199344[pmid]
PMC7006615[pmcid]
v8i6e12774[PII]},
author = {Sales, Jessica M and Escoffery, Cam and Hussen, Sophia A and Haddad, Lisa B and Phillips, Ashley and Filipowicz, Teresa and Sanchez, Maria and McCumber, Micah and Rupp, Betty and Kwiatkowski, Evan and Psioda, Matthew A and Sheth, Anandi N},
doi = {10.2196/12774},
issn = {1929-0748},
journal = {JMIR research protocols},
keywords = {HIV implementation science pre-exposure prophylaxi},
language = {eng LB  - Sales2019},
number = {6},
pages = {e12774--e12774},
title = {{Pre-Exposure Prophylaxis Integration into Family Planning Services at Title X Clinics in the Southeastern United States: A Geographically-Targeted Mixed Methods Study (Phase 1 ATN 155)}},
url = {https://pubmed.ncbi.nlm.nih.gov/31199344 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7006615/},
volume = {8},
year = {2019}
}
@article{Sales2019a,
abstract = {Background: Black adolescent and young adult women (AYAW) in the Southern United States are disproportionately affected by HIV. Pre-exposure prophylaxis (PrEP) is an effective, scalable, individual-controlled HIV prevention strategy that is grossly underutilized among women of all ages and requires innovative delivery approaches to optimize its benefit. Anchoring PrEP delivery to health services that AYAW already trust, access routinely, and deem useful for their sexual health may offer an ideal opportunity to reach women at risk for HIV and to enhance their PrEP uptake and adherence. These services include those of family planning (FP) providers in high HIV incidence settings. However, PrEP has not been widely integrated into FP services, including Title X-funded FP clinics that provide safety net sources of care for AYAW. To overcome potential implementation challenges for AYAW, Title X clinics in the Southern United States are uniquely positioned to be focal sites for conceptually informed and thoroughly evaluated PrEP implementation science studies. Objective: The aim of this study is to assess inner and outer context factors (barriers and facilitators) that may influence the adoption of PrEP prescription and treatment services in Title X clinics serving AYAW in the Southern United States. Methods: Phase 1 of Planning4PrEP is an explanatory sequential, mixed methods study consisting of a geographically-targeted Web-based survey of Title X clinic administrators and providers in the Southern United States, followed by key informant interviews among a purposively selected subset of responders to more comprehensively assess inner and outer context factors that may influence adoption and implementation of PrEP in Title X FP clinics in the South. Results: Phase 1 of Planning4PrEP research activities began in October 2017 and are ongoing. To date, survey and key informant interview administration is near completion, with quantitative and qualitative data analysis scheduled to begin soon after data collection completion. Conclusions: This study seeks to assess inner and outer contextual factors (barriers and facilitators) that may influence the adoption and integration of PrEP prescription and treatment services in Title X clinics serving AYAW in the Southern United States. Data gained from this study will inform a type 1 hybrid effectiveness implementation study, which will evaluate the multilevel factors associated with successful PrEP implementation while evaluating the degree of PrEP uptake, continuation, and adherence among women seen in Title X clinics.},
author = {Sales, Jessica M. and Escoffery, Cam and Hussen, Sophia A. and Haddad, Lisa B. and Phillips, Ashley and Filipowicz, Teresa and Sanchez, Maria and McCumber, Micah and Rupp, Betty and Kwiatkowski, Evan and Psioda, Matthew A. and Sheth, Anandi N.},
doi = {10.2196/12774},
issn = {19290748},
journal = {JMIR Research Protocols},
keywords = {HIV,Implementation science,Pre-exposure prophylaxis,Women's health},
title = {{Pre-exposure prophylaxis integration into family planning services at title X clinics in the southeastern United States: A geographically-targeted mixed methods study (Phase 1 ATN 155)}},
year = {2019}
}
@article{Saville2014,
abstract = {BackgroundBayesian predictive probabilities can be used for interim monitoring of clinical trials to estimate the probability of observing a statistically significant treatment effect if the trial were to continue to its predefined maximum sample size.PurposeWe explore settings in which Bayesian predictive probabilities are advantageous for interim monitoring compared to Bayesian posterior probabilities, p-values, conditional power, or group sequential methods.ResultsFor interim analyses that address prediction hypotheses, such as futility monitoring and efficacy monitoring with lagged outcomes, only predictive probabilities properly account for the amount of data remaining to be observed in a clinical trial and have the flexibility to incorporate additional information via auxiliary variables.LimitationsComputational burdens limit the feasibility of predictive probabilities in many clinical trial settings. The specification of prior distributions brings additional challenges for regulatory approval.ConclusionsThe use of Bayesian predictive probabilities enables the choice of logical interim stopping rules that closely align with the clinical decision-making process.},
author = {Saville, Benjamin R and Connor, Jason T and Ayers, Gregory D and Alvarez, JoAnn},
doi = {10.1177/1740774514531352},
number = {4},
pages = {485--493},
title = {{The utility of Bayesian predictive probabilities for interim monitoring of clinical trials}},
url = {https://journals.sagepub.com/doi/abs/10.1177/1740774514531352},
volume = {11},
year = {2014}
}
@article{Schmidli2014,
abstract = {Historical information is always relevant for clinical trial design. Additionally, if incorporated in the analysis of a new trial, historical data allow to reduce the number of subjects. This decreases costs and trial duration, facilitates recruitment, and may be more ethical. Yet, under prior-data conflict, a too optimistic use of historical data may be inappropriate. We address this challenge by deriving a Bayesian meta-analytic-predictive prior from historical data, which is then combined with the new data. This prospective approach is equivalent to a meta-analytic-combined analysis of historical and new data if parameters are exchangeable across trials. The prospective Bayesian version requires a good approximation of the meta-analytic-predictive prior, which is not available analytically. We propose two- or three-component mixtures of standard priors, which allow for good approximations and, for the one-parameter exponential family, straightforward posterior calculations. Moreover, since one of the mixture components is usually vague, mixture priors will often be heavy-tailed and therefore robust. Further robustness and a more rapid reaction to prior-data conflicts can be achieved by adding an extra weakly-informative mixture component. Use of historical prior information is particularly attractive for adaptive trials, as the randomization ratio can then be changed in case of prior-data conflict. Both frequentist operating characteristics and posterior summaries for various data scenarios show that these designs have desirable properties. We illustrate the methodology for a phase II proof-of-concept trial with historical controls from four studies. Robust meta-analytic-predictive priors alleviate prior-data conflicts ' they should encourage better and more frequent use of historical data in clinical trials.},
annote = {L605883464
2015-09-08},
author = {Schmidli, H and Gsteiger, S and Roychoudhury, S and O'Hagan, A and Spiegelhalter, D and Neuenschwander, B},
doi = {10.1111/biom.12242},
issn = {1541-0420},
journal = {Biometrics},
keywords = {algorithm automated pattern recognition Bayes theo},
language = {English LB  - Schmidli2014},
number = {4},
pages = {1023--1032},
title = {{Robust meta-analytic-predictive priors in clinical trials with historical control information}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L605883464 http://dx.doi.org/10.1111/biom.12242},
volume = {70},
year = {2014}
}
@article{Schmidli2019,
abstract = {Randomized controlled trials are the gold standard to investigate efficacy and safety of new treatments. In certain settings, however, randomizing patients to control may be difficult for ethical or feasibility reasons. Borrowing strength using relevant individual patient data on control from external trials or real-world data (RWD) sources may then allow us to reduce, or even eliminate, the concurrent control group. Naive direct use of external control data is not valid due to differences in patient characteristics and other confounding factors. Instead, we suggest the rigorous application of meta-analytic and propensity score methods to use external controls in a principled way. We illustrate these methods with two case studies: (i) a single-arm trial in a rare cancer disease, using propensity score matching to construct an external control from RWD; (ii) a randomized trial in children with multiple sclerosis, borrowing strength from past trials using a Bayesian meta-analytic approach.},
author = {Schmidli, Heinz and H{\"{a}}ring, Dieter A and Thomas, Marius and Cassidy, Adrian and Weber, Sebastian and Bretz, Frank},
doi = {10.1002/cpt.1723},
issn = {0009-9236},
journal = {Clinical Pharmacology and Therapeutics},
number = {n/a LB  - Schmidli2019},
title = {{Beyond Randomized Clinical Trials: Use of External Controls}},
url = {https://ascpt.onlinelibrary.wiley.com/doi/abs/10.1002/cpt.1723},
volume = {n/a},
year = {2019}
}
@article{Schoenfeld1983,
abstract = {A formula is derived for determining the number of observations necessary to test the equality of two survival distributions when concomitant information is incorporated. This formula should be useful in designing clinical trials with a heterogeneous patient population. Schoenfeld (1981, Biometrika 68, 316-319) derived the asymptotic power of a class of statistics used to test the equality of two survival distributions. That result is extended to the case where concomitant information is available for each individual and where the proportional-hazards model holds. The loss of efficiency caused by ignoring concomitant variables is also computed.},
annote = {Schoenfeld, D A},
author = {Schoenfeld, D A},
edition = {1983/06/01},
issn = {0006-341X (Print) 0006-341x},
journal = {Biometrics},
keywords = {Clinical Trials as Topic *Epidemiologic Methods Hu},
language = {eng LB  - Schoenfeld1983},
number = {2},
pages = {499--503},
title = {{Sample-size formula for the proportional-hazards regression model}},
volume = {39},
year = {1983}
}
@article{Schuirmann1987,
abstract = {The statistical test of the hypothesis of no difference between the average bioavailabilities of two drug formulations, usually supplemented by an assessment of what the power of the statistical test would have been if the true averages had been inequivalent, continues to be used in the statistical analysis of bioavailability/bioequivalence studies. In the present article, this Power Approach (which in practice usually consists of testing the hypothesis of no difference at level 0.05 and requiring an estimated power of 0.80) is compared to another statistical approach, the Two One-Sided Tests Procedure, which leads to the same conclusion as the approach proposed by Westlake (2) based on the usual (shortest) 1–2$\alpha$ confidence interval for the true average difference. It is found that for the specific choice of $\alpha$=0.05 as the nominal level of the one-sided tests, the two one-sided tests procedure has uniformly superior properties to the power approach in most cases. The only cases where the power approach has superior properties when the true averages are equivalent correspond to cases where the chance of concluding equivalence with the power approach when the true averages are notequivalent exceeds 0.05. With appropriate choice of the nominal level of significance of the one-sided tests, the two one-sided tests procedure always has uniformly superior properties to the power approach. The two one-sided tests procedure is compared to the procedure proposed by Hauck and Anderson (1).},
author = {Schuirmann, Donald J},
doi = {10.1007/BF01068419},
issn = {0090-466X},
journal = {Journal of Pharmacokinetics and Biopharmaceutics},
number = {6},
pages = {657--680},
title = {{A comparison of the Two One-Sided Tests Procedure and the Power Approach for assessing the equivalence of average bioavailability}},
volume = {15},
year = {1987}
}
@article{Seidman2016,
abstract = {OBJECTIVES: The Centers for Disease Control and Prevention defines HIV prevention as a core family planning service. The HIV community identified family planning visits as key encounters for women to access preexposure prophylaxis (PrEP) for HIV prevention. No studies explore US family planning providers' knowledge of and attitudes towards PrEP. We conducted a national survey of clinicians to understand barriers and facilitators to PrEP implementation in family planning. STUDY DESIGN: Family planning providers recruited via website postings, national meetings, and email completed an anonymous survey in 2015. Descriptive statistics were performed. RESULTS: Among 604 respondents, 495 were eligible for analysis and 342 were potential PrEP prescribers (physicians, nurse practitioners, midwives or physicians assistants). Among potential prescribers, 38{\%} correctly defined PrEP [95{\%} confidence interval (CI): 32.5-42.8], 37{\%} correctly stated the efficacy of PrEP (95{\%} CI: 32.0-42.4), and 36{\%} chose the correct HIV test after a recent exposure (95{\%} CI: 30.6-40.8). Characteristics of those who answered knowledge questions correctly included age less than 35 years, practicing in the Northeast or West, routinely offering HIV testing, providing rectal sexually transmitted infection screening or having seen any PrEP guidelines. Even among providers in the Northeast and West, the proportion of respondents answering questions correctly was less than 50{\%}. Thirty-six percent of respondents had seen any PrEP guidelines. Providers identified lack of training as the main barrier to PrEP implementation; 87{\%} wanted PrEP education. CONCLUSIONS: To offer comprehensive HIV prevention services, family planning providers urgently need training on PrEP and HIV testing. IMPLICATIONS: US family planning providers have limited knowledge about HIV PrEP and HIV testing, and report lack of provider training as the main barrier to PrEP provision. Provider education is needed to ensure that family planning clients access comprehensive HIV prevention methods.},
author = {Seidman, Dominika and Carlson, Kimberly and Weber, Shannon and Witt, Jacki and Kelly, Patricia J},
doi = {10.1016/j.contraception.2015.12.018},
issn = {1879-0518},
journal = {Contraception},
keywords = {Humans Female Adult Attitudes Family planning Fami},
language = {eng},
number = {5},
pages = {463--469},
title = {{United States family planning providers' knowledge of and attitudes towards preexposure prophylaxis for HIV prevention: a national survey}},
volume = {93},
year = {2016}
}
@article{Simon2017,
abstract = {The successful development of new drugs with a companion diagnostic based on genomic alteration of an oncogene has led to rethinking of all phases on clinical development of cancer drugs. We critically review some of the new clinical trial designs for biomarker?based cancer drug development. We try to clarify the objectives of the new designs and examine completed trials using these designs to evaluate what has been learned about these designs.},
annote = {doi: 10.1002/cpt.814},
author = {Simon, Richard},
doi = {10.1002/cpt.814},
issn = {0009-9236},
journal = {Clinical Pharmacology {\&} Therapeutics},
number = {6},
pages = {934--941},
title = {{Critical Review of Umbrella, Basket, and Platform Designs for Oncology Clinical Trials}},
volume = {102},
year = {2017}
}
@article{Sjoberg2019,
abstract = {Rapid changes in the natural and social environments of the Arctic region have led to increased scientific presence across the Arctic. Simultaneously, the importance of involving local Indigenous peoples in research activities is increasingly recognized for several reasons, including knowledge sharing and sustainable development. This study explores Arctic early career researchers' (ECRs) perceptions on involving local Indigenous peoples in their research. The results, based on 108 online survey respondents from 22 countries, show that ECRs value the knowledge of local Indigenous peoples and generally wish to extend the involvement of this group in their research. ECRs in North America and in the social sciences have more experience working with Indigenous communities and value it more than researchers in the Nordic area and in the natural sciences. Respondents cited more funding, networking opportunities, and time as the main needs for increasing collaborations. The results of this study are helpful for developing strategies to build good relationships between scientists and Indigenous peoples and for increasing the involvement of Arctic Indigenous peoples in science and engagement of their knowledge systems. The complementary views from Arctic Indigenous peoples are, however, needed for a full understanding of how to effectively achieve this.},
author = {Sj{\"{o}}berg, Ylva and Gomach, Sarah and Kwiatkowski, Evan and Mansoz, Mathilde},
doi = {10.1139/as-2017-0045},
issn = {23687460},
journal = {Arctic Science},
keywords = {Arctic,Early career researchers,Indigenous peoples},
title = {{Involvement of local indigenous peoples in arctic research — expectations, needs and challenges perceived by early career researchers}},
year = {2019}
}
@article{Sofen2014a,
author = {Sofen, Howard and Smith, Stacy and Matheson, Robert T and Leonardi, Craig L and Calderon, Cesar and Brodmerkel, Carrie and Li, Katherine and Campbell, Kim and Marciniak, Stanley J and Wasfi, Yasmine and Wang, Yuhua and Szapary, Philippe and Krueger, James G},
doi = {https://doi.org/10.1016/j.jaci.2014.01.025},
issn = {0091-6749},
journal = {Journal of Allergy and Clinical Immunology},
keywords = {gene expression guselkumab Histology IL-23 psorias},
number = {4},
pages = {1032--1040},
title = {{Guselkumab (an IL-23–specific mAb) demonstrates clinical and molecular response in patients with moderate-to-severe psoriasis}},
volume = {133},
year = {2014}
}
@article{Sofen2014,
author = {Sofen, Howard and Smith, Stacy and Matheson, Robert T and Leonardi, Craig L and Calderon, Cesar and Brodmerkel, Carrie and Li, Katherine and Campbell, Kim and Marciniak, Stanley J and Wasfi, Yasmine and Wang, Yuhua and Szapary, Philippe and Krueger, James G},
doi = {https://doi.org/10.1016/j.jaci.2014.01.025},
issn = {0091-6749},
journal = {Journal of Allergy and Clinical Immunology},
keywords = {Histology,IL-23,Psoriasis Area and Severity Index,},
number = {4},
pages = {1032--1040},
title = {{Guselkumab (an IL-23–specific mAb) demonstrates clinical and molecular response in patients with moderate-to-severe psoriasis}},
url = {http://www.sciencedirect.com/science/article/pii/S009167491400181X},
volume = {133},
year = {2014}
}
@article{Spiegelhalter1993,
author = {Spiegelhalter, David J. and Freedman, Laurence S. and Parmar, Mahesh K. B.},
doi = {10.1002/sim.4780121516},
file = {:Users/kwiatkoe/Library/Application Support/Mendeley Desktop/Downloaded/Spiegelhalter, Freedman, Parmar - 1993 - Applying Bayesian ideas in drug development and clinical trials.pdf:pdf},
issn = {02776715},
journal = {Statistics in Medicine},
month = {aug},
number = {15-16},
pages = {1501--1511},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Applying Bayesian ideas in drug development and clinical trials}},
url = {http://doi.wiley.com/10.1002/sim.4780121516},
volume = {12},
year = {1993}
}
@article{Stallard2020,
abstract = {There is a growing interest in the use of Bayesian adaptive designs in late-phase clinical trials. This includes the use of stopping rules based on Bayesian analyses in which the frequentist type I error rate is controlled as in frequentist group-sequential designs.},
author = {Stallard, Nigel and Todd, Susan and Ryan, Elizabeth G and Gates, Simon},
doi = {10.1186/s12874-019-0892-8},
issn = {1471-2288},
journal = {BMC Medical Research Methodology},
number = {1},
pages = {4},
title = {{Comparison of Bayesian and frequentist group-sequential clinical trial designs}},
type = {Journal Article},
url = {https://doi.org/10.1186/s12874-019-0892-8},
volume = {20},
year = {2020}
}
@article{Striley2019,
abstract = {Introduction: Research progress on neurocognitive disorders requires donation of both healthy and diseased brains. Here, we describe attitudes toward brain donation among a large community sample in Florida. Methods: HealthStreet, a community engagement program at the University of Florida, used community health workers to assess community attitudes toward research participation, including brain donation. Results: Over 60{\%} of people, primarily Caucasian and employed, indicated that they would be likely or somewhat likely to donate their brain for research. Those who would be willing to donate were also more likely to be willing to participate in other research studies and to have participated in research. Discussion: Brain donation will add to the science of disorders of aging, including accurate diagnoses and validation of in vivo biomarkers. Increasing willingness to donate is a first step toward donation. Community populations are willing; community health workers can educate others about the need for this initiative in communities.},
author = {Striley, Catherine W. and Milani, Sadaf A. and Kwiatkowski, Evan and DeKosky, Steven T. and Cottler, Linda B.},
doi = {10.1016/j.jalz.2018.09.005},
issn = {15525279},
journal = {Alzheimer's and Dementia},
keywords = {Alzheimer's,Brain donation,Community health worker,Dementia,Epidemiology,Public health,Research perceptions},
pmid = {30365929},
title = {{Community perceptions related to brain donation: Evidence for intervention}},
year = {2019}
}
@article{Striley2017,
author = {Striley, Catherine Woodstock and Kwiatkowski, Evan and Cottler, Linda},
doi = {10.1016/j.drugalcdep.2016.08.544},
issn = {03768716},
journal = {Drug and Alcohol Dependence},
title = {{Efforts to diversity research populations can pay dividends}},
year = {2017}
}
@article{Sun2014,
author = {Sun, Anna and Dong, Xiaoyu and Tsong, Yi},
doi = {10.1080/10543406.2014.941986},
journal = {Journal of Biopharmaceutical Statistics},
number = {6},
pages = {1203--1214},
title = {{Sample Size Determination for Equivalence Assessment with Multiple Endpoints}},
volume = {24},
year = {2014}
}
@article{Takeda2018,
abstract = {We consider the problem of incorporating historical data from a preceding trial to design and conduct a subsequent dose-finding trial in a possibly different population of patients. In oncology, for example, after a phase I dose-finding trial is completed in Caucasian patients, investigators often conduct a further phase I trial to determine the maximum tolerated dose in Asian patients. This may be due to concerns about possible differences in treatment tolerability between populations. In this study, we propose to adaptively incorporate historical data into prior distributions assumed in a new dose-finding trial. Our proposed approach aims to appropriately borrow strength from a previous trial to improve the maximum tolerated dose determination in another patient population. We define a “historical-to-current (H-C)” parameter representing the degree of borrowing based on a retrospective analysis of previous trial data. In simulation studies, we examine the operating characteristics of the proposed method in comparison with 3 alternative approaches and assess how the H-C parameter functions across a variety of realistic settings.},
address = {K. Takeda, Data Science, Astellas Pharma Global Development, Inc., United States},
annote = {L620383428
2018-02-01},
author = {Takeda, K and Morita, S},
doi = {10.1002/pst.1850},
issn = {1539-1612 1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {adult article Asian Caucasian controlled study dos},
language = {English LB  - Takeda2018},
number = {4},
pages = {372--382},
title = {{Bayesian dose-finding phase I trial design incorporating historical data from a preceding trial}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L620383428 http://dx.doi.org/10.1002/pst.1850},
volume = {17},
year = {2018}
}
@article{Takeda2015,
abstract = {Following phase I dose-finding oncology trials completed in Western countries, Asian investigators often conduct further phase I trials to determine the maximum tolerated dose for Asian patients. This may be due to concerns about possible differences in treatment tolerability between Caucasian and Asian patient groups. Our proposed approach aims to appropriately borrow strength from a previous Caucasian trial to improve the maximum tolerated dose determination in an Asian population of patients. We design an Asian phase I trial using the Bayesian continual reassessment method. First we analyze toxicity data from a Caucasian trial to derive the prior distributions for a subsequent Asian trial. Then, we calibrate the informativeness of the prior distributions according to prior effective sample size defined by Morita et al. Extensive simulation studies demonstrate favourable operating characteristics of the proposed method, compared with two methods based on power and noninformative priors, respectively.},
address = {K. Takeda, Biostatistics Group, Data Science, Global Development, Astellas Pharma Inc, 2-5-1, Nihonbashi-Honcho, Chuo-ku, Tokyo, Japan},
annote = {L601416135
2015-01-22
2015-01-27},
author = {Takeda, K and Morita, S},
doi = {10.1177/2168479014546333},
issn = {2168-4804 2168-4790},
journal = {Therapeutic Innovation and Regulatory Science},
keywords = {antineoplastic agent article Asian Bayesian method},
language = {English LB  - Takeda2015},
number = {1},
pages = {93--99},
title = {{Incorporating Historical Data in Bayesian Phase I Trial Design: The Caucasian-to-Asian Toxicity Tolerability Problem}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L601416135 http://dx.doi.org/10.1177/2168479014546333},
volume = {49},
year = {2015}
}
@article{Tamura1986,
abstract = {Empirical Bayes procedures for incorporating historical control information in bioassay carcinogenesis studies are receiving attention in the literature. In general, the empirical Bayes methods fail to take into account the error in estimating the parameters of a prior distribution. The implications of this are studied for the beta prior of Tarone (1982, Biometrics 38, 215-220). Using simulations, we show that the skewness in the maximum likelihood estimators for the parameters of the beta prior increases the false positive rate in the test of dose-related trend.},
annote = {Tamura, R N
Young, S S
Journal Article
United States
Biometrics. 1986 Jun;42(2):343-9.},
author = {Tamura, R N and Young, S S},
edition = {1986/06/01},
issn = {0006-341X (Print) 0006-341x},
journal = {Biometrics},
keywords = {Animals Biometry *Carcinogens Drug Evaluation/*met},
language = {eng LB  - Tamura1986},
number = {2},
pages = {343--349},
title = {{The incorporation of historical control information in tests of proportions: simulation study of Tarone's procedure}},
volume = {42},
year = {1986}
}
@book{Team2016,
author = {Team, CFIR Research},
title = {{Consolidated Framework for Implementation Research (CFIR) Technical Assistance Website}},
year = {2016}
}
@article{Tibshirani2005,
author = {Tibshirani, Robert and Walther, Guenther},
doi = {10.1198/106186005X59243},
journal = {Journal of Computational and Graphical Statistics},
number = {3},
pages = {511--528},
title = {{Cluster Validation by Prediction Strength}},
volume = {14},
year = {2005}
}
@article{Tibshirani2001,
author = {Tibshirani, Robert and Walther, Guenther and Hastie, Trevor},
doi = {10.1111/1467-9868.00293},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {Clustering Groups Hierarchy Uniform distribution},
number = {2},
pages = {411--423},
title = {{Estimating the number of clusters in a data set via the gap statistic}},
volume = {63},
year = {2001}
}
@article{Tramer1998,
author = {Tram{\`{e}}r, Martin R and Reynolds, D John M and Moore, R Andrew and McQuay, Henry J},
doi = {10.1136/bmj.317.7162.875},
issn = {0959-8138},
journal = {BMJ},
number = {7162},
pages = {875--880},
title = {{When placebo controlled trials are essential and equivalence trials are inadequate}},
volume = {317},
year = {1998}
}
@article{USCongress2016,
author = {{U.S. Congress}},
title = {{21st Century Cures Act (Pubic Law 114-255, 130 STAT 1033-1344)}},
type = {Journal Article},
year = {2016}
}
@article{FDA_CID,
author = {{U.S. Food and Drug Administration}},
title = {{Interacting with the FDA on Complex Innovative Trial Designs for Drugs and Biological Products}},
type = {Journal Article},
year = {2019}
}
@article{FDA2006,
author = {{U.S. Food and Drug Administration}},
title = {{Establishment and Operation of Clinical Trial Data Monitoring Committees}},
year = {2006}
}
@article{FDA2017,
author = {{U.S. Food and Drug Administration}},
title = {{PDUFA Reauthorization Performance Goals and Procedures Fiscal Years 2018 through 2022}},
type = {Journal Article},
year = {2017}
}
@article{FDA2018,
annote = {[Online; last accessed 21-February-2018]},
author = {{U.S. Food and Drug Administration}},
title = {{Guidance for the Use of Bayesian Statistics in Medical Device Clinical Trials}},
year = {2018}
}
@article{Vaddiparti2017,
author = {Vaddiparti, Krishna and Striley, Catherine Woodstock and Kwiatkowski, Evan and Cottler, Linda},
doi = {10.1016/j.drugalcdep.2016.08.562},
issn = {03768716},
journal = {Drug and Alcohol Dependence},
title = {{Monetary payment for research participation: What do marijuana users think?}},
year = {2017}
}
@article{VanBuuren2007,
abstract = {The goal of multiple imputation is to provide valid inferences for statistical estimates from incomplete data. To achieve that goal, imputed values should preserve the structure in the data, as well as the uncertainty about this structure, and include any knowledge about the process that generated the missing data. Two approaches for imputing multivariate data exist: joint modeling (JM) and fully conditional specification (FCS). JM is based on parametric statistical theory, and leads to imputation procedures whose statistical properties are known. JM is theoretically sound, but the joint model may lack flexibility needed to represent typical data features, potentially leading to bias. FCS is a semi-parametric and flexible alternative that specifies the multivariate model by a series of conditional models, one for each incomplete variable. FCS provides tremendous flexibility and is easy to apply, but its statistical properties are difficult to establish. Simulation work shows that FCS behaves very well in the cases studied. The present paper reviews and compares the approaches. JM and FCS were applied to pubertal development data of 3801 Dutch girls that had missing data on menarche (two categories), breast development (five categories) and pubic hair development (six stages). Imputations for these data were created under two models: a multivariate normal model with rounding and a conditionally specified discrete model. The JM approach introduced biases in the reference curves, whereas FCS did not. The paper concludes that FCS is a useful and easily applied flexible alternative to JM when no convenient and realistic joint distribution can be specified.},
author = {van Buuren, Stef},
doi = {10.1177/0962280206074463},
issn = {0962-2802},
journal = {Statistical Methods in Medical Research},
keywords = {Humans Data Interpretation Statistical Bias Female},
language = {eng LB  - vanBuuren2007},
number = {3},
pages = {219--242},
title = {{Multiple imputation of discrete and continuous data by fully conditional specification}},
volume = {16},
year = {2007}
}
@article{VanRosmalen2018,
abstract = {Data of previous trials with a similar setting are often available in the analysis of clinical trials. Several Bayesian methods have been proposed for including historical data as prior information in the analysis of the current trial, such as the (modified) power prior, the (robust) meta-analytic-predictive prior, the commensurate prior and methods proposed by Pocock and Murray et al. We compared these methods and illustrated their use in a practical setting, including an assessment of the comparability of the current and the historical data. The motivating data set consists of randomised controlled trials for acute myeloid leukaemia. A simulation study was used to compare the methods in terms of bias, precision, power and type I error rate. Methods that estimate parameters for the between-trial heterogeneity generally offer the best trade-off of power, precision and type I error, with the meta-analytic-predictive prior being the most promising method. The results show that it can be feasible to include historical data in the analysis of clinical trials, if an appropriate method is used to estimate the heterogeneity between trials, and the historical data satisfy criteria for comparability.},
address = {J. van Rosmalen, Department of Biostatistics, Erasmus University Medical Center, Wytemaweg 80, Rotterdam, Netherlands},
annote = {L621252993
2018-03-20
2018-10-02},
author = {van Rosmalen, J and Dejardin, D and van Norden, Y and L{\"{o}}wenberg, B and Lesaffre, E},
doi = {10.1177/0962280217694506},
issn = {1477-0334 0962-2802},
journal = {Statistical Methods in Medical Research},
keywords = {anthracycline antineoplastic agent granulocyte col},
language = {English LB  - vanRosmalen2018},
number = {10},
pages = {3167--3182},
title = {{Including historical data in the analysis of clinical trials: Is it worth the effort?}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L621252993 http://dx.doi.org/10.1177/0962280217694506},
volume = {27},
year = {2018}
}
@article{Varma2016,
abstract = {BACKGROUND Mobile phoned-based interventions have been increasingly used in clinical populations to improve health and health care delivery. The literature has shown that mobile phone-based text messages (short message service, SMS) are instantaneous, cost effective, and have less chance of being misplaced. Studies using mobile phone based-text messages have reported text messages as effective reminders that have resulted in increased appointment attendance, adherence to treatment, and better self-management. There have been no reports of adverse events when using text messaging in terms of misreading or misinterpreting data, transmitting inaccurate data, losing verbal or nonverbal communication cues, privacy issues, or failure or delay in message delivery. However, the literature has cited a need for personalized messages that are more responsive to individual needs. In addition, there has been a dearth of information on the use of reminders in nonclinical populations. OBJECTIVE The goal of this study is to assess the effectiveness of adding reminders in the form of text messaging versus reminder calls versus text messages and reminder calls to increase use of service referrals provided through community outreach. METHODS A total of 300 participants will be recruited for the study. Each participant will be randomized to one of three arms: a group that receives only reminder calls (CALLSONLY); a group that receives only text message reminders (TEXTONLY); and a group that receives both reminder calls and text messages (CALLS+TEXT). All groups will receive their reminder intervention on the 15th and 45th day after baseline when they receive medical and social service referrals from the community health workers (CHWs). A standard script will be used to administer the call and text reminders and a 15-item telephone-based satisfaction survey will be administered to assess the participant satisfaction with the process of receiving periodic reminders. RESULTS The study is in the recruitment and follow-up phase. The authors anticipate completion of recruitment, interventions, and data entry by July 2016. Preliminary results are expected to be available by September 2016. CONCLUSIONS This study will provide an opportunity to test the effectiveness of mobile-based interventions on nonclinical, community-recruited populations. In particular, such a protocol would increase the effectiveness of a community-based engagement program by instating a formal reminder system for all program members who receive social and/or medical service referrals during outreach in the community. Findings from this study would guide the development and implementation of reminder protocols for community-based engagement programs nationwide.},
author = {Varma, Deepthi Satheesa and Hart, Mark and McIntyre, Denise Sonya and Kwiatkowski, Evan and Cottler, Linda Bauer},
doi = {10.2196/resprot.5854},
issn = {1929-0748},
journal = {JMIR Research Protocols},
title = {{A Research Protocol to Test the Effectiveness of Text Messaging and Reminder Calls to Increase Service Use Referrals in a Community Engagement Program}},
year = {2016}
}
@article{Ventz2019,
abstract = {Purpose: We discuss designs and interpretable metrics of bias and statistical efficiency of “externally controlled” trials (ECT) and compare ECT performance to randomized and single-arm designs.Experimental Design: We specify an ECT design that leverages information from real-world data (RWD) and prior clinical trials to reduce bias associated with interstudy variations of the enrolled populations. We then used a collection of clinical studies in glioblastoma (GBM) and RWD from patients treated with the current standard of care to evaluate ECTs. Validation is based on a “leave one out” scheme, with iterative selection of a single-arm from one of the studies, for which we estimate treatment effects using the remaining studies as external control. This produces interpretable and robust estimates on ECT bias and type I errors.Results: We developed a model-free approach to evaluate ECTs based on collections of clinical trials and RWD. For GBM, we verified that inflated false positive error rates of standard single-arm trials can be considerably reduced (up to 30{\%}) by using external control data.Conclusions: The use of ECT designs in GBM, with adjustments for the clinical profiles of the enrolled patients, should be preferred to single-arm studies with fixed efficacy thresholds extracted from published results on the current standard of care.},
author = {Ventz, Steffen and Lai, Albert and Cloughesy, Timothy F and Wen, Patrick Y and Trippa, Lorenzo and Alexander, Brian M},
doi = {10.1158/1078-0432.CCR-19-0820 %J Clinical Cancer Research},
journal = {Clinical Cancer Research},
number = {16 LB  - Ventz2019},
pages = {4993--5001},
title = {{Design and Evaluation of an External Control Arm Using Prior Clinical Trials and Real-World Data}},
url = {https://clincancerres.aacrjournals.org/content/clincanres/25/16/4993.full.pdf},
volume = {25},
year = {2019}
}
@article{Ventz2015,
abstract = {Summary Frequentist concepts, such as the control of the type I error or the false discovery rate, are well established in the medical literature and often required by regulators. Most Bayesian designs are defined without explicit considerations of frequentist characteristics. Once the Bayesian design is structured, statisticians use simulations and adjust tuning parameters to comply with a set of targeted operating characteristics. These adjustments affect the use of prior information and utility functions. Here we consider a Bayesian decision theoretic approach for experimental designs with explicit frequentist requisites. We define optimal designs under a set of constraints required by a regulator. Our approach combines the use of interpretable utility functions with frequentist criteria, and selects an optimal design that satisfies a set of required operating characteristics. We illustrate the approach using a group-sequential multi-arm Phase II trial and a bridging trial.},
author = {Ventz, Steffen and Trippa, Lorenzo},
doi = {10.1111/biom.12226},
issn = {0006-341X},
journal = {Biometrics},
keywords = {Bayesian design Clinical trials Decision theory Fr},
number = {1},
pages = {218--226},
title = {{Bayesian designs and the control of frequentist characteristics: A practical solution}},
type = {Journal Article},
url = {https://doi.org/10.1111/biom.12226},
volume = {71},
year = {2015}
}
@article{Viele2014,
annote = {Cited By :92
Export Date: 1 November 2019},
author = {Viele, K and Berry, S and Neuenschwander, B and Amzal, B and Chen, F and Enas, N and Hobbs, B and Ibrahim, J G and Kinnersley, N and Lindborg, S and Micallef, S and Roychoudhury, S and Thompson, L},
doi = {10.1002/pst.1589},
journal = {Pharmaceutical statistics},
number = {1 LB  - Viele2014},
pages = {41--54},
title = {{Use of historical control data for assessing treatment effects in clinical trials}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907953363{\&}doi=10.1002{\%}2Fpst.1589{\&}partnerID=40{\&}md5=5543c88d67003c47f06e587311dcf017},
volume = {13},
year = {2014}
}
@article{Viele2018,
abstract = {New antimicrobial drugs for treatment of complicated urinary tract infection (cUTI) are generally assessed in randomized, double-blind, noninferiority clinical trials. Robust historical data for the active comparator inform on treatment effect estimation, yet typically do not substitute for the active comparator data in the proposed trial. We report design options for a phase 3 trial of cUTI using a Bayesian hierarchical model and historical data from 2 well-executed phase 3 registrational trials of doripenem. The methodology is directly applicable to other phase 3 noninferiority settings. In addition to the research design application, we provide a novel methodology for assessing the robustness of type I error control. The model borrows heavily from the prior data when the current active comparator parameter estimate approximated the historical estimate. In contrast, the model had restricted borrowing when the 2 estimates were very different. The alternative trial design, with or without the inclusion of futility stopping criteria, provides a framework for future cUTI phase 3 trials.},
address = {J.D. Wetherington, GlaxoSmithKline, Collegeville, PA, United States},
annote = {L623883052
2018-09-19
2019-04-05},
author = {Viele, K and Mundy, L M and Noble, R B and Li, G and Broglio, K and Wetherington, J D},
doi = {10.1002/pst.1892},
issn = {1539-1612 1539-1604},
journal = {Pharmaceutical Statistics},
keywords = {doripenem analytical error article Bayes theorem c},
language = {English LB  - Viele2018},
number = {6},
pages = {811--822},
title = {{Phase 3 adaptive trial design options in treatment of complicated urinary tract infection}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L623883052 http://dx.doi.org/10.1002/pst.1892},
volume = {17},
year = {2018}
}
@article{Wadsworth2018,
abstract = {Objective: When developing new medicines for children, the potential to extrapolate from adult data to reduce the experimental burden in children is well recognised. However, significant assumptions about the similarity of adults and children are needed for extrapolations to be biologically plausible. We reviewed the literature to identify statistical methods that could be used to optimise extrapolations in paediatric drug development programmes. Methods: Web of Science was used to identify papers proposing methods relevant for using data from a ‘source population' to support inferences for a ‘target population'. Four key areas of methods development were targeted: paediatric clinical trials, trials extrapolating efficacy across ethnic groups or geographic regions, the use of historical data in contemporary clinical trials and using short-term endpoints to support inferences about long-term outcomes. Results: Searches identified 626 papers of which 52 met our inclusion criteria. From these we identified 102 methods comprising 58 Bayesian and 44 frequentist approaches. Most Bayesian methods (n = 54) sought to use existing data in the source population to create an informative prior distribution for a future clinical trial. Of these, 46 allowed the source data to be down-weighted to account for potential differences between populations. Bayesian and frequentist versions of methods were found for assessing whether key parameters of source and target populations are commensurate (n = 34). Fourteen frequentist methods synthesised data from different populations using a joint model or a weighted test statistic. Conclusions: Several methods were identified as potentially applicable to paediatric drug development. Methods which can accommodate a heterogeneous target population and which allow data from a source population to be down-weighted are preferred. Methods assessing the commensurability of parameters may be used to determine whether it is appropriate to pool data across age groups to estimate treatment effects.},
address = {I. Wadsworth, Department of Mathematics and Statistics, Fylde College, Lancaster University, Lancaster, United Kingdom},
annote = {L620696991
2018-02-20
2018-02-28},
author = {Wadsworth, I and Hampson, L V and Jaki, T},
doi = {10.1177/0962280216631359},
issn = {1477-0334 0962-2802},
journal = {Statistical Methods in Medical Research},
keywords = {article Bayes theorem child child care clinical st},
language = {English LB  - Wadsworth2018},
number = {2},
pages = {398--413},
title = {{Extrapolation of efficacy and other data to support the development of new medicines for children: A systematic review of methods}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L620696991 http://dx.doi.org/10.1177/0962280216631359},
volume = {27},
year = {2018}
}
@article{Walker2011,
author = {Walker, Esteban and Nowacki, Amy},
doi = {10.1007/s11606-010-1513-8},
journal = {Journal of general internal medicine},
pages = {192--196},
title = {{Understanding Equivalence and Noninferiority Testing}},
volume = {26},
year = {2011}
}
@article{Walter2017,
abstract = {An imprecise Bayesian nonparametric approach to system reliability with multiple types of components is developed. This allows modelling partial or imperfect prior knowledge on component failure distributions in a flexible way through bounds on the functioning probability. Given component level test data these bounds are propagated to bounds on the posterior predictive distribution for the functioning probability of a new system containing components exchangeable with those used in testing. The method further enables identification of prior–data conflict at the system level based on component level test data. New results on first-order stochastic dominance for the Beta-Binomial distribution make the technique computationally tractable. Our methodological contributions can be immediately used in applications by reliability practitioners as we provide easy to use software tools. {\textcopyright} 2016 The Authors},
address = {School of Industrial Engineering, Eindhoven University of Technology, Eindhoven, Netherlands Department of Statistics, University of Oxford, Oxford, United Kingdom Department of Mathematical Sciences, Durham University, Durham, United Kingdom},
annote = {Cited By :7
Export Date: 12 November 2019},
author = {Walter, G and Aslett, L J M and Coolen, F P A},
doi = {10.1016/j.ijar.2016.08.005},
journal = {International Journal of Approximate Reasoning},
keywords = {Bayesian nonparametrics Imprecise probability Prio},
pages = {67--88},
title = {{Bayesian nonparametric system reliability using sets of priors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044368476{\&}doi=10.1016{\%}2Fj.ijar.2016.08.005{\&}partnerID=40{\&}md5=de89565566720ee13f4e4ae29e746d2e},
volume = {80},
year = {2017}
}
@article{Walter2009,
abstract = {A great advantage of imprecise probability models over models based on precise, traditional probabilities is the potential to reflect the amount of knowledge they stand for. Consequently, imprecise probability models promise to offer a vivid tool for handling situations of prior-data conflict in (generalized) Bayesian inference. In this paper we consider a general class of recently studied imprecise probability models, including the Imprecise Dirichlet Model under prior information, and more generally the framework of Quaeghebeur and de Cooman for imprecise inference in canonical exponential families. We demonstrate that such models, in their originally proposed form, prove to be insensitive to the extent of prior-data conflict. We propose an extension reestablishing the natural relationship between knowledge and imprecision: the higher the discrepancy between the observed sample and what was expected from prior knowledge, the higher the imprecision in the posterior, producing cau24 tious inferences if, and only if, caution is needed. Our approach is illustrated by some examples and simulation results. {\textcopyright} 2009 Taylor {\&} Francis Group, LLC. All rights reserved.},
address = {Department of Statistics, Ludwig-Maximilians-Universit{\"{a}}t (LMU), Ludwigstr. 33, Munich, D80539, Germany},
annote = {Cited By :26
Export Date: 12 November 2019},
author = {Walter, G and Augustin, T},
doi = {10.1080/15598608.2009.10411924},
journal = {Journal of Statistical Theory and Practice},
keywords = {Canonical exponential family Generalized Bayesian },
number = {1},
pages = {255--271},
title = {{Imprecision and prior-data conflict in generalized bayesian inference}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008756961{\&}doi=10.1080{\%}2F15598608.2009.10411924{\&}partnerID=40{\&}md5=91e1c3d08cbfbbfb50f4c36cba082b72},
volume = {3},
year = {2009}
}
@incollection{Walter2010,
abstract = {The paper is concerned with Bayesian analysis under prior-data conflict, i.e. the situation when observed data are rather unexpected under the prior (and the sample size is not large enough to eliminate the influence of the prior). Two approaches for Bayesian linear regression modeling based on conjugate priors are considered in detail, namely the standard approach also described in Fahrmeir et al. (2007) and an alternative adoption of the general construction procedure for exponential family sampling models. We recognize that - in contrast to some standard i.i.d. models like the scaled normal model and the Beta-Binomial / Dirichlet-Multinomial model, where prior-data conflict is completely ignored - the models may show some reaction to prior-data conflict, however in a rather unspecific way. Finally we briefly sketch the extension to a corresponding imprecise probability model, where, by considering sets of prior distributions instead of a single prior, prior-data conflict can be handled in a very appealing and intuitive way. {\textcopyright} 2010 Springer-Verlag Berlin Heidelberg.},
address = {Institut f{\"{u}}r Statistik, Ludwig-Maximilians-Universit{\"{a}}t M{\"{u}}nchen, D-80539 M{\"{u}}nchen, Germany},
annote = {Cited By :2
Export Date: 12 November 2019},
author = {Walter, G and Augustin, T},
booktitle = {Statistical Modelling and Regression Structures: Festschrift in Honour of Ludwig Fahrmeir},
doi = {10.1007/978-3-7908-2413-1_4},
keywords = {conjugate analysis imprecise probability Linear re},
pages = {59--78},
title = {{Bayesian linear regression - Different conjugate models and their (In)sensitivity to prior-data conflict}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892230386{\&}doi=10.1007{\%}2F978-3-7908-2413-1{\_}4{\&}partnerID=40{\&}md5=bc4960cabc1df5c6467dd443d0dc43ea},
year = {2010}
}
@inproceedings{Walter2011,
abstract = {By its capability to deal with the multidimensional nature of uncertainty, imprecise probability provides a powerful methodology to sensibly handle prior-data conflict in Bayesian inference. When there is strong conflict between sample observations and prior knowledge the posterior model should be more imprecise than in the situation of mutual agreement or compatibility. Focusing presentation on the prototypical example of Bernoulli trials, we discuss the ability of different approaches to deal with prior-data conflict. We study a generalized Bayesian setting, including Walley's Imprecise Beta-Binomial model and his extension to handle prior data conflict (called pdc- IBBM here). We investigate alternative shapes of prior parameter sets, chosen in a way that shows improved behaviour in the case of prior-data conflict and their influence on the posterior predictive distribution. Thereafter we present a new approach, consisting of an imprecise weighting of two originally separate inferences, one of which is based on an informative imprecise prior whereas the other one is based on an uninformative imprecise prior. This approach deals with prior-data conflict in a fascinating way.},
address = {Department of Statistics, Ludwig-Maximilians-Universit{\"{a}}t M{\"{u}}nchen (LMU), Germany Department of Mathematics, Durham University, United Kingdom},
annote = {Cited By :6
Export Date: 12 November 2019},
author = {Walter, G and Augustin, T and Coolen, F P A},
booktitle = {ISIPTA 2011 - Proceedings of the 7th International Symposium on Imprecise Probability: Theories and Applications},
keywords = {Bayesian inference Generalized iluckmodels Impreci},
pages = {391--400},
title = {{On prior-data conflict in predictive bernoulli inferences}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873133583{\&}partnerID=40{\&}md5=b636fee44ad40b60a04b10d4698be4aa},
year = {2011}
}
@misc{Walter2016,
abstract = {In Bayesian statistics, the choice of prior distribution is often debatable, especially if prior knowledge is limited or data are scarce. In imprecise probability, sets of priors are used to accurately model and reflect prior knowledge. This has the advantage that prior-data conflict sensitivity can be modelled: Ranges of posterior inferences should be larger when prior and data are in conflict. We propose a new method for generating prior sets which, in addition to prior-data conflict sensitivity, allows to reflect strong prior-data agreement by decreased posterior imprecision. {\textcopyright} Springer International Publishing Switzerland 2016.},
address = {School of Industrial Engineering, Eindhoven University of Technology, Eindhoven, Netherlands Department of Mathematical Sciences, Durham University, Durham, United Kingdom},
annote = {Cited By :2
Export Date: 12 November 2019},
author = {Walter, G and Coolen, F P A},
booktitle = {Communications in Computer and Information Science},
doi = {10.1007/978-3-319-40596-4_14},
keywords = {Bayesian inference Conjugate priors Imprecise prob},
pages = {153--164},
title = {{Sets of priors reflecting prior-data conflict and agreement}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977139232{\&}doi=10.1007{\%}2F978-3-319-40596-4{\_}14{\&}partnerID=40{\&}md5=20a3d059246c79d1d70bdfa62cc69122},
volume = {610},
year = {2016}
}
@article{Wang2019,
abstract = {We are now at an amazing time for medical product development in drugs, biological products and medical devices. As a result of dramatic recent advances in biomedical science, information technology and engineering, ``big data'' from health care in the real-world have become available. Although big data may not necessarily be attuned to provide the preponderance of evidence to a clinical study, high-quality real-world data can be transformed into scientific evidence for regulatory and healthcare decision-making using proven analytical methods and techniques, such as propensity score methodology and Bayesian inference. In this paper, we extend the Bayesian power prior approach for a single-arm study (the current study) to leverage external real-world data. We use propensity score methodology to pre-select a subset of real-world data containing patients that are similar to those in the current study in terms of covariates, and to stratify the selected patients together with those in the current study into more homogeneous strata. The power prior approach is then applied in each stratum to obtain stratum-specific posterior distributions, which are combined to complete the Bayesian inference for the parameters of interest. We evaluate the performance of the proposed method as compared to that of the ordinary power prior approach by simulation and illustrate its implementation using a hypothetical example, based on our regulatory review experience.},
address = {Division of Biostatistics and Bioinformatics, Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins University , Baltimore , MD , USA. Division of Biostatistics, Center for Devices and Radiological Health, U.S. Food and Drug Administration , Silver Spr},
annote = {1520-5711
Wang, Chenguang
ORCID: https://orcid.org/0000-0002-7085-3303
Li, Heng
Chen, Wei-Chen
Lu, Nelson
Tiwari, Ram
Xu, Yunling
Yue, Lilly Q
Journal Article
England
J Biopharm Stat. 2019;29(5):731-748. doi: 10.1080/10543406.2019.1657133. Epub 2019 Sep 17.},
author = {Wang, C and Li, H and Chen, W C and Lu, N and Tiwari, R and Xu, Y and Yue, L Q},
doi = {10.1080/10543406.2019.1657133},
edition = {2019/09/19},
issn = {1054-3406},
journal = {Journal of Biopharmaceutical Statistics},
keywords = {Covariate balance overlapping coefficient power pr},
language = {eng LB  - Wang2019a},
number = {5},
pages = {731--748},
title = {{Propensity score-integrated power prior approach for incorporating real-world evidence in single-arm clinical studies}},
volume = {29},
year = {2019}
}
@article{Wang2019a,
abstract = {With the wide availability of various real-world data (RWD), there is an increasing interest in synthesizing information from both randomized clinical trials and RWD for health-care decision makings. The task of addressing study-specific heterogeneities is one of the most difficult challenges in synthesizing data from disparate sources. Bayesian hierarchical models with nonparametric extension provide a powerful and convenient platform that formalizes the information borrowing strength across the sources. In this paper, we propose a propensity score-based Bayesian nonparametric Dirichlet process mixture model that summarizes subject-level information from randomized and registry studies to draw inference on the causal treatment effect. Simulation studies are conducted to evaluate the model performance under different scenarios. In addition, we demonstrate the proposed method using data from a clinical study on angiotensin converting enzyme inhibitor for treating congestive heart failure.},
address = {C. Wang, Oncology Biostatistics and Bioinformatics, Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins University, Baltimore, MD, United States},
annote = {L628000844
2019-06-13
2019-06-18},
author = {Wang, C and Rosner, G L},
doi = {10.1002/sim.8134},
issn = {1097-0258 0277-6715},
journal = {Statistics in Medicine},
keywords = {causal inference enalapril article Bayesian nonpar},
language = {English LB  - Wang2019b},
number = {14},
pages = {2573--2588},
title = {{A Bayesian nonparametric causal inference model for synthesizing randomized clinical trial and real-world evidence}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L628000844 http://dx.doi.org/10.1002/sim.8134},
volume = {38},
year = {2019}
}
@article{Wang2006,
author = {Wang, W W B and Mehrotra, D V and Chan, I S F and Heyse, J F},
doi = {10.1080/10543400600719251},
journal = {Journal of Biopharmaceutical Statistics},
number = {4},
pages = {429--441},
title = {{Statistical Considerations for NonInferiority/Equivalence Trials in Vaccine Development}},
volume = {16},
year = {2006}
}
@article{Whitehead2008,
abstract = {This paper presents a simple Bayesian approach to sample size determination in clinical trials. It is required that the trial should be large enough to ensure that the data collected will provide convincing evidence either that an expcrimental treatment is better than a control or that it fails to improve upon control by some clinically relevant difference. The method resembles standard frequentist formulations of the problem, and indeed in certain circumstances involving 'non-informative' prior information it leads to identical answers. In particular, unlike many Bayesian approaches to sample size determination, use is made of an alternative hypothesis that an experimental treatment is better than a control treatment by some specified magnitude. The approach is introduced in the context of testing whether a single stream of binary observations are consistent with a given success rate p0. Next the case of comparing two independent streams of normally distributed responses is considered, first under the assumption that their common variance is known and then for unknown variance. Finally, the more general situation in which a large sample is to be collected and analysed according to the asymptotic properties of the score statistic is explored. Copyright {\textcopyright} 2007 John Wiley {\&} Sons, Ltd.},
address = {J. Whitehead, MPS Research Unit, Department of Mathematics and Statistics, Lancaster University, Lancaster LA1 4YF, United Kingdom},
annote = {L351802896
2008-06-20},
author = {Whitehead, J and Vald{\'{e}}s-M{\'{a}}rquez, E and Johnson, P and Graham, G},
doi = {10.1002/sim.3140},
issn = {0277-6715 1097-0258},
journal = {Statistics in Medicine},
keywords = {antineoplastic agent phosphodiesterase V inhibitor},
language = {English LB  - Whitehead2008},
number = {13},
pages = {2307--2327},
title = {{Bayesian sample size for exploratory clinical trials incorporating historical data}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L351802896 http://dx.doi.org/10.1002/sim.3140},
volume = {27},
year = {2008}
}
@article{Whitehead1996,
abstract = {Abstract Sequential designs are increasingly being used in major clinical trials concerning life-threatening diseases. So far most applications have concerned trials designed to establish whether an experimental treatment is superior to a control. However, many trials are conducted with the objective of showing that an experimental treatment is equivalent to a control. This paper concerns the application of sequential designs to equivalence trials. Criteria for claiming equivalence are reviewed and compared, and methods first developed in the context of bioequivalence are described. Appropriate sequential procedures are identified. A simulated example, based on a clinical comparison of bronchodilators, is used to illustrate both the double triangular test and a comparable procedure constructed from $\alpha$-spending functions.},
author = {Whitehead, John},
doi = {10.1002/(SICI)1097-0258(19961230)15:24<2703::AID-SIM536>3.0.CO;2-V},
journal = {Statistics in Medicine},
number = {24},
pages = {2703--2715},
title = {{SEQUENTIAL DESIGNS FOR EQUIVALENCE STUDIES}},
volume = {15},
year = {1996}
}
@article{Wiens2002,
abstract = {Studies that compare treatments with the purpose of demonstrating that the treatments are similar require an a priori definition of an equivalence limit, how different the treatments can be before the difference is of concern. Defining such an equivalence limit is one of the most difficult aspects of planning the study. Three principles are proposed for setting such limits, depending on the objective of the study: a putative placebo calculation, an approach based on clinically important differences, and methods based on statistical properties. All methods will be useful for many studies, but the study objective should determine the final choice of an equivalence limit. The statistician must play an integral role in determining the final equivalence limit. Advice is offered for helping the statistician participate in the decision on the equivalence limits.},
author = {Wiens, Brian L},
doi = {https://doi.org/10.1016/S0197-2456(01)00196-9},
issn = {0197-2456},
journal = {Controlled Clinical Trials},
keywords = {Active control Equivalence limit Putative placebo },
number = {1},
pages = {2--14},
title = {{Choosing an equivalence limit for noninferiority or equivalence studies}},
volume = {23},
year = {2002}
}
@article{Wiesenfarth2019,
abstract = {Bayesian methods allow borrowing of historical information through prior distributions. The concept of prior effective sample size (prior ESS) facilitates quantification and communication of such prior information by equating it to a sample size. Prior information can arise from historical observations, thus the traditional approach identifies the ESS with such historical sample size. However, this measure is independent from newly observed data, and thus would not capture an actual "loss of information" induced by the prior in case of prior-data conflict. We build on recent work to relate prior impact to a number of (virtual) samples from the current data model and introduce the effective current sample size (ECSS) of a prior, tailored to the application in Bayesian clinical trial designs. Special emphasis is put on robust mixture, power and commensurate priors. We apply the approach to an adaptive design in which the number of recruited patients is adjusted depending on the effective sample size at an interim analysis. We argue that the ECSS is the appropriate measure in this case, as the aim is to save current (as opposed to historical) patients from recruitment. Furthermore, the ECSS can help overcoming lack of consensus in the ESS assessment of mixture priors and can, more broadly, provide further insights into the impact of priors. An R package accompanies the paper. This article is protected by copyright. All rights reserved.},
annote = {L628967703},
author = {Wiesenfarth, M and Calderazzo, S},
doi = {10.1111/biom.13124},
issn = {1541-0420},
journal = {Biometrics},
keywords = {adaptive clinical trial adult article consensus hu},
language = {English LB  - Wiesenfarth2019},
title = {{Quantification of Prior Impact in Terms of Effective Current Sample Size}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L628967703 http://dx.doi.org/10.1111/biom.13124},
year = {2019}
}
@article{Young2020,
abstract = { Background . Research based on emergency departments (EDs) primarily focuses on medical conditions. There is limited research that investigates patients who willingly participate in research. This current study explored ED super-utilizers' (SUs') and nonsuper-utilizers' (NSUs') attitudes toward research. Objective . The study assesses the willingness of SUs to participate in research. We hypothesize that the SU population will be as interested as nonutilizers in participating in medical research. Methods . This prospective observational study stratified participants into SU and NSU cohorts based on their self-reported number of ED visits within 6 months. Surveys were captured in a secured database and analyzed using SAS 9.4. Results . 7,481 completed questionnaires. SUs were more interested in participating in all types of research compared to NSUs. Both groups were most willing to participate in surveys. Neither group was particularly interested in studies that required medications. SUs were not more willing to participate in studies without payment than NSUs. Both groups trusted researchers at the same rates. Conclusion . Although rarely included in medical research, SUs were more willing to participate in nearly all types of research and expressed a similar trust in medical research when compared to nonsuper-utilizers. },
author = {Young, Henry W. and Martin, Emmett T. and Kwiatkowski, Evan and Tyndall, J. Adrian and Cottler, Linda B.},
doi = {10.1155/2020/9404293},
issn = {2090-2840},
journal = {Emergency Medicine International},
title = {{The Association between Emergency Department Super-Utilizer Status and Willingness to Participate in Research}},
year = {2020}
}
@article{Yuan2019,
author = {Yuan, Jiacheng and Liu, Jeen and Zhu, Ray and Lu, Ying and Palm, Ulo},
doi = {10.1080/10543406.2018.1559853},
issn = {1054-3406},
journal = {Journal of Biopharmaceutical Statistics},
number = {3},
pages = {558--573},
title = {{Design of randomized controlled confirmatory trials using historical control data to augment sample size for concurrent controls}},
url = {https://doi.org/10.1080/10543406.2018.1559853},
volume = {29},
year = {2019}
}
@article{Zalevsky2007,
abstract = {TNF is a pleiotropic cytokine required for normal development and function of the immune system; however, TNF overexpression also induces inflammation and is associated with autoimmune diseases. TNF exists as both a soluble and a transmembrane protein. Genetic studies in mice have suggested that inflammation in disease models involves soluble TNF (solTNF) and that maintenance of innate immune function involves transmembrane TNF (tmTNF). These findings imply that selective pharmacologic inhibition of solTNF may be anti-inflammatory and yet preserve innate immunity to infection. To address this hypothesis, we now describe dominant-negative inhibitors of TNF (DN-TNFs) as a new class of biologics that selectively inhibits solTNF. DN-TNFs blocked solTNF activity in human and mouse cells, a human blood cytokine release assay, and two mouse arthritis models. In contrast, DN-TNFs neither inhibited the activity of human or mouse tmTNF nor suppressed innate immunity to Listeria infection in mice. These results establish DN-TNFs as the first selective inhibitors of solTNF, demonstrate that inflammation in mouse arthritis models is primarily driven by solTNF, and suggest that the maintenance of tmTNF activity may improve the therapeutic index of future anti-inflammatory agents.},
author = {Zalevsky, Jonathan and Secher, Thomas and Ezhevsky, Sergei A and Janot, Laure and Steed, Paul M and O'Brien, Christopher and Eivazi, Araz and Kung, James and Nguyen, Duc-Hanh T and Doberstein, Stephen K and Erard, Fran{\c{c}}ois and Ryffel, Bernhard and Szymkowski, David E},
journal = {The Journal of Immunology},
number = {3},
pages = {1872 LP -- 1883},
title = {{Dominant-Negative Inhibitors of Soluble TNF Attenuate Experimental Arthritis without Suppressing Innate Immunity to Infection}},
volume = {179},
year = {2007}
}
@article{Zalevsky2007a,
abstract = {TNF is a pleiotropic cytokine required for normal development and function of the immune system; however, TNF overexpression also induces inflammation and is associated with autoimmune diseases. TNF exists as both a soluble and a transmembrane protein. Genetic studies in mice have suggested that inflammation in disease models involves soluble TNF (solTNF) and that maintenance of innate immune function involves transmembrane TNF (tmTNF). These findings imply that selective pharmacologic inhibition of solTNF may be anti-inflammatory and yet preserve innate immunity to infection. To address this hypothesis, we now describe dominant-negative inhibitors of TNF (DN-TNFs) as a new class of biologics that selectively inhibits solTNF. DN-TNFs blocked solTNF activity in human and mouse cells, a human blood cytokine release assay, and two mouse arthritis models. In contrast, DN-TNFs neither inhibited the activity of human or mouse tmTNF nor suppressed innate immunity to Listeria infection in mice. These results establish DN-TNFs as the first selective inhibitors of solTNF, demonstrate that inflammation in mouse arthritis models is primarily driven by solTNF, and suggest that the maintenance of tmTNF activity may improve the therapeutic index of future anti-inflammatory agents.},
author = {Zalevsky, Jonathan and Secher, Thomas and Ezhevsky, Sergei A and Janot, Laure and Steed, Paul M and O'Brien, Christopher and Eivazi, Araz and Kung, James and Nguyen, Duc-Hanh T and Doberstein, Stephen K and Erard, Franois and Ryffel, Bernhard and Szymkowski, David E},
journal = {The Journal of Immunology},
number = {3},
pages = {1872 LP ---- 1883},
title = {{Dominant-Negative Inhibitors of Soluble TNF Attenuate Experimental Arthritis without Suppressing Innate Immunity to Infection}},
url = {http://www.jimmunol.org/content/179/3/1872.abstract},
volume = {179},
year = {2007}
}
@article{Zhang2017,
abstract = {In drug development programs, an experimental treatment is evaluated across different populations and/or disease types using multiple studies conducted in countries around the world. In order to show the efficacy and safety in a specific population, a bridging study may be required. There are therapeutic areas for which enrolling patients to a trial is very challenging. Therefore, it is of interest to utilize the available historical information from previous studies. However, treatment effect may vary across different subpopulations/disease types; therefore, directly utilizing outcomes from historical studies may result in a biased estimation of treatment effect under investigation in the target trial. In this article, we propose novel approaches using both frequentist and Bayesian frameworks that allow borrowing information from historical studies while accounting for relevant patient's covariates via a propensity-based weighting. We evaluate the operating characteristics of the proposed methods in a simulation study and demonstrate that under certain conditions these methods may lead to improved estimation of a treatment effect.},
address = {T. Zhang, Department of Statistics, North Carolina State University, Raleigh, NC, United States},
annote = {L614798728
2017-03-20
2017-05-09},
author = {Zhang, T and Lipkovich, I and Marchenko, O},
doi = {10.1080/10543406.2017.1289948},
issn = {1520-5711 1054-3406},
journal = {Journal of Biopharmaceutical Statistics},
keywords = {article Bayes theorem bridging study experimental },
language = {English LB  - Zhang2017},
number = {3},
pages = {426--441},
title = {{Bridging data across studies using frequentist and Bayesian estimation}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L614798728 http://dx.doi.org/10.1080/10543406.2017.1289948},
volume = {27},
year = {2017}
}
@article{Zheng2015,
abstract = {Bioequivalence (BE) studies are designed to show that two formulations of one drug are equivalent and they play an important role in drug development. When in a design stage, it is possible that there is a high degree of uncertainty on variability of the formulations and the actual performance of the test versus reference formulation. Therefore, an interim look may be desirable to stop the study if there is no chance of claiming BE at the end (futility), or claim BE if evidence is sufficient (efficacy), or adjust the sample size. Sequential design approaches specially for BE studies have been proposed previously in publications. We applied modification to the existing methods focusing on simplified multiplicity adjustment and futility stopping. We name our method modified sequential design for BE studies (MSDBE). Simulation results demonstrate comparable performance between MSDBE and the original published methods while MSDBE offers more transparency and better applicability. The R package MSDBE is available at https://sites.google.com/site/modsdbe/. Copyright {\textcopyright} 2015 John Wiley {\&} Sons, Ltd.},
author = {Zheng, Cheng and Zhao, Lihui and Wang, Jixian},
doi = {10.1002/pst.1672},
journal = {Pharmaceutical Statistics},
keywords = {adaptive design bioequivalence sample size re-esti},
number = {3},
pages = {180--188},
title = {{Modifications of sequential designs in bioequivalence trials}},
volume = {14},
year = {2015}
}
@article{Zheng2019,
abstract = {Before a first-in-man trial is conducted, preclinical studies are performed in animals to help characterise the safety profile of the new medicine. We propose a robust Bayesian hierarchical model to synthesise animal and human toxicity data, using scaling factors to translate doses administered to different animal species onto an equivalent human scale. After scaling doses, the parameters of dose-toxicity models intrinsic to different animal species can be interpreted on a common scale. A prior distribution is specified for each translation factor to capture uncertainty about differences between toxicity of the drug in animals and humans. Information from animals can then be leveraged to learn about the relationship between dose and risk of toxicity in a new phase I trial in humans. The model allows human dose-toxicity parameters to be exchangeable with the study-specific parameters of animal species studied so far or non-exchangeable with any of them. This leads to robust inferences, enabling the model to give greatest weight to the animal data with parameters most consistent with human parameters or discount all animal data in the case of non-exchangeability. The proposed model is illustrated using a case study and simulations. Numerical results suggest that our proposal improves the precision of estimates of the toxicity rates when animal and human data are consistent, while it discounts animal data in cases of inconsistency.},
address = {L.V. Hampson, Statistical Methodology and Consulting, Novartis Pharma AG, Basel, Switzerland},
annote = {L626156240
2019-02-04},
author = {Zheng, H and Hampson, L V and Wandel, S},
doi = {10.1177/0962280218820040},
issn = {1477-0334 0962-2802},
journal = {Statistical Methods in Medical Research},
keywords = {animal experiment animal model article controlled },
language = {English LB  - Zheng2019},
title = {{A robust Bayesian meta-analytic approach to incorporate animal data into phase I oncology trials}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L626156240 http://dx.doi.org/10.1177/0962280218820040},
year = {2019}
}
@article{Zhu2015,
abstract = {We propose in this article a Bayesian sequential design using alpha spending functions to control the overall type I error in phase III clinical trials. We provide algorithms to calculate critical values, power, and sample sizes for the proposed design. Sensitivity analysis is implemented to check the effects from different prior distributions, and conservative priors are recommended. We compare the power and actual sample sizes of the proposed Bayesian sequential design with different alpha spending functions through simulations. We also compare the power of the proposed method with frequentist sequential design using the same alpha spending function. Simulations show that, at the same sample size, the proposed method provides larger power than the corresponding frequentist sequential design. It also has larger power than traditional Bayesian sequential design which sets equal critical values for all interim analyses. When compared with other alpha spending functions, O?Brien-Fleming alpha spending function has the largest power and is the most conservative in terms that at the same sample size, the null hypothesis is the least likely to be rejected at early stage of clinical trials. And finally, we show that adding a step of stop for futility in the Bayesian sequential design can reduce the overall type I error and reduce the actual sample sizes.},
author = {Zhu, Han and Yu, Qingzhao},
doi = {10.1177/0962280215595058},
issn = {0962-2802},
journal = {Statistical Methods in Medical Research},
number = {5},
pages = {2184--2196},
title = {{A Bayesian sequential design using alpha spending function to control type I error}},
type = {Journal Article},
url = {https://doi.org/10.1177/0962280215595058},
volume = {26},
year = {2015}
}
@article{Zhu2019,
abstract = {There is increasing interest in Bayesian group sequential design because of its potential to improve efficiency in clinical trials, to shorten drug development time, and to enhance statistical inference precision without undermining the clinical trial's integrity or validity. We propose a Bayesian sequential design for clinical trials with time-to-event outcomes and use alpha spending functions to control the overall type I error rate. Bayes factor is adapted for decision-making at interim analyses. Algorithms are presented to make decision rules and to calculate power of the proposed tests. Sensitivity analysis is implemented to evaluate the impact of different choices of prior parameters on choosing critical values. The power of tests, the expected event size of the proposed design, and the quality of estimators are studied through simulations, and compared with the frequentist group sequential design. Simulations show that at fixed total number of events, the proposed design can achieve greater power and require smaller expected event size when appropriate priors are chosen, compared with the frequentist group sequential design. The feasibility of the proposed design is further illustrated on a real data set.},
annote = {32226580[pmid]
PMC7100880[pmcid]},
author = {Zhu, Lin and Yu, Qingzhao and Mercante, Donald E},
doi = {10.1080/19466315.2019.1629996},
issn = {1946-6315},
journal = {Statistics in Biopharmaceutical Research},
keywords = {Alpha spending function Multiple stage analysis Su},
number = {4},
pages = {387--397},
title = {{A Bayesian Sequential Design for Clinical Trials with Time-to-Event Outcomes}},
type = {Journal Article},
url = {https://pubmed.ncbi.nlm.nih.gov/32226580 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7100880/},
volume = {11},
year = {2019}
}

#low (skeptical)
plot(x,dbeta(x,alpha.skpt,beta.skpt),type="l",col="red",xlab="Response Probability",ylab="Density Value",main="Skeptical Prior",
#xaxt="n",
ylim=c(0,max(dbeta(x,alpha.skpt,beta.skpt),dbeta(x,alpha.enth,beta.enth))))
#axis(1,at=seq(0,1,by=0.2))
abline(v=p.enth)
abline(v=p.skpt)
#high (enthuastic)
plot(x,dbeta(x,alpha.enth,beta.enth),type="l",col="blue",xlab="Response Probability",ylab="Density Value",main="Enthuastic Prior",
#xaxt="n",
ylim=c(0,max(dbeta(x,alpha.skpt,beta.skpt),dbeta(x,alpha.enth,beta.enth))))
#axis(1,at=p.enth,labels=expression(theta[A]))
abline(v=p.enth)
abline(v=p.skpt)
# Step 6: Plot inference priors (mixtures)
## 7/19/19 make 50:50 solid black line, 25:75 dark grey with different dash patterns,
# make skeptical/enthuastic light grey with smaller thinkness
# no legend, put omega on actual lines
par(mfrow = c(1, 1))
plot(x,dbeta(x,alpha.skpt,beta.skpt),type="l",col="red",xlab="Response Probability",ylab="Density Value",main="Inference Priors",
xaxt="n",
ylim=c(0,max(dbeta(x,alpha.skpt,beta.skpt),dbeta(x,alpha.enth,beta.enth))))
lines(x,dbeta(x,alpha.enth,beta.enth),type="l",col="blue")
axis(1,at=p.enth,labels=expression(theta[A]))
axis(1,at=p.skpt,labels=expression(theta[0]))
points(x,1/4*dbeta(x,alpha.skpt,beta.skpt)+3/4*dbeta(x,alpha.enth,beta.enth),type='l',lty=3)
points(x,1/2*dbeta(x,alpha.skpt,beta.skpt)+1/2*dbeta(x,alpha.enth,beta.enth),type='l',lty=2)
points(x,3/4*dbeta(x,alpha.skpt,beta.skpt)+1/4*dbeta(x,alpha.enth,beta.enth),type='l',lty=1)
legend(x=0.55,y=4.5,
legend=c("Skeptical","75:25","50:50","25:75","Enthuastic"),
col=c("red","black","black","black","blue"),lty=c(1,1,2,3,1),
cex=0.8,text.font=3)
counter<-0
cutoff.time<-0
for (i in 1:target){
successes<-sum(y[1:i])
if (successes>=3){
cutoff.time<-event.times[i]
break
}
}
y[1:i]
y[event.times<=cutoff.time+2]
require("poisson")
rate <- 1
target <- 50
event.times<-hpp.event.times(rate, target)
rate<-1
h
# can find all subjects and outcomes at once!
y<-rbinom(n=target,size=1,prob=0.5)
counter<-0
cutoff.time<-0
for (i in 1:target){
successes<-sum(y[1:i])
if (successes>=3){
cutoff.time<-event.times[i]
break
}
}
y[1:i]
y[event.times<=cutoff.time+2]
i
cutoff.time
event.times
y
y
y[event.times<=cutoff.time+2]
length(y[event.times<=cutoff.time+2])
length(y[event.times<=cutoff.time+2])-length(y[1:i])
length(y[event.times<=cutoff.time+2])-length(y[1:i])
require("poisson")
rate <- 1
target <- 50
event.times<-hpp.event.times(rate, target)
rate<-1
h
# can find all subjects and outcomes at once!
y<-rbinom(n=target,size=1,prob=0.5)
counter<-0
cutoff.time<-0
for (i in 1:target){
successes<-sum(y[1:i])
if (successes>=3){
cutoff.time<-event.times[i]
break
}
}
# # of additional subjects enrolled
length(y[event.times<=cutoff.time+2])-length(y[1:i])
require("poisson")
rate <- 1
target <- 50
event.times<-hpp.event.times(rate, target)
rate<-1
# can find all subjects and outcomes at once!
y<-rbinom(n=target,size=1,prob=0.5)
counter<-0
cutoff.time<-0
for (i in 1:target){
successes<-sum(y[1:i])
if (successes>=3){
cutoff.time<-event.times[i]
break
}
}
# # of additional subjects enrolled
length(y[event.times<=cutoff.time+2])-length(y[1:i])
require("poisson")
rate <- 1
target <- 50
event.times<-hpp.event.times(rate, target)
rate<-1
# can find all subjects and outcomes at once!
y<-rbinom(n=target,size=1,prob=0.5)
counter<-0
cutoff.time<-0
for (i in 1:target){
successes<-sum(y[1:i])
if (successes>=3){
cutoff.time<-event.times[i]
break
}
}
# # of additional subjects enrolled
length(y[event.times<=cutoff.time+2])-length(y[1:i])
require("poisson")
rate <- 1
target <- 50
event.times<-hpp.event.times(rate, target)
rate<-1
# can find all subjects and outcomes at once!
y<-rbinom(n=target,size=1,prob=0.5)
counter<-0
cutoff.time<-0
for (i in 1:target){
successes<-sum(y[1:i])
if (successes>=3){
cutoff.time<-event.times[i]
break
}
}
# # of additional subjects enrolled
length(y[event.times<=cutoff.time+2])-length(y[1:i])
require("poisson")
rate <- 1
target <- 50
event.times<-hpp.event.times(rate, target)
rate<-1
# can find all subjects and outcomes at once!
y<-rbinom(n=target,size=1,prob=0.5)
counter<-0
cutoff.time<-0
for (i in 1:target){
successes<-sum(y[1:i])
if (successes>=3){
cutoff.time<-event.times[i]
break
}
}
# # of additional subjects enrolled
length(y[event.times<=cutoff.time+2])-length(y[1:i])
require("poisson")
rate <- 1
target <- 50
event.times<-hpp.event.times(rate, target)
rate<-1
# can find all subjects and outcomes at once!
y<-rbinom(n=target,size=1,prob=0.5)
counter<-0
cutoff.time<-0
for (i in 1:target){
successes<-sum(y[1:i])
if (successes>=3){
cutoff.time<-event.times[i]
break
}
}
# # of additional subjects enrolled
length(y[event.times<=cutoff.time+2])-length(y[1:i])
y
event.times
rm(list = ls())
# mean of skeptical prior
p.skpt<-0.20
# mean of enthuastic prior
p.enth<-0.40
# futility theta
p.intr<-0.30
# value of true response proportion
p.range<-seq(p.skpt-0.05,p.enth+0.05,by=0.05)
# tail probabilities for priors (low, high)
tail.skpt<-0.045
tail.enth<-0.05
# prior model probabilities
prior.skpt<-1/2
prior.enth<-1/2
# maximum sample sizes
max.ss<-76
# frequency of sequential monitoring
freq.mntr<-c(2)
# significant trial result threshold
sig.inf<-0.9
sig.fut<-0.85
sig.eff<-0.95
# number of simulated trials per design
reps<-10000
#example1<-function(){
#################################################################################################
## PRIOR SPECIFICATION ##########################################################################
#################################################################################################
# Step 1: Create grid for possible values of phi
phi.range<-seq(0,100,by=0.01)
# Step 2: Compute tail probabilities for every possible choice of phi
# upper tail probability equal to tail.skpt
quantiles.skpt<-qbeta(tail.skpt,(p.skpt)*phi.range,(1-(p.skpt))*phi.range,lower.tail=FALSE)
# lower tail probability equal to tail.enth
quantiles.enth<-qbeta(tail.enth,(p.enth)*phi.range,(1-(p.enth))*phi.range,lower.tail=TRUE)
# Step 3: Grid search to find value of phi with the desired tail probability for the priors
phi_L<-phi.range[which.min(abs(p.enth-quantiles.skpt))] # fixed 5/13/19
phi_H<-phi.range[which.min(abs(p.skpt-quantiles.enth))] # fixed 5/13/19
# Step 4: Find parameters for the priors
alpha.skpt<-(p.skpt)*phi_L
beta.skpt<-(1-(p.skpt))*phi_L
alpha.enth<-(p.enth)*phi_H
beta.enth<-(1-(p.enth))*phi_H
#################################################################################################
## SIMULATIONS ##################################################################################
#################################################################################################
## Step 1: Create outer loop based on frequency of interim analyses
# stop early for efficacy
outer.eff<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# stop early for futility
outer.fut<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# inconclusive findings
outer.inc<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# sample mean
outer.phat.initial<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
outer.phat.final<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# sample size
outer.ss.initial<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
outer.ss.finial<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# posterior mean
outer.post.mean.initial<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
outer.post.mean.final<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# coverage probability
outer.cov.initial<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
outer.cov.final<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
for (k in 1:length(freq.mntr)){ # frequency of monitoring
for (j in 1:length(p.range)){ # true response proportion
inner.eff<-vector(length=reps)
inner.fut<-vector(length=reps)
inner.inc<-vector(length=reps)
inner.ss.initial<-vector(length=reps)
inner.ss.final<-vector(length=reps)
inner.phat.initial<-vector(length=reps)
inner.phat.final<-vector(length=reps)
inner.post.mean.initial<-vector(length=reps)
inner.post.mean.final<-vector(length=reps)
inner.cov.initial<-vector(length=reps)
inner.cov.final<-vector(length=reps)
for (i in 1:reps){ # simulate specified trial design
efficacy<-0     # initialize
futility<-0     # initialize
inner.inc[i]<-1 # initialize
n<-1            # initializing sample size
y1_before<-0    # initializing number of successes
additional_subjects<-0
rate <- 1
event.times<-hpp.event.times(rate, max_ss)
while (n<max.ss){
# generate trial result
y<-rbinom(1,size=1,prob=p.range[j])
# new number of successes
y1<-sum(y1_before)+y
# new number of failures
y0<-n-y1
# futility (even optimst would give up)
futility<-pbeta(p.intr,alpha.enth+y1,beta.enth+y0,lower.tail=TRUE)
# efficacy (even pessimist would accept)
efficacy<-pbeta(p.skpt,alpha.skpt+y1,beta.skpt+y0,lower.tail=FALSE)
## for next loop
y1_before<-y1
if (n%%freq.mntr[k]==0 & futility>sig.fut){
inner.fut[i]<-1
inner.inc[i]<-0
cutoff.time<-event.times[i]
break
}
if (n%%freq.mntr[k]==0 & efficacy>sig.eff){
inner.eff[i]<-1
inner.inc[i]<-0
cutoff.time<-event.times[i]
break
}
n<-n+1
}
## Posterior model probabilities, slide 133/1005 of 779 notes
# posterior probability of data given models
#post_L_D<-(beta(alpha.skpt,beta.skpt))^(-1)*beta(alpha.skpt+y1,beta.skpt+y0)
#post_H_D<-(beta(alpha.enth,beta.enth))^(-1)*beta(alpha.enth+y1,beta.enth+y0)
# posterior probability of models given data
#post_L<-post_L_D*prior.skpt/(post_L_D*prior.skpt+post_H_D*prior.enth)
#post_H<-post_H_D*prior.enth/(post_L_D*prior.skpt+post_H_D*prior.enth)
## compute probability of event A given the models, slide 7/1005 of 779 notes
post_L_eventA<-pbeta(p.skpt,alpha.skpt+y1,beta.skpt+y0,lower.tail=FALSE)
post_H_eventA<-pbeta(p.skpt,alpha.enth+y1,beta.enth+y0,lower.tail=FALSE)
# compute probability of event A
#trial_result[i]<-sum(post_L*post_L_eventA,post_H*post_H_eventA)
#trial_result_binary[i]=(trial_result[i]>=sig.inf) # rejecting null hypothesis
# inference posterior mixture proportions
c1<-prior.skpt*beta(alpha.skpt+y1,beta.skpt+y0)/
(prior.skpt*beta(alpha.skpt+y1,beta.skpt+y0)+prior.enth*beta(alpha.enth+y1,beta.enth+y0))
c2<-prior.enth*beta(alpha.enth+y1,beta.enth+y0)/
(prior.skpt*beta(alpha.skpt+y1,beta.skpt+y0)+prior.enth*beta(alpha.enth+y1,beta.enth+y0))
# posterior mean
inner.post.mean.initial[i]<-c1*(alpha.skpt+y1)/(alpha.skpt+beta.skpt+n)+c2*(alpha.enth+y1)/(alpha.enth+beta.enth+n)
x<-0
for (l in 1:reps){
p = runif(1)
if(p<=c1){
x[l] = rbeta(1,alpha.skpt+y1,beta.skpt+y0)
}
if(p>c1){
x[l] = rbeta(1,alpha.enth+y1,beta.enth+y0)
}
}
# coverage probability
inner.cov.initial[i]<-(p.range[j]>quantile(x,0.025) & p.range[j]<quantile(x,0.975))
inner.ss.initial[i]<-n
inner.phat.initial[i]<-y1/n
#freq_trial_result[i]<-((sqrt(n)*(p.range[j]-inner.phat.initial-delta_0)/sqrt(inner.phat.initial*(1-inner.phat.initial))<qnorm(alpha)) &
#    (sqrt(n)*(p.range[j]-inner.phat.initial+delta_0)/sqrt(inner.phat.initial*(1-inner.phat.initial))>qnorm(1-alpha)))
}
outer_trial_result_binary[k,j]<-mean(trial_result_binary) # sent to final results matrix
outer_trial_result[k,j]<-mean(trial_result)
#outer_freq_trial_result[j]<-mean(freq_trial_result)
outer.ss.initial[k,j]<-mean(inner.ss.initial)
outer.phat.initial[k,j]<-mean(inner.phat.initial)
outer.fut[k,j]<-mean(inner.fut)
outer.eff[k,j]<-mean(inner.eff)
outer.inc[k,j]<-mean(inner.inc)
outer.post.mean.initial[k,j]<-mean(inner.post.mean.initial)
outer.cov.initial[k,j]<-mean(inner.cov.initial)
}
}
rm(list = ls())
# mean of skeptical prior
p.skpt<-0.20
# mean of enthuastic prior
p.enth<-0.40
# futility theta
p.intr<-0.30
# value of true response proportion
p.range<-seq(p.skpt-0.05,p.enth+0.05,by=0.05)
# tail probabilities for priors (low, high)
tail.skpt<-0.045
tail.enth<-0.05
# prior model probabilities
prior.skpt<-1/2
prior.enth<-1/2
# maximum sample sizes
max.ss<-76
# frequency of sequential monitoring
freq.mntr<-c(2)
# significant trial result threshold
sig.inf<-0.9
sig.fut<-0.85
sig.eff<-0.95
# number of simulated trials per design
reps<-10000
#example1<-function(){
#################################################################################################
## PRIOR SPECIFICATION ##########################################################################
#################################################################################################
# Step 1: Create grid for possible values of phi
phi.range<-seq(0,100,by=0.01)
# Step 2: Compute tail probabilities for every possible choice of phi
# upper tail probability equal to tail.skpt
quantiles.skpt<-qbeta(tail.skpt,(p.skpt)*phi.range,(1-(p.skpt))*phi.range,lower.tail=FALSE)
# lower tail probability equal to tail.enth
quantiles.enth<-qbeta(tail.enth,(p.enth)*phi.range,(1-(p.enth))*phi.range,lower.tail=TRUE)
# Step 3: Grid search to find value of phi with the desired tail probability for the priors
phi_L<-phi.range[which.min(abs(p.enth-quantiles.skpt))] # fixed 5/13/19
phi_H<-phi.range[which.min(abs(p.skpt-quantiles.enth))] # fixed 5/13/19
# Step 4: Find parameters for the priors
alpha.skpt<-(p.skpt)*phi_L
beta.skpt<-(1-(p.skpt))*phi_L
alpha.enth<-(p.enth)*phi_H
beta.enth<-(1-(p.enth))*phi_H
#################################################################################################
## SIMULATIONS ##################################################################################
#################################################################################################
## Step 1: Create outer loop based on frequency of interim analyses
# stop early for efficacy
outer.eff<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# stop early for futility
outer.fut<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# inconclusive findings
outer.inc<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# sample mean
outer.phat.initial<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
outer.phat.final<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# sample size
outer.ss.initial<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
outer.ss.finial<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# posterior mean
outer.post.mean.initial<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
outer.post.mean.final<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
# coverage probability
outer.cov.initial<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
outer.cov.final<-matrix(nrow=length(freq.mntr),ncol=length(p.range))
for (k in 1:length(freq.mntr)){ # frequency of monitoring
for (j in 1:length(p.range)){ # true response proportion
inner.eff<-vector(length=reps)
inner.fut<-vector(length=reps)
inner.inc<-vector(length=reps)
inner.ss.initial<-vector(length=reps)
inner.ss.final<-vector(length=reps)
inner.phat.initial<-vector(length=reps)
inner.phat.final<-vector(length=reps)
inner.post.mean.initial<-vector(length=reps)
inner.post.mean.final<-vector(length=reps)
inner.cov.initial<-vector(length=reps)
inner.cov.final<-vector(length=reps)
for (i in 1:reps){ # simulate specified trial design
efficacy<-0     # initialize
futility<-0     # initialize
inner.inc[i]<-1 # initialize
n<-1            # initializing sample size
y1_before<-0    # initializing number of successes
additional_subjects<-0
rate <- 1
event.times<-hpp.event.times(rate, max.ss)
while (n<max.ss){
# generate trial result
y<-rbinom(1,size=1,prob=p.range[j])
# new number of successes
y1<-sum(y1_before)+y
# new number of failures
y0<-n-y1
# futility (even optimst would give up)
futility<-pbeta(p.intr,alpha.enth+y1,beta.enth+y0,lower.tail=TRUE)
# efficacy (even pessimist would accept)
efficacy<-pbeta(p.skpt,alpha.skpt+y1,beta.skpt+y0,lower.tail=FALSE)
## for next loop
y1_before<-y1
if (n%%freq.mntr[k]==0 & futility>sig.fut){
inner.fut[i]<-1
inner.inc[i]<-0
cutoff.time<-event.times[i]
break
}
if (n%%freq.mntr[k]==0 & efficacy>sig.eff){
inner.eff[i]<-1
inner.inc[i]<-0
cutoff.time<-event.times[i]
break
}
n<-n+1
}
## Posterior model probabilities, slide 133/1005 of 779 notes
# posterior probability of data given models
#post_L_D<-(beta(alpha.skpt,beta.skpt))^(-1)*beta(alpha.skpt+y1,beta.skpt+y0)
#post_H_D<-(beta(alpha.enth,beta.enth))^(-1)*beta(alpha.enth+y1,beta.enth+y0)
# posterior probability of models given data
#post_L<-post_L_D*prior.skpt/(post_L_D*prior.skpt+post_H_D*prior.enth)
#post_H<-post_H_D*prior.enth/(post_L_D*prior.skpt+post_H_D*prior.enth)
## compute probability of event A given the models, slide 7/1005 of 779 notes
post_L_eventA<-pbeta(p.skpt,alpha.skpt+y1,beta.skpt+y0,lower.tail=FALSE)
post_H_eventA<-pbeta(p.skpt,alpha.enth+y1,beta.enth+y0,lower.tail=FALSE)
# compute probability of event A
#trial_result[i]<-sum(post_L*post_L_eventA,post_H*post_H_eventA)
#trial_result_binary[i]=(trial_result[i]>=sig.inf) # rejecting null hypothesis
# inference posterior mixture proportions
c1<-prior.skpt*beta(alpha.skpt+y1,beta.skpt+y0)/
(prior.skpt*beta(alpha.skpt+y1,beta.skpt+y0)+prior.enth*beta(alpha.enth+y1,beta.enth+y0))
c2<-prior.enth*beta(alpha.enth+y1,beta.enth+y0)/
(prior.skpt*beta(alpha.skpt+y1,beta.skpt+y0)+prior.enth*beta(alpha.enth+y1,beta.enth+y0))
# posterior mean
inner.post.mean.initial[i]<-c1*(alpha.skpt+y1)/(alpha.skpt+beta.skpt+n)+c2*(alpha.enth+y1)/(alpha.enth+beta.enth+n)
x<-0
for (l in 1:reps){
p = runif(1)
if(p<=c1){
x[l] = rbeta(1,alpha.skpt+y1,beta.skpt+y0)
}
if(p>c1){
x[l] = rbeta(1,alpha.enth+y1,beta.enth+y0)
}
}
# coverage probability
inner.cov.initial[i]<-(p.range[j]>quantile(x,0.025) & p.range[j]<quantile(x,0.975))
inner.ss.initial[i]<-n
inner.phat.initial[i]<-y1/n
#freq_trial_result[i]<-((sqrt(n)*(p.range[j]-inner.phat.initial-delta_0)/sqrt(inner.phat.initial*(1-inner.phat.initial))<qnorm(alpha)) &
#    (sqrt(n)*(p.range[j]-inner.phat.initial+delta_0)/sqrt(inner.phat.initial*(1-inner.phat.initial))>qnorm(1-alpha)))
}
outer_trial_result_binary[k,j]<-mean(trial_result_binary) # sent to final results matrix
outer_trial_result[k,j]<-mean(trial_result)
#outer_freq_trial_result[j]<-mean(freq_trial_result)
outer.ss.initial[k,j]<-mean(inner.ss.initial)
outer.phat.initial[k,j]<-mean(inner.phat.initial)
outer.fut[k,j]<-mean(inner.fut)
outer.eff[k,j]<-mean(inner.eff)
outer.inc[k,j]<-mean(inner.inc)
outer.post.mean.initial[k,j]<-mean(inner.post.mean.initial)
outer.cov.initial[k,j]<-mean(inner.cov.initial)
}
}
vector(1)
vector()

# ## define survival function;
# surv.pwe <- function(t,lambda,theta,t1)
# {
#   (t<t1)  * exp(-lambda*t) +
#     (t>=t1) * exp(-lambda*t1 - theta*(t-t1));
# }
## estimate hazard function;
est.haz <- function(time, t1, weight = 1)
{
v1 = sum(weight*(time<t1));
r1 = sum(weight*(time<t1)*time) + sum(weight*(time>=t1)*(time-t1))
h1 = v1/r1;
v2 = sum(weight*(time>=t1));
r2 = sum(weight*(time>=t1)*(time-t1))
h2 = v2/r2;
return(c(h1,h2));
}
## simulate PWE survival times;
sim.pwe <- function(u, lambda, theta, t1)
{
p1    = exp(-lambda*t1);
time1 = log(u)/-lambda;
time2 = (log(u)+lambda*t1-theta*t1)/-theta;
time  = (u > p1)*time1 + (u <= p1)*time2 ;
return(time);
}
b = NA
for (m in 1:M){
## simulate new and historical survival times;
time.n = sim.pwe(runif(N),lambda,theta,t1)
time.h = sim.pwe(runif(N),lambda,theta,t1)
## simulate from new data posterior;
v1 = sum((time.n<t1));
r1 = sum((time.n<t1)*time.n) + sum((time.n>=t1)*(time.n-t1))
v2 = sum((time.n>=t1));
r2 = sum((time.n>=t1)*(time.n-t1))
lambda.s = rgamma(S,v1,r1);
theta.s  = rgamma(S,v2,r2);
## calculate the predictive distribution for the historical data;
predictive     = sim.pwe(runif(S),lambda.s,theta.s,t1);
empirical.cdf  = ecdf(predictive) # lightning fast!
## compute Bayesian p-values;
transformed.historical.values = qnorm(empirical.cdf(time.h));
bayes.pvalue   = 2*pnorm(-abs(transformed.historical.values));
## estimate hazard to verify PWE;
estimates[m,]=c(	c(v1/r1,v2/r2),
est.haz(c(time.n,time.h),t1,weight=rep(1,2*N)),
est.haz(c(time.n,time.h),t1,weight=c(rep(1,N),bayes.pvalue)),
mean(bayes.pvalue)
)
b = c(b,bayes.pvalue);
}
colMeans(estimates)
hist(b)
hist(time.n)
hist(time.h)
hist(predictive, freq = F, breaks = 50, xlim = c(0, 6))
plot(sort(time.n), empirical.cdf(sort(time.n)))
plot(sort(time.n), qnorm(empirical.cdf(sort(time.n))))
abline(h = 0)
abline(v = log(2))
hist(-abs(transformed.historical.values))
hist(pnorm(-abs(transformed.historical.values)))
hist(2*pnorm(-abs(transformed.historical.values)))
time.h2 <- time.h * 1/10
## calculate the predictive distribution for the historical data;
predictive     = sim.pwe(runif(S),lambda.s,theta.s,t1)
empirical.cdf  = ecdf(predictive) # lightning fast!
## compute Bayesian p-values;
transformed.historical.values = qnorm(empirical.cdf(time.h2))
bayes.pvalue   = 2*pnorm(-abs(transformed.historical.values))
hist(bayes.pvalue)
summary(bayes.pvalue)
time.h2 <- time.h * 1
## calculate the predictive distribution for the historical data;
predictive     = sim.pwe(runif(S),lambda.s,theta.s,t1)
empirical.cdf  = ecdf(predictive) # lightning fast!
## compute Bayesian p-values;
transformed.historical.values = qnorm(empirical.cdf(time.h2))
bayes.pvalue   = 2*pnorm(-abs(transformed.historical.values))
hist(bayes.pvalue)
summary(bayes.pvalue)
time.h2 <- time.h * 2
## calculate the predictive distribution for the historical data;
predictive     = sim.pwe(runif(S),lambda.s,theta.s,t1)
empirical.cdf  = ecdf(predictive) # lightning fast!
## compute Bayesian p-values;
transformed.historical.values = qnorm(empirical.cdf(time.h2))
bayes.pvalue   = 2*pnorm(-abs(transformed.historical.values))
hist(bayes.pvalue)
summary(bayes.pvalue)
time.h2 <- time.h * 3
## calculate the predictive distribution for the historical data;
predictive     = sim.pwe(runif(S),lambda.s,theta.s,t1)
empirical.cdf  = ecdf(predictive) # lightning fast!
## compute Bayesian p-values;
transformed.historical.values = qnorm(empirical.cdf(time.h2))
bayes.pvalue   = 2*pnorm(-abs(transformed.historical.values))
hist(bayes.pvalue)
summary(bayes.pvalue)
time.h2 <- time.h * 10
## calculate the predictive distribution for the historical data;
predictive     = sim.pwe(runif(S),lambda.s,theta.s,t1)
empirical.cdf  = ecdf(predictive) # lightning fast!
## compute Bayesian p-values;
transformed.historical.values = qnorm(empirical.cdf(time.h2))
bayes.pvalue   = 2*pnorm(-abs(transformed.historical.values))
hist(bayes.pvalue)
summary(bayes.pvalue)
time.h2 <- time.h * 1/1
## calculate the predictive distribution for the historical data;
predictive     = sim.pwe(runif(S),lambda.s,theta.s,t1)
empirical.cdf  = ecdf(predictive) # lightning fast!
## compute Bayesian p-values;
transformed.historical.values = qnorm(empirical.cdf(time.h2))
bayes.pvalue   = 2*pnorm(-abs(transformed.historical.values))
hist(bayes.pvalue)
summary(bayes.pvalue)
time.h2 <- time.h * 1/2
## calculate the predictive distribution for the historical data;
predictive     = sim.pwe(runif(S),lambda.s,theta.s,t1)
empirical.cdf  = ecdf(predictive) # lightning fast!
## compute Bayesian p-values;
transformed.historical.values = qnorm(empirical.cdf(time.h2))
bayes.pvalue   = 2*pnorm(-abs(transformed.historical.values))
hist(bayes.pvalue)
summary(bayes.pvalue)
time.h2 <- time.h * 1/3
## calculate the predictive distribution for the historical data;
predictive     = sim.pwe(runif(S),lambda.s,theta.s,t1)
empirical.cdf  = ecdf(predictive) # lightning fast!
## compute Bayesian p-values;
transformed.historical.values = qnorm(empirical.cdf(time.h2))
bayes.pvalue   = 2*pnorm(-abs(transformed.historical.values))
hist(bayes.pvalue)
summary(bayes.pvalue)
time.h2 <- time.h * 1/4
## calculate the predictive distribution for the historical data;
predictive     = sim.pwe(runif(S),lambda.s,theta.s,t1)
empirical.cdf  = ecdf(predictive) # lightning fast!
## compute Bayesian p-values;
transformed.historical.values = qnorm(empirical.cdf(time.h2))
bayes.pvalue   = 2*pnorm(-abs(transformed.historical.values))
hist(bayes.pvalue)
summary(bayes.pvalue)
time.h2 <- time.h * 1/5
## calculate the predictive distribution for the historical data;
predictive     = sim.pwe(runif(S),lambda.s,theta.s,t1)
empirical.cdf  = ecdf(predictive) # lightning fast!
## compute Bayesian p-values;
transformed.historical.values = qnorm(empirical.cdf(time.h2))
bayes.pvalue   = 2*pnorm(-abs(transformed.historical.values))
hist(bayes.pvalue)
summary(bayes.pvalue)
rm(list = ls())
start_time <- Sys.time()
setwd("/Users/kwiatkoe/Documents/GitHub/hybrid-methods/pprior-a0j/2020-11-17_code")
library(xtable)
library(LearnBayes)
library(MCMCpack)
library(ks)     # kde
library(Renext) # lomax
library(truncdist)
library(foreach)
library(doParallel)
registerDoParallel(detectCores() - 1)
getDoParWorkers()
start_time <- Sys.time()
rexpt <- function(n, a, b, rate){
F.a <- pexp(a, rate = rate)
F.b <- pexp(b, rate = rate)
u   <- runif(n, min = F.a, max = F.b)
qexp(u, rate = rate)
}
names     <- c("l", "cen", "n_event","n_cen","n_mle", "n_mle_std",
"n.h_event", "n.h_cen_drop", "n.h_cen_admin", "n.h_mle",
"start_h",
"y0_all", "y0_evnt", "y0_drop", "y0_admin",
"y0_all_2", "y0_evnt_2", "y0_drop_2", "y0_admin_2",
"a0_all", "a0_evnt", "a0_drop", "a0_admin",
"a0_evnt_2", "a0_cen_2",
"v1", "v1_std")
#l.seq     <- c(0.05, seq(.1, 1, by = 0.1), 2, 3, 4, 5)
ex.seq <- seq(3, 1, length = 9)
mult.seq <- c(ex.seq, (1/rev(ex.seq))[-1])
l.seq     <- rep(1, length(mult.seq))
l.cen     <- l.seq
l.start   <- rep(0, length(l.seq))
l.fixed   <- rep(1000, length(l.seq))
outermost <- matrix(NA, nrow = length(l.seq), ncol = length(names))
samp.size <- 1E4
a0_outermost <- matrix(NA, nrow = samp.size, ncol = length(l.seq))
idx_n     <- 1  # repetitions per design
N         <- 1E2  # number of samples from posterior predictive
M         <- 1    # number of imputations for each admin censored observation
a <- 0.001
b <- 0.001
foreach(l_idx = 1:length(l.seq)) %dopar% {
# for (l_idx in 1:length(l.seq)){
# for (l_idx in 1:length(l.seq)){
print(paste0("l_idx = ", l_idx))
outer_results           <- matrix(NA, nrow = idx_n, ncol = length(names))
colnames(outer_results) <- names
for (idx in 1:idx_n){
# 5.2
n        <- samp.size
start    <- rep(0, n)
# C        <- rexp(n, rate = l.cen[l_idx])
Tlat     <- rexp(n, rate = l.seq[l_idx])
C        <- max(Tlat) + 1
y        <- pmin(Tlat, C)
nu       <- as.numeric(Tlat <= C) # equals 1 if observed
# 5.3
n.h       <- samp.size
start.h   <- runif(n.h, min = 0, max = l.start[l_idx]) # calendar time
Tlat.h    <- start.h + rexp(n.h, rate = l.seq[l_idx] * mult.seq[l_idx])  # calendar time
# C.h       <- start.h + rexp(n.h, rate = l.cen[l_idx])  # calendar time
C.h       <- max(Tlat.h) + 1
C.fixed   <- l.fixed[l_idx]                            # calendar time
Z.h       <- pmin(Tlat.h, C.h, C.fixed)                # calendar time
y.h       <- Z.h - start.h                             # net time
nu.h      <- as.numeric(Z.h == Tlat.h)                 # equals 1 if observed
cen.drop  <- as.numeric(Z.h == C.h)                    # equals 1 if dropout
cen.admin <- as.numeric(Z.h == C.fixed)                # equals 1 if admin censored
outer_results[idx,"l"]               <- l.seq[l_idx]
outer_results[idx,"cen"]             <- l.cen[l_idx]
outer_results[idx,"n_event"]         <- sum(nu)
outer_results[idx,"n_cen"]           <- sum(nu == 0)
outer_results[idx,"n_mle"]           <- (sum(nu)/sum(y))
outer_results[idx,"n_mle_std"]       <- sqrt(sum(nu))/sum(y) # RMS 425
outer_results[idx,"n.h_event"]       <- sum(Z.h == Tlat.h)
outer_results[idx,"n.h_cen_drop"]    <- sum(Z.h == C.h)
outer_results[idx,"n.h_cen_admin"]   <- sum(Z.h == C.fixed)
outer_results[idx,"n.h_mle"]         <- (sum(nu.h)/sum(y.h))
outer_results[idx,"start_h"]         <- mean(start.h)
outer_results[idx,"y0_all"]          <- mean(y.h)
outer_results[idx,"y0_evnt"]         <- mean(y.h[nu.h == 1])
outer_results[idx,"y0_drop"]         <- mean(y.h[cen.drop == 1])
outer_results[idx,"y0_admin"]        <- mean(y.h[cen.admin == 1])
inner.names <- c("a0_all", "a0_evnt_2", "a0_cen_2",
"a0_evnt", "a0_drop", "a0_admin",
"v1", "v1_std",
"y0_all_2", "y0_evnt_2", "y0_drop_2", "y0_admin_2")
innermost   <- matrix(NA, nrow = M, ncol = length(inner.names))
colnames(innermost) <- inner.names
for (m in 1:M){
Tlat.h.new <- rep(NA, length(y.h))
y.h.new    <- rep(NA, length(y.h))
C.h.new    <- rep(NA, length(y.h))
Z.h.new    <- rep(NA, length(y.h))
nu.h.new   <- rep(NA, length(y.h))
for(i in 1:length(y.h)){
if (Z.h[i] == C.fixed){
# 5.4
lambda.eb <- rgamma(n = 1, shape = a + sum(nu.h),       rate = b + sum(y.h)) # .eb = "empirical Bayes"
theta.eb  <- rgamma(n = 1, shape = a + sum(Z.h == C.h), rate = b + sum(y.h)) # .eb = "empirical Bayes"
# 5.5
Tlat.h.new[i] <- rtrunc(1, "exp", C.fixed, Inf, rate = lambda.eb) # calendar time
C.h.new[i]    <- rtrunc(1, "exp", C.fixed, Inf, rate = theta.eb)  # calendar time
Z.h.new[i]    <- min(Tlat.h.new[i], C.h.new[i])                   # calendar time
y.h.new[i]      <- Z.h.new[i] - start.h[i]                          # net time
nu.h.new[i]   <- as.numeric(Z.h.new[i] == Tlat.h.new[i])
} else {
Tlat.h.new[i] <- Tlat.h[i]
C.h.new[i]    <- C.h[i]
Z.h.new[i]    <- Z.h[i]
y.h.new[i]    <- y.h[i]
nu.h.new[i]   <- nu.h[i]
}
}
# 5.6
box.p.log <- rep(NA, length(y.h))
for(i in 1:length(y.h)){
lambda <- rgamma(n = N, shape = a + sum(nu),         rate = b + sum(y))
theta  <- rgamma(n = N, shape = a + sum(Z.h == C.h), rate = b + sum(y.h))
y.h.pred <- rexp(n = N, rate = lambda + theta)
fhat0    <- kde(log(y.h.pred))
box.p.log[i]  <- mean(predict(fhat0, x = log(y.h.pred)) <= predict(fhat0, x = log(y.h.new[i])))
}
a0          <- box.p.log
a0_outermost[ , l_idx] <- a0
innermost[m,"a0_all"]    <- mean(a0)
innermost[m,"a0_evnt_2"] <- mean(a0[nu.h.new == 1])
innermost[m,"a0_cen_2"]  <- mean(a0[nu.h.new == 0])
innermost[m,"a0_evnt"]   <- mean(a0[nu.h == 1])
innermost[m,"a0_drop"]   <- mean(a0[cen.drop == 1])
innermost[m,"a0_admin"]  <- mean(a0[cen.admin == 1])
# 5.7
innermost[m,"v1"]        <- (a + sum(a0*nu.h.new) + sum(nu))/(b + sum(a0*y.h.new) + sum(y))
innermost[m,"v1_std"]    <- sqrt(a + sum(a0*nu.h.new) + sum(nu))/(b + sum(a0*y.h.new) + sum(y))
innermost[m,"y0_all_2"]          <- mean(y.h.new)
innermost[m,"y0_evnt_2"]         <- mean(y.h.new[Z.h.new == Tlat.h.new])
innermost[m,"y0_drop_2"]         <- mean(y.h.new[Z.h.new == C.h.new])
innermost[m,"y0_admin_2"]        <- mean(y.h.new[Z.h.new == C.fixed])
}
outer_results[idx,"a0_all"]    <- mean(innermost[,"a0_all"])
outer_results[idx,"a0_evnt_2"] <- mean(innermost[,"a0_evnt_2"])
outer_results[idx,"a0_cen_2"]  <- mean(innermost[,"a0_cen_2"])
outer_results[idx,"a0_evnt"]  <- mean(innermost[,"a0_evnt"])
outer_results[idx,"a0_drop"]  <- mean(innermost[,"a0_drop"])
outer_results[idx,"a0_admin"] <- mean(innermost[,"a0_admin"])
outer_results[idx,"v1"]        <- mean(innermost[,"v1"])
outer_results[idx,"v1_std"]    <- mean(innermost[,"v1_std"])
outer_results[idx,"y0_all_2"]          <- mean(innermost[,"y0_all_2"])
outer_results[idx,"y0_evnt_2"]         <- mean(innermost[,"y0_evnt_2"])
outer_results[idx,"y0_drop_2"]         <- mean(innermost[,"y0_drop_2"])
outer_results[idx,"y0_admin_2"]        <- mean(innermost[,"y0_admin_2"])
}
outermost[l_idx,] <- apply(outer_results, 2, mean)
# write.csv(outer_results, paste0("output/", l_idx, ".csv"))
write.csv(a0, paste0("output/", sprintf("%02d", l_idx), ".csv"))
}
end_time  <- Sys.time()
diff_time <- difftime(end_time, start_time, units = "auto")
cat("Started  ", as.character(start_time), "\n",
"Finished ", as.character(end_time), "\n",
"Time difference of ", diff_time, " ", attr(diff_time, "units"), "\n",
"Used ", foreach::getDoParWorkers(), " cores\n",
"Used ", foreach::getDoParName(), " as backend\n",
sep = "")
# outer_results
# boxplot(a0)
# hist(outer_results[, "a0_all"])
setwd("/Users/kwiatkoe/Documents/GitHub/hybrid-methods/pprior-a0j/2020-11-17_code")
overall_list <- list.files("output")
a0_outermost <- matrix(NA, nrow = samp.size, ncol = length(seq(1, length(l.seq), by = 1)))
for (i in seq(1, length(l.seq), by = 1)){
a0_outermost[, i] <- read.csv(file = paste0("output/", overall_list[i]), header = TRUE, sep = ",")[,-1]
}
#
#
#
# for (i in 1:length(overall_list)){
#   temp <- apply(read.csv(file = paste0("output/", overall_list[i]), header = TRUE, sep = ",")[,-1], 2, mean, na.rm = TRUE)
#   if (i==1) {
#     overall <- rbind(temp)
#   } else {
#     overall <- rbind(overall, temp)
#   }
# }
# overall
# subset <- overall[,c("n_mle", "n_mle_std", "a0_all", "a0_evnt", "a0_drop", "a0_admin", "v1", "v1_std")]
# subset
par(mfrow=c(1,1))
n0 <- samp.size
# right side boxplot
boxplot(as.vector(a0_outermost) ~ rep(seq(1:ncol(a0_outermost)), each = n0),
main = "",
xlab = "Perturbation of Baseline Hazard",
ylab = "Compatibility Weight",
xaxt = "n",
yaxt = "n",
whisklty = 0, staplelty = 0, outcex = 0)
# mannually add 90/10 percentile wiskers
test <- apply(a0_outermost, 2, quantile, probs=c(0.1,0.25,0.75,0.9))
for(i in seq(1:ncol(a0_outermost))){
segments(x0=i, x1=i, y0=test[1,i],y1=test[2,i])
segments(x0=i, x1=i, y0=test[3,i],y1=test[4,i])
segments(x0=i-0.25,x1=i+0.25,y0=test[4,i],y1=test[4,i])
segments(x0=i-0.25,x1=i+0.25,y0=test[1,i],y1=test[1,i])}
axis(2, at = seq(0,1,0.25))
axis(1, at = floor(seq(1:ncol(a0_outermost))), labels = round(mult.seq[seq(1,length(l.seq), by = 1)], 2))
outer_results
bsamsize(p1, p2, fraction=.5, alpha=.05, power=.8)
require(Hmisc)
bsamsize(p1, p2, fraction=.5, alpha=.05, power=.8)
bsamsize(0.51, 0.39, fraction=.5, alpha=.05, power=.8)
bsamsize(0.51, 0.39, fraction=.4, alpha=.05, power=.8)
getwd()
setwd(/Users/kwiatkoe/Documents/GitHub/hybrid-methods/pprior-a0j/2020-11-17_code)
setwd("/Users/kwiatkoe/Documents/GitHub/hybrid-methods/pprior-a0j/2020-11-17_code")
setwd("/Users/kwiatkoe/Documents/GitHub/GitHub/Bayesian-Sequential-Monitoring/00-paper/FIGURES/riskdiff/plots")
setwd("/Users/kwiatkoe/Documents/GitHub/GitHub/Bayesian-Sequential-Monitoring/00-paper/FIGURES/riskdiff/code/plots")
setwd("/Users/kwiatkoe/Documents/GitHub/GitHub/Bayesian-Sequential-Monitoring")#/00-paper/FIGURES/riskdiff/code/plots")
setwd("/Users/kwiatkoe/Documents/GitHub/GitHub")/Bayesian-Sequential-Monitoring")#/00-paper/FIGURES/riskdiff/code/plots")
setwd("/Users/kwiatkoe/Documents/GitHub/GitHub")#/Bayesian-Sequential-Monitoring")#/00-paper/FIGURES/riskdiff/code/plots")
setwd("/Users")
setwd("/Users/kwiatioe")
setwd("/Users/kwiatkoe")
setwd("/Users/kwiatkoe/Documents")
setwd("/Users/kwiatkoe/Documents/GitHub")
setwd("/Users/kwiatkoe/Documents/GitHub/Bayesian-Sequential-Monitoring")
setwd("/Users/kwiatkoe/Documents/GitHub/Bayesian-Sequential-Monitoring/00-paper")
setwd("/Users/kwiatkoe/Documents/GitHub/Bayesian-Sequential-Monitoring/00-paper/FIGURES")
setwd("/Users/kwiatkoe/Documents/GitHub/Bayesian-Sequential-Monitoring/00-paper/FIGURES/riskdiff")
setwd("/Users/kwiatkoe/Documents/GitHub/Bayesian-Sequential-Monitoring/00-paper/FIGURES/riskdiff/code")
setwd("/Users/kwiatkoe/Documents/GitHub/Bayesian-Sequential-Monitoring/00-paper/FIGURES/riskdiff/code/plots")
setwd("/Users/kwiatkoe/Documents/GitHub/Bayesian-Sequential-Monitoring/00-paper/FIGURES/riskdiff/code/plots")
output_png <- TRUE
sig.fut    <- 0.975
sig.eff    <- 0.975
width.scale <- 7
#############################################
#### Figure 6, Risk Diff Inference Plots ####
#############################################
rm(list = ls())
setwd("/Users/kwiatkoe/Documents/GitHub/Bayesian-Sequential-Monitoring/00-paper/FIGURES/riskdiff/code/plots")
output_png <- FALSE
sig.fut    <- 0.975
sig.eff    <- 0.975
width.scale <- 7
if(output_png){
png('../../../figure6.png',
width = 450*width.scale,
height = 300*width.scale,
pointsize=16,
res=300)
}
par(mar=c(5.1 + 2, 4.1 + 0.5, 2.1, 2.1 + 0.5)) #c(bottom, left, top, right)
#par(mar=c(5.1+2, 4.1, 4.1, 2.1)) #c(bottom, left, top, right)
stretch <- 0.35 # to add x-axis table under graph
# set initial plotting area
plot(NULL,
type = 'l',
xlim = c(.39, .63),
ylim = c(0,1),
lwd  = 1,
ylab = "Probability",
xlab = "", #Treatment Response Probability",
main = "",
xaxt = "n",
yaxt = "n")
abline(h = seq(0, 1, by = 0.1),
col = 'grey')
axis(2,
las = 2,
at = seq(0, 1, by = 0.1),
labels = format(seq(0, 1, by = 0.1), nsmall = 1))
mtext(text=c(as.expression(bquote(theta))),side=1,line=1,at=stretch,adj=0)
legend('topleft',
legend= c("1: 25% Skeptical (Mostly Enthusiastic)",
"2: Adaptive Weight Mixture",
"3: 50% Skeptical",
"4: 75% Skeptical Mixture",
"5: 100% Skeptical (Default)"))
# # plot all fixed weight priors
# Table1        <- read.csv(file = "../../output/table1031920.csv", header = T)
# #Table1_ref    <- read.csv(file = "../../output/output062120/Table1/1Table1.csv")
# #names(Table1) <- names(Table1_ref)
# args          <- read.csv(file = "../../output/args_simulation031920.csv", header = F)
# args_ref      <- read.csv(file = "../args_simulation.csv")
# names(args)   <- names(args_ref)
# combined1     <- merge(args, Table1, by.x = "X", by.y = "idx")
# figure3       <- combined1
Table0                 <- read.csv("../../output/Table0_merged_071620.csv")
Table0$ss.final        <- Table0$y0.IP.final +
Table0$y0.PC.final +
Table0$y1.IP.final +
Table0$y1.PC.final
Table0$ss.initial        <- Table0$y0.IP.initial +
Table0$y0.PC.initial +
Table0$y1.IP.initial +
Table0$y1.PC.initial
Table0$eff.mon.initial <- Table0$eff.prob.initial >= sig.eff
figure3         <- aggregate(x   = Table0,
by  = list(Table0$p.IP, Table0$p.PC, Table0$eff.mix.prob),
FUN = mean)
## may need to change eff.mix.prob to eff.mix.prob.x
probs <- seq(0.25, 1, by = 0.25)
for (i in 1:length(probs)){
if (i == 1) row = 2
if (i == 2) row = 4
if (i == 3) row = 5
if (i == 4) row = 6
#row  <- i + 2
temp <- figure3[is.na(figure3$eff.mix.prob) == FALSE,]
temp <- temp[temp$eff.mix.prob == probs[i],]
#temp.lines <- temp[temp$p.IP != 0.51,]
lines(temp$p.IP,temp$eff.mon.initial)
for (j in seq(1,length(temp$p.IP)#, by=6
)){
mtext(text=paste0(format(round(temp$ss.initial[j],digits=1),nsmall=1),
" + ",
format(round(temp$ss.final[j]-
temp$ss.initial[j],digits=1),nsmall=1),
" = ",
format(round(temp$ss.final[j],digits=1),nsmall=1)),
side=1,line=row,at=temp$p.IP[j])
}
text(temp$p.IP[j], temp$eff.mon.initial[j], row - 1)
mtext(text=paste0(row - 1),side=1,line=row,at=stretch,adj=0)
}
axis(1,
las = 0,
at = temp$p.IP,
labels = format(temp$p.IP-temp$p.PC, nsmall = 2))
# plot adaptive mixing prior
#Table0  <- read.csv(file = "../../output/Table0_merged_062420.csv")
# figure3 <- aggregate(x   = Table0,
#                      by  = list(Table0$p.IP, Table0$p.PC, Table0$eff.mix.prob),
#                      FUN = mean)
for (i in 5){
row <- 3
temp <- figure3[figure3$eff.mix.prob == 10, ]
#temp <- figure3[is.na(figure3$eff.mix.prob) == TRUE,]
lines(temp$p.IP,temp$eff.mon.initial)
for (j in seq(1,length(temp$p.IP)#, by=3
)){
mtext(text=paste0(format(round(temp$ss.initial[j],digits=1),nsmall=1),
" + ",
format(round(temp$ss.final[j]-
temp$ss.initial[j],digits=1),nsmall=1),
" = ",
format(round(temp$ss.final[j],digits=1),nsmall=1)),
side=1,line=row,at=temp$p.IP[j])
}
mtext(text=paste0(row - 1),side=1,line=row,at=stretch,adj=0)
text(temp$p.IP[j], temp$eff.mon.initial[j], row - 1)
}
if(output_png){dev.off()}
temp
View(figure3)
